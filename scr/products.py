import csv
import os
import time
import requests
import shutil
import re
import pandas as pd
import random 
import logging
from scr.base_function import get_wc_api, load_settings, setup_new_log_file, log_message_to_existing_file
from datetime import datetime, timedelta


def export_products():
    """
    –ï–∫—Å–ø–æ—Ä—Ç —É—Å—ñ—Ö —Ç–æ–≤–∞—Ä—ñ–≤ —É CSV –ø–∞—á–∫–∞–º–∏ –ø–æ 100, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—á–∏ –ø–æ–ª—è –∑ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω—å.
    """
    setup_new_log_file()

    settings = load_settings()
    if not settings or "paths" not in settings or "csv_path_zalishki" not in settings["paths"] or "export_fields" not in settings:
        logging.error("‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –Ω–µ–æ–±—Ö—ñ–¥–Ω—ñ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è (—à–ª—è—Ö –¥–æ CSV –∞–±–æ –ø–æ–ª—è –µ–∫—Å–ø–æ—Ä—Ç—É) –≤ settings.json. –ï–∫—Å–ø–æ—Ä—Ç –ø–µ—Ä–µ—Ä–≤–∞–Ω–æ.")
        return

    csv_path = os.path.join(os.path.dirname(__file__), "..", settings["paths"]["csv_path_zalishki"])

    # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Å–ø–∏—Å–∫—É –ø–æ–ª—ñ–≤ –¥–ª—è –∑–∞–ø–∏—Ç—É –¥–æ API —Ç–∞ –∑–∞–≥–æ–ª–æ–≤–∫—ñ–≤ –¥–ª—è CSV
    api_fields = []
    csv_headers = []
    meta_fields_for_api = []
    
    # –†–æ–∑–¥—ñ–ª—è—î–º–æ –ø–æ–ª—è –Ω–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ñ —ñ –º–µ—Ç–∞–¥–∞–Ω—ñ
    for field in settings["export_fields"]:
        if isinstance(field, str):
            api_fields.append(field)
            csv_headers.append(field)
        elif isinstance(field, dict) and "meta_data" in field:
            meta_fields_for_api = field["meta_data"]
            api_fields.append("meta_data")
            # –î–æ–¥–∞—î–º–æ –º–µ—Ç–∞–¥–∞–Ω—ñ –¥–æ –∑–∞–≥–æ–ª–æ–≤–∫—ñ–≤ CSV –∑ –ø—Ä–µ—Ñ—ñ–∫—Å–æ–º "–ú–µ—Ç–∞:"
            for meta_field in meta_fields_for_api:
                csv_headers.append(f"–ú–µ—Ç–∞: {meta_field}")

    wcapi = get_wc_api(settings)
    if not wcapi:
        logging.error("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è —Å—Ç–≤–æ—Ä–∏—Ç–∏ –æ–±'—î–∫—Ç WooCommerce API. –ï–∫—Å–ø–æ—Ä—Ç –ø–µ—Ä–µ—Ä–≤–∞–Ω–æ.")
        return

    start_time = time.time()
    total_products = 0
    exported_count = 0
    errors = []

    logging.info("üöÄ –ü–æ—á–∞—Ç–æ–∫ –µ–∫—Å–ø–æ—Ä—Ç—É —Ç–æ–≤–∞—Ä—ñ–≤.")

    try:
        response = wcapi.get("products", params={"per_page": 1})
        if response.status_code != 200:
            error_msg = f"–ü–æ–º–∏–ª–∫–∞ {response.status_code} –ø—Ä–∏ –ø—ñ–¥—Ä–∞—Ö—É–Ω–∫—É —Ç–æ–≤–∞—Ä—ñ–≤: {response.text}"
            print(f"‚ùå {error_msg}")
            logging.error(f"‚ùå {error_msg}")
            errors.append(error_msg)
            return

        total_products = int(response.headers.get("X-WP-Total", 0))
        logging.info(f"üîé –ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–æ–≤–∞—Ä—ñ–≤: {total_products}")

        with open(csv_path, "w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow(csv_headers)

            page = 1
            while exported_count < total_products:
                response = wcapi.get(
                    "products",
                    params={
                        "per_page": 100,
                        "page": page,
                        "_fields": ",".join(api_fields)
                    }
                )

                if response.status_code != 200:
                    error_msg = f"–ü–æ–º–∏–ª–∫–∞ {response.status_code} –Ω–∞ —Å—Ç–æ—Ä—ñ–Ω—Ü—ñ {page}: {response.text}"
                    print(f"‚ùå {error_msg}")
                    logging.error(f"‚ùå {error_msg}")
                    errors.append(error_msg)
                    break

                products = response.json()
                if not products:
                    break
                
                for product in products:
                    row = []
                    # –ó–∞–ø–æ–≤–Ω–µ–Ω–Ω—è —Ä—è–¥–∫–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏–º–∏ –ø–æ–ª—è–º–∏
                    for field in settings["export_fields"]:
                        if isinstance(field, str):
                            if field == "status":
                                row.append("yes" if product.get(field) == "publish" else "no")
                            elif field == "categories":
                                row.append(", ".join([cat["name"] for cat in product.get("categories", [])]))
                            else:
                                row.append(product.get(field, ""))
                        # –ó–∞–ø–æ–≤–Ω–µ–Ω–Ω—è –º–µ—Ç–∞–¥–∞–Ω–∏–º–∏
                        elif isinstance(field, dict) and "meta_data" in field:
                            meta_data_dict = {m["key"]: m["value"] for m in product.get("meta_data", [])}
                            for meta_field in meta_fields_for_api:
                                row.append(meta_data_dict.get(meta_field, ""))
                    
                    writer.writerow(row)
                    exported_count += 1
                
                if exported_count % 100 == 0 or exported_count == total_products:
                    elapsed = int(time.time() - start_time)
                    status_message = f"‚úÖ –í–∏–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {exported_count} –∑ {total_products} ({elapsed} —Å–µ–∫)"
                    print(status_message)
                    logging.info(status_message)

                page += 1
                time.sleep(1)

    except Exception as e:
        error_msg = f"–í–∏–Ω–∏–∫–ª–∞ –Ω–µ–≤—ñ–¥–æ–º–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –µ–∫—Å–ø–æ—Ä—Ç—É: {e}"
        print(f"‚ùå {error_msg}")
        logging.error(f"‚ùå {error_msg}", exc_info=True)
        errors.append(error_msg)
    finally:
        end_time = time.time()
        elapsed_time = int(end_time - start_time)
        
        print(f"üéâ –ï–∫—Å–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –í–∏–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {exported_count} –∑ {total_products} —Ç–æ–≤–∞—Ä—ñ–≤ –∑–∞ {elapsed_time} —Å–µ–∫.")
        if errors:
            print(f"‚ö†Ô∏è –ï–∫—Å–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–∏–≤—Å—è –∑ {len(errors)} –ø–æ–º–∏–ª–∫–∞–º–∏. –î–µ—Ç–∞–ª—ñ –≤ –ª–æ–≥-—Ñ–∞–π–ª—ñ.")
        
        logging.info("--- –ü—ñ–¥—Å—É–º–æ–∫ –µ–∫—Å–ø–æ—Ä—Ç—É ---")
        logging.info(f"–°—Ç–∞—Ç—É—Å: {'–£—Å–ø—ñ—à–Ω–æ' if not errors else '–ó–∞–≤–µ—Ä—à–µ–Ω–æ –∑ –ø–æ–º–∏–ª–∫–∞–º–∏'}")
        logging.info(f"–ö—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–æ–≤–∞—Ä—ñ–≤: {exported_count} –∑ {total_products}")
        logging.info(f"–¢—Ä–∏–≤–∞–ª—ñ—Å—Ç—å: {elapsed_time} —Å–µ–∫.")
        if errors:
            logging.info(f"–ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø–æ–º–∏–ª–æ–∫: {len(errors)}")
            logging.info("–ü–µ—Ä–µ–ª—ñ–∫ –ø–æ–º–∏–ª–æ–∫:")
            for err in errors:
                logging.info(f"- {err}")

def download_supplier_price_list(supplier_id):
    """
    –°–∫–∞—á—É—î –ø—Ä–∞–π—Å-–ª–∏—Å—Ç –≤—ñ–¥ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ –∑–∞ –π–æ–≥–æ ID.
    """
    # 0. –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ª–æ–≥—É–≤–∞–Ω–Ω—è –¥–ª—è –¥–æ–ø–∏—Å—É–≤–∞–Ω–Ω—è
    log_message_to_existing_file()

    # 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω—å
    settings = load_settings()
    if not settings:
        logging.error("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è. –°–∫–∞—á—É–≤–∞–Ω–Ω—è –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –ø–µ—Ä–µ—Ä–≤–∞–Ω–æ.")
        return
    
    # 2. –û—Ç—Ä–∏–º–∞–Ω–Ω—è —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –ø—Ä–æ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞
    supplier_info = settings.get("suppliers", {}).get(str(supplier_id))
    if not supplier_info:
        logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞: –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ –∑ ID '{supplier_id}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return

    # 3. –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è —à–ª—è—Ö—ñ–≤
    base_dir = os.path.join(os.path.dirname(__file__), "..")
    url = supplier_info.get("download_url")
    csv_path = os.path.join(base_dir, supplier_info.get("csv_path"))

    if not url or not csv_path:
        logging.error(f"‚ùå –ù–µ–ø–æ–≤–Ω—ñ –¥–∞–Ω—ñ –ø—Ä–æ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ '{supplier_id}'. –í—ñ–¥—Å—É—Ç–Ω—ñ–π URL –∞–±–æ —à–ª—è—Ö.")
        return
    
    logging.info(f"‚è≥ –ó–∞–ø—É—Å–∫–∞—é –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –≤—ñ–¥ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ (ID: {supplier_id}).")

    # 4. –í–∏–¥–∞–ª–µ–Ω–Ω—è —Å—Ç–∞—Ä–æ–≥–æ —Ñ–∞–π–ª—É
    if os.path.exists(csv_path):
        try:
            os.remove(csv_path)
            # –û–Ω–æ–≤–ª–µ–Ω–∞ –ª–æ–≥—ñ–∫–∞: –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ ID –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ –∑–∞–º—ñ—Å—Ç—å –Ω–∞–∑–≤–∏ —Ñ–∞–π–ª—É
            logging.info(f"‚úÖ –°—Ç–∞—Ä–∏–π –ø—Ä–∞–π—Å-–ª–∏—Å—Ç –≤—ñ–¥ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ (ID: {supplier_id}) —É—Å–ø—ñ—à–Ω–æ –≤–∏–¥–∞–ª–µ–Ω–æ.")
        except OSError as e:
            logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –≤–∏–¥–∞–ª–µ–Ω–Ω—ñ —Å—Ç–∞—Ä–æ–≥–æ —Ñ–∞–π–ª—É: {e}")
            return
    
    # 5. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª—É
    try:
        with requests.get(url, stream=True) as r:
            r.raise_for_status()
            with open(csv_path, 'wb') as f:
                shutil.copyfileobj(r.raw, f)
        
        logging.info(f"üéâ –ü—Ä–∞–π—Å-–ª–∏—Å—Ç –≤—ñ–¥ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ (ID: {supplier_id}) —É—Å–ø—ñ—à–Ω–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ.")
    except requests.exceptions.RequestException as e:
        logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ñ–∞–π–ª—É –≤—ñ–¥ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ (ID: {supplier_id}): {e}", exc_info=True)
    except Exception as e:
        logging.error(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –Ω–µ–≤—ñ–¥–æ–º–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è: {e}", exc_info=True)

def process_supplier_1_price_list():
    """
    –û–±—Ä–æ–±–ª—è—î —Ç–∞ –æ—á–∏—â–∞—î –ø—Ä–∞–π—Å-–ª–∏—Å—Ç –≤—ñ–¥ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 1.
    """
    # 0. –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ª–æ–≥—É–≤–∞–Ω–Ω—è –¥–ª—è –¥–æ–ø–∏—Å—É–≤–∞–Ω–Ω—è
    log_message_to_existing_file()

    # 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω—å
    settings = load_settings()
    if not settings:
        logging.error("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è. –û–±—Ä–æ–±–∫–∞ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –ø–µ—Ä–µ—Ä–≤–∞–Ω–∞.")
        return

    supplier_id = "1"
    supplier_info = settings.get("suppliers", {}).get(supplier_id)
    if not supplier_info:
        logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞: –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ –∑ ID '{supplier_id}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return

    # 2. –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è —à–ª—è—Ö—ñ–≤ —Ç–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤
    base_dir = os.path.join(os.path.dirname(__file__), "..")
    csv_path = os.path.join(base_dir, supplier_info.get("csv_path"))
    delimiter = supplier_info.get("delimiter", ",")

    if not os.path.exists(csv_path):
        logging.error(f"‚ùå –§–∞–π–ª –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –¥–ª—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {supplier_id} –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ")
        return

    logging.info(f"‚öôÔ∏è –ó–∞–ø—É—Å–∫–∞—é –æ–±—Ä–æ–±–∫—É –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –¥–ª—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {supplier_id}.")

    # 3. –§—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è —Ç–∞ –æ–±—Ä–æ–±–∫–∞ –¥–∞–Ω–∏—Ö
    words_to_filter_from_name = ["jos", "a-toys"]
    words_to_filter_from_brand = ["toyfa"]

    temp_file_path = f"{csv_path}.temp"
    processed_rows = []
    skipped_rows = 0
    total_rows = 0

    try:
        with open(csv_path, "r", newline="", encoding="utf-8") as infile:
            reader = csv.reader(infile, delimiter=delimiter)
            headers = next(reader)
            processed_rows.append(headers)
            
            row_number = 1
            for row in reader:
                row_number += 1
                total_rows += 1

                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∫–æ–ª–æ–Ω–∫–∏ 4 (—Ü—ñ–Ω–∞) –Ω–∞ –Ω–∞—è–≤–Ω—ñ—Å—Ç—å –ª—ñ—Ç–µ—Ä
                if len(row) > 3:
                    price_value = row[3]
                    if re.search(r'[a-zA-Z]', price_value):
                        logging.warning(f"üö´ –í–∏–¥–∞–ª–µ–Ω–æ —Ä—è–¥–æ–∫ {row_number} —á–µ—Ä–µ–∑ –Ω–∞—è–≤–Ω—ñ—Å—Ç—å –ª—ñ—Ç–µ—Ä —É –∫–æ–ª–æ–Ω—Ü—ñ 4 (—Ü—ñ–Ω–∞): '{price_value}'.")
                        skipped_rows += 1
                        continue

                # –§—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è –∑–∞ –∫–æ–ª–æ–Ω–∫–æ—é 3 (–Ω–∞–∑–≤–∞)
                if len(row) > 2:
                    product_name = row[2].lower()
                    if any(word in product_name for word in words_to_filter_from_name):
                        logging.warning(f"üö´ –í–∏–¥–∞–ª–µ–Ω–æ —Ä—è–¥–æ–∫ {row_number} —á–µ—Ä–µ–∑ –∑–∞–±–æ—Ä–æ–Ω–µ–Ω–µ —Å–ª–æ–≤–æ –≤ –Ω–∞–∑–≤—ñ ('{row[2]}').")
                        skipped_rows += 1
                        continue
                
                # –§—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è –∑–∞ –∫–æ–ª–æ–Ω–∫–æ—é 8 (–±—Ä–µ–Ω–¥)
                if len(row) > 7:
                    brand_name = row[7].lower()
                    if any(word in brand_name for word in words_to_filter_from_brand):
                        logging.warning(f"üö´ –í–∏–¥–∞–ª–µ–Ω–æ —Ä—è–¥–æ–∫ {row_number} —á–µ—Ä–µ–∑ –∑–∞–±–æ—Ä–æ–Ω–µ–Ω–µ —Å–ª–æ–≤–æ –≤ –±—Ä–µ–Ω–¥—ñ ('{row[7]}').")
                        skipped_rows += 1
                        continue

                # –ü–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è –∫–æ–ª–æ–Ω–∫–∏ 4 (—Ü—ñ–Ω–∞) –∑ float –Ω–∞ int
                if len(row) > 3 and row[3]:
                    try:
                        row[3] = str(int(float(row[3])))
                    except (ValueError, IndexError):
                        logging.warning(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –ø–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ü—ñ–Ω–∏ –≤ —Ä—è–¥–∫—É {row_number}. –ó–Ω–∞—á–µ–Ω–Ω—è: '{row[3]}'")
                
                # –ó–∞–º—ñ–Ω–∞ –∑–Ω–∞—á–µ–Ω–Ω—è –≤ –∫–æ–ª–æ–Ω—Ü—ñ 7 (–∫–∞—Ç–µ–≥–æ—Ä—ñ—è)
                if len(row) > 6 and row[6] == ">3":
                    row[6] = "4"
                
                processed_rows.append(row)
    
    except Exception as e:
        logging.error(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –æ–±—Ä–æ–±–∫–∏ —Ñ–∞–π–ª—É: {e}", exc_info=True)
        return

    # 4. –ó–∞–ø–∏—Å –æ–±—Ä–æ–±–ª–µ–Ω–æ–≥–æ —Ñ–∞–π–ª—É
    with open(temp_file_path, "w", newline="", encoding="utf-8") as outfile:
        writer = csv.writer(outfile, delimiter=delimiter)
        writer.writerows(processed_rows)

    os.replace(temp_file_path, csv_path)

    # 5. –õ–æ–≥—É–≤–∞–Ω–Ω—è –ø—ñ–¥—Å—É–º–∫—ñ–≤
    logging.info(f"üéâ –û–±—Ä–æ–±–∫—É –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –¥–ª—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {supplier_id} –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")
    logging.info(f"--- –ü—ñ–¥—Å—É–º–æ–∫ –æ–±—Ä–æ–±–∫–∏: ---")
    logging.info(f"üì¶ –í—Å—å–æ–≥–æ —Ä—è–¥–∫—ñ–≤ —É —Ñ–∞–π–ª—ñ: {total_rows}")
    logging.info(f"üóëÔ∏è –í–∏–¥–∞–ª–µ–Ω–æ —Ä—è–¥–∫—ñ–≤: {skipped_rows}")
    logging.info(f"‚úÖ –û–±—Ä–æ–±–ª–µ–Ω—ñ —Ä—è–¥–∫–∏: {len(processed_rows) - 1}")

def process_supplier_2_price_list():
    """
    –û–±—Ä–æ–±–ª—è—î —Ç–∞ –æ—á–∏—â–∞—î –ø—Ä–∞–π—Å-–ª–∏—Å—Ç –≤—ñ–¥ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 2.
    """
    # 0. –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ª–æ–≥—É–≤–∞–Ω–Ω—è –¥–ª—è –¥–æ–ø–∏—Å—É–≤–∞–Ω–Ω—è
    log_message_to_existing_file()

    # 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω—å
    settings = load_settings()
    if not settings:
        logging.error("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è. –û–±—Ä–æ–±–∫–∞ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –ø–µ—Ä–µ—Ä–≤–∞–Ω–∞.")
        return

    supplier_id = "2"
    supplier_info = settings.get("suppliers", {}).get(supplier_id)
    if not supplier_info:
        logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞: –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ –∑ ID '{supplier_id}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return

    # 2. –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è —à–ª—è—Ö—ñ–≤ —Ç–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤
    base_dir = os.path.join(os.path.dirname(__file__), "..")
    csv_path = os.path.join(base_dir, supplier_info.get("csv_path"))
    delimiter = supplier_info.get("delimiter", ",")

    if not os.path.exists(csv_path):
        logging.error(f"‚ùå –§–∞–π–ª –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –¥–ª—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {supplier_id} –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∑–∞ —à–ª—è—Ö–æ–º: {csv_path}")
        return

    logging.info(f"‚öôÔ∏è –ó–∞–ø—É—Å–∫–∞—é –æ–±—Ä–æ–±–∫—É –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –¥–ª—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {supplier_id}.")

    # 3. –û–±—Ä–æ–±–∫–∞ –¥–∞–Ω–∏—Ö
    temp_file_path = f"{csv_path}.temp"
    processed_rows = []
    skipped_rows = 0
    total_rows = 0
    modifications_count = 0

    try:
        with open(csv_path, "r", newline="", encoding="utf-8") as infile:
            reader = csv.reader(infile, delimiter=delimiter)
            try:
                headers = next(reader)
                processed_rows.append(headers)
            except StopIteration:
                logging.warning("‚ö†Ô∏è –§–∞–π–ª –ø–æ—Ä–æ–∂–Ω—ñ–π. –í—ñ–¥—Å—É—Ç–Ω—ñ —Ä—è–¥–∫–∏.")
                return

            row_number = 1
            for row in reader:
                row_number += 1
                total_rows += 1

                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∫–æ–ª–æ–Ω–∫–∏ 5 (–≤–∞–ª—é—Ç–∞)
                if len(row) > 4:
                    currency_value = row[4].strip().upper()
                    if currency_value != "UAH":
                        logging.warning(f"üö´ –í–∏–¥–∞–ª–µ–Ω–æ —Ä—è–¥–æ–∫ {row_number} —á–µ—Ä–µ–∑ –Ω–µ–∫–æ—Ä–µ–∫—Ç–Ω—É –≤–∞–ª—é—Ç—É —É –∫–æ–ª–æ–Ω—Ü—ñ 5: '{row[4]}'.")
                        skipped_rows += 1
                        continue
                else:
                    logging.warning(f"üö´ –í–∏–¥–∞–ª–µ–Ω–æ —Ä—è–¥–æ–∫ {row_number} —á–µ—Ä–µ–∑ –≤—ñ–¥—Å—É—Ç–Ω—ñ—Å—Ç—å –∑–Ω–∞—á–µ–Ω–Ω—è —É –∫–æ–ª–æ–Ω—Ü—ñ 5 (–≤–∞–ª—é—Ç–∞).")
                    skipped_rows += 1
                    continue

                # –ü–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è –∫–æ–ª–æ–Ω–∫–∏ 4 (—Ü—ñ–Ω–∞) –∑ float –Ω–∞ int
                if len(row) > 3 and row[3]:
                    try:
                        row[3] = str(int(float(row[3])))
                    except (ValueError, IndexError):
                        logging.warning(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –ø–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ü—ñ–Ω–∏ –≤ —Ä—è–¥–∫—É {row_number}. –ó–Ω–∞—á–µ–Ω–Ω—è: '{row[3]}'")
                
                # –ó–∞–º—ñ–Ω–∞ –∑–Ω–∞—á–µ–Ω–Ω—è –≤ –∫–æ–ª–æ–Ω—Ü—ñ 7 (–∫–∞—Ç–µ–≥–æ—Ä—ñ—è)
                if len(row) > 6 and row[6] == ">3":
                    row[6] = "4"
                    modifications_count += 1
                
                processed_rows.append(row)
    
    except Exception as e:
        logging.error(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –æ–±—Ä–æ–±–∫–∏ —Ñ–∞–π–ª—É: {e}", exc_info=True)
        return

    # 4. –ó–∞–ø–∏—Å –æ–±—Ä–æ–±–ª–µ–Ω–æ–≥–æ —Ñ–∞–π–ª—É
    with open(temp_file_path, "w", newline="", encoding="utf-8") as outfile:
        writer = csv.writer(outfile, delimiter=delimiter)
        writer.writerows(processed_rows)

    os.replace(temp_file_path, csv_path)

    # 5. –õ–æ–≥—É–≤–∞–Ω–Ω—è –ø—ñ–¥—Å—É–º–∫—ñ–≤
    logging.info(f"üéâ –û–±—Ä–æ–±–∫—É –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –¥–ª—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {supplier_id} –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")
    logging.info("--- –ü—ñ–¥—Å—É–º–æ–∫ –æ–±—Ä–æ–±–∫–∏: ---")
    logging.info(f"üì¶ –í—Å—å–æ–≥–æ —Ä—è–¥–∫—ñ–≤ —É —Ñ–∞–π–ª—ñ: {total_rows}")
    logging.info(f"üóëÔ∏è –í–∏–¥–∞–ª–µ–Ω–æ —Ä—è–¥–∫—ñ–≤: {skipped_rows}")
    logging.info(f"üìù –ó–º—ñ–Ω–µ–Ω–æ –∫–∞—Ç–µ–≥–æ—Ä—ñ–π '>3' -> '4': {modifications_count} —Ä–∞–∑—ñ–≤")
    logging.info(f"‚úÖ –û–±—Ä–æ–±–ª–µ–Ω—ñ —Ä—è–¥–∫–∏: {len(processed_rows) - 1}")
    print("‚úÖ –û–±—Ä–æ–±–∫–∞ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –î–µ—Ç–∞–ª—ñ –≤ –ª–æ–≥-—Ñ–∞–π–ª—ñ.")

def process_supplier_3_price_list():
    """
    –û–±—Ä–æ–±–ª—è—î —Ç–∞ –∫–æ–Ω–≤–µ—Ä—Ç—É—î –ø—Ä–∞–π—Å-–ª–∏—Å—Ç –≤—ñ–¥ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 3 (—Ñ–æ—Ä–º–∞—Ç .xls),
    –∞ –ø–æ—Ç—ñ–º —Ñ—ñ–ª—å—Ç—Ä—É—î –¥–∞–Ω—ñ.
    """
    # 0. –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ª–æ–≥—É–≤–∞–Ω–Ω—è –¥–ª—è –¥–æ–ø–∏—Å—É–≤–∞–Ω–Ω—è
    log_message_to_existing_file()

    # 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω—å
    settings = load_settings()
    if not settings:
        logging.error("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è. –û–±—Ä–æ–±–∫–∞ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –ø–µ—Ä–µ—Ä–≤–∞–Ω–∞.")
        return

    supplier_id = "3"
    supplier_info = settings.get("suppliers", {}).get(supplier_id)
    if not supplier_info:
        logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞: –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ –∑ ID '{supplier_id}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return

    # 2. –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è —à–ª—è—Ö—ñ–≤
    base_dir = os.path.join(os.path.dirname(__file__), "..")
    xls_path = os.path.join(base_dir, supplier_info.get("csv_path"))
    csv_name = os.path.join(base_dir, supplier_info.get("csv_name"))

    logging.info(f"‚öôÔ∏è –ó–∞–ø—É—Å–∫–∞—é –æ–±—Ä–æ–±–∫—É –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –¥–ª—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {supplier_id}.")

    # 3. –í–∏–¥–∞–ª–µ–Ω–Ω—è —Å—Ç–∞—Ä–æ–≥–æ CSV-—Ñ–∞–π–ª—É
    if os.path.exists(csv_name):
        try:
            os.remove(csv_name)
            logging.info(f"‚úÖ –°—Ç–∞—Ä–∏–π –ø—Ä–∞–π—Å-–ª–∏—Å—Ç –¥–ª—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {supplier_id} —É—Å–ø—ñ—à–Ω–æ –≤–∏–¥–∞–ª–µ–Ω–æ.")
        except OSError as e:
            logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –≤–∏–¥–∞–ª–µ–Ω–Ω—ñ —Å—Ç–∞—Ä–æ–≥–æ CSV-—Ñ–∞–π–ª—É: {e}")
            return

    # 4. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è XLS –≤ CSV
    if not os.path.exists(xls_path):
        logging.error(f"‚ùå –§–∞–π–ª .xls –¥–ª—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {supplier_id} –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∑–∞ —à–ª—è—Ö–æ–º: {xls_path}")
        return

    try:
        df = pd.read_excel(xls_path)
        df.to_csv(csv_name, index=False, encoding="utf-8")
        
        logging.info(f"üéâ –§–∞–π–ª .xls –¥–ª—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {supplier_id} —É—Å–ø—ñ—à–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–æ–≤–∞–Ω–æ –≤ CSV.")

    except Exception as e:
        logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—ó —Ñ–∞–π–ª—É: {e}", exc_info=True)
        return

    # 5. –§—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è —Ç–∞ –æ—á–∏—â–µ–Ω–Ω—è CSV-—Ñ–∞–π–ª—É
    logging.info(f"üîç –ó–∞–ø—É—Å–∫–∞—é —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—é –¥–∞–Ω–∏—Ö —É CSV-—Ñ–∞–π–ª—ñ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {supplier_id}.")

    temp_file_path = f"{csv_name}.temp"
    processed_rows = []
    skipped_rows = 0
    total_rows = 0

    try:
        with open(csv_name, "r", newline="", encoding="utf-8") as infile:
            reader = csv.reader(infile)
            try:
                headers = next(reader)
                processed_rows.append(headers)
            except StopIteration:
                logging.warning("‚ö†Ô∏è –§–∞–π–ª –ø–æ—Ä–æ–∂–Ω—ñ–π. –í—ñ–¥—Å—É—Ç–Ω—ñ —Ä—è–¥–∫–∏.")
                return
            
            row_number = 1
            for row in reader:
                row_number += 1
                total_rows += 1

                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞, —â–æ —Ä—è–¥–æ–∫ –º—ñ—Å—Ç–∏—Ç—å –¥–æ—Å—Ç–∞—Ç–Ω—å–æ –∫–æ–ª–æ–Ω–æ–∫
                if len(row) < 4:
                    logging.warning(f"üö´ –í–∏–¥–∞–ª–µ–Ω–æ —Ä—è–¥–æ–∫ {row_number} —á–µ—Ä–µ–∑ –Ω–µ–¥–æ—Å—Ç–∞—Ç–Ω—é –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫–æ–ª–æ–Ω–æ–∫.")
                    skipped_rows += 1
                    continue

                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∫–æ–ª–æ–Ω–æ–∫ 3 —Ç–∞ 4 –Ω–∞ —Ü—ñ–ª–µ —á–∏—Å–ª–æ >= 0
                is_valid = True
                for col_index in [2, 3]:
                    value = row[col_index]
                    try:
                        int_value = int(float(value))
                        if int_value < 0:
                            logging.warning(f"üö´ –í–∏–¥–∞–ª–µ–Ω–æ —Ä—è–¥–æ–∫ {row_number} —á–µ—Ä–µ–∑ –≤—ñ–¥'—î–º–Ω–µ –∑–Ω–∞—á–µ–Ω–Ω—è –≤ –∫–æ–ª–æ–Ω—Ü—ñ {col_index + 1}: '{value}'.")
                            is_valid = False
                            break
                    except (ValueError, IndexError):
                        logging.warning(f"üö´ –í–∏–¥–∞–ª–µ–Ω–æ —Ä—è–¥–æ–∫ {row_number} —á–µ—Ä–µ–∑ –Ω–µ–∫–æ—Ä–µ–∫—Ç–Ω–µ —á–∏—Å–ª–æ–≤–µ –∑–Ω–∞—á–µ–Ω–Ω—è –≤ –∫–æ–ª–æ–Ω—Ü—ñ {col_index + 1}: '{value}'.")
                        is_valid = False
                        break

                if is_valid:
                    processed_rows.append(row)
                else:
                    skipped_rows += 1
    
    except Exception as e:
        logging.error(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—ó —Ñ–∞–π–ª—É: {e}", exc_info=True)
        return

    # 6. –ó–∞–ø–∏—Å –≤—ñ–¥—Ñ—ñ–ª—å—Ç—Ä–æ–≤–∞–Ω–∏—Ö –¥–∞–Ω–∏—Ö —É —Ñ–∞–π–ª
    with open(temp_file_path, "w", newline="", encoding="utf-8") as outfile:
        writer = csv.writer(outfile)
        writer.writerows(processed_rows)

    os.replace(temp_file_path, csv_name)

    # 7. –õ–æ–≥—É–≤–∞–Ω–Ω—è –ø—ñ–¥—Å—É–º–∫—ñ–≤
    logging.info(f"üéâ –û–±—Ä–æ–±–∫—É —Ç–∞ —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—é –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –¥–ª—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {supplier_id} –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")
    logging.info("--- –ü—ñ–¥—Å—É–º–æ–∫ –æ–±—Ä–æ–±–∫–∏: ---")
    logging.info(f"üì¶ –í—Å—å–æ–≥–æ —Ä—è–¥–∫—ñ–≤ —É —Ñ–∞–π–ª—ñ: {total_rows}")
    logging.info(f"üóëÔ∏è –í–∏–¥–∞–ª–µ–Ω–æ —Ä—è–¥–∫—ñ–≤: {skipped_rows}")
    logging.info(f"‚úÖ –û–±—Ä–æ–±–ª–µ–Ω—ñ —Ä—è–¥–∫–∏: {len(processed_rows) - 1}")
    print("‚úÖ –û–±—Ä–æ–±–∫–∞ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –î–µ—Ç–∞–ª—ñ –≤ –ª–æ–≥-—Ñ–∞–π–ª—ñ.")

def process_and_combine_all_data():
    """
    –û–±—Ä–æ–±–ª—è—î –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∏ —Ç–∞ –æ–±'—î–¥–Ω—É—î –¥–∞–Ω—ñ —É –∑–≤–µ–¥–µ–Ω—É —Ç–∞–±–ª–∏—Ü—é csv/process/zvedena.csv.
    """
    
    # 0. –ü–æ—á–∞—Ç–∫–æ–≤–µ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —Ç–∞ –ª–æ–≥—É–≤–∞–Ω–Ω—è
    log_message_to_existing_file()
    logging.info("--- ‚öôÔ∏è –ó–∞–ø—É—Å–∫–∞—é –ø–æ–≤–Ω–∏–π –ø—Ä–æ—Ü–µ—Å –æ–±—Ä–æ–±–∫–∏ —Ç–∞ –æ–±'—î–¥–Ω–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö... ---")

    # 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω—å —Ç–∞ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è —à–ª—è—Ö—ñ–≤
    # –¶–µ–π –±–ª–æ–∫ –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î —Ñ–∞–π–ª –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω—å settings.json —ñ –≤–∏–∑–Ω–∞—á–∞—î –≤—Å—ñ –Ω–µ–æ–±—Ö—ñ–¥–Ω—ñ —à–ª—è—Ö–∏ –¥–æ —Ñ–∞–π–ª—ñ–≤.
    settings = load_settings()
    if not settings:
        logging.error("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è. –ü—Ä–æ—Ü–µ—Å –ø–µ—Ä–µ—Ä–≤–∞–Ω–æ.")
        return

    base_dir = os.path.join(os.path.dirname(__file__), "..")
    
    # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –º–µ—Ç–æ–¥ .get() –∑ –≤–∫–ª–∞–¥–µ–Ω–∏–º–∏ –∫–ª—é—á–∞–º–∏ –¥–ª—è –±–µ–∑–ø–µ—á–Ω–æ–≥–æ –¥–æ—Å—Ç—É–ø—É
    paths = settings.get("paths", {})
    suppliers = settings.get("suppliers", {})
    
    log_file_path = os.path.join(base_dir, paths.get("main_log_file"))
    zalishki_path = os.path.join(base_dir, paths.get("csv_path_zalishki"))
    zvedena_path = os.path.join(base_dir, paths.get("csv_path_zvedena"))
    
    # –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫—ñ–≤
    supplier_info_1 = suppliers.get("1", {})
    supplier_csv_path_1 = os.path.join(base_dir, supplier_info_1.get("csv_path"))
    supplier_delimiter_1 = supplier_info_1.get("delimiter", ",")
    
    supplier_info_2 = suppliers.get("2", {})
    supplier_csv_path_2 = os.path.join(base_dir, supplier_info_2.get("csv_path"))
    supplier_delimiter_2 = supplier_info_2.get("delimiter", ",")

    supplier_info_3 = suppliers.get("3", {})
    supplier_csv_path_3 = os.path.join(base_dir, supplier_info_3.get("csv_name"))
    supplier_delimiter_3 = supplier_info_3.get("delimiter", ",")
    
    supplier_info_4 = suppliers.get("4", {})
    supplier_csv_path_4 = os.path.join(base_dir, supplier_info_4.get("csv_path"))
    supplier_delimiter_4 = supplier_info_4.get("delimiter", ",")
    
    # –î–æ–¥–∞—Ç–∫–æ–≤—ñ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è
    zvedena_names_map = settings.get("column_zvedena_name")
    new_header = [zvedena_names_map.get(str(i)) for i in range(len(zvedena_names_map))]
    
    zalishki_columns = ["0", "1", "7", "9", "11", "13", "4", "5", "3", "2", "6"]
    
    supplier_1_columns = ["0", "3", "6"]
    supplier_1_match_column = "0"
    zvedena_match_column_1 = "3"
    
    supplier_2_columns = ["0", "3", "6"]
    supplier_2_match_column = "0"
    zvedena_match_column_2 = "4"

    supplier_3_columns = ["0", "2", "3"]
    supplier_3_match_column = "0"
    zvedena_match_column_3 = "5"
    
    supplier_4_columns = ["5", "4", "6"]
    supplier_4_match_column = "5"
    zvedena_match_column_4 = "1"
    
    # 2. –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ –≤—Å—ñ—Ö –Ω–µ–æ–±—Ö—ñ–¥–Ω–∏—Ö —Ñ–∞–π–ª—ñ–≤
    # –¶–µ–π –±–ª–æ–∫ –ø–µ—Ä–µ–≤—ñ—Ä—è—î, —á–∏ —ñ—Å–Ω—É—é—Ç—å —É—Å—ñ —Ñ–∞–π–ª–∏, –ø–µ—Ä—à –Ω—ñ–∂ –ø–æ—á–∞—Ç–∏ –æ–±—Ä–æ–±–∫—É.
    required_files = {
        "—Ñ–∞–π–ª –∑–∞–ª–∏—à–∫—ñ–≤": zalishki_path,
        "–ø—Ä–∞–π—Å-–ª–∏—Å—Ç –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 1": supplier_csv_path_1,
        "–ø—Ä–∞–π—Å-–ª–∏—Å—Ç –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 2": supplier_csv_path_2,
        "–ø—Ä–∞–π—Å-–ª–∏—Å—Ç –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 3": supplier_csv_path_3,
        "–ø—Ä–∞–π—Å-–ª–∏—Å—Ç –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 4": supplier_csv_path_4,
    }

    for file_name, path in required_files.items():
        if not path or not os.path.exists(path):
            logging.error(f"‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ {file_name} –∑–∞ —à–ª—è—Ö–æ–º: {path}. –ü—Ä–æ—Ü–µ—Å –∑—É–ø–∏–Ω–µ–Ω–æ.")
            print(f"‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ {file_name}.")
            return
    
    # 3. –í–∏–¥–∞–ª–µ–Ω–Ω—è —Å—Ç–∞—Ä–æ–≥–æ –∑–≤–µ–¥–µ–Ω–æ–≥–æ —Ñ–∞–π–ª—É (—è–∫—â–æ —ñ—Å–Ω—É—î)
    if os.path.exists(zvedena_path):
        try:
            os.remove(zvedena_path)
            logging.info(f"‚úÖ –°—Ç–∞—Ä–∏–π —Ñ–∞–π–ª {os.path.basename(zvedena_path)} —É—Å–ø—ñ—à–Ω–æ –≤–∏–¥–∞–ª–µ–Ω–æ.")
        except OSError as e:
            logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –≤–∏–¥–∞–ª–µ–Ω–Ω—ñ —Å—Ç–∞—Ä–æ–≥–æ —Ñ–∞–π–ª—É: {e}", exc_info=True)
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: {e}")
            return
    
    # 4. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫—ñ–≤ —É —Å–ª–æ–≤–Ω–∏–∫–∏ –¥–ª—è —à–≤–∏–¥–∫–æ–≥–æ –¥–æ—Å—Ç—É–ø—É
    # –ö–æ–∂–µ–Ω —Ñ–∞–π–ª –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ –∑—á–∏—Ç—É—î—Ç—å—Å—è –≤ –ø–∞–º'—è—Ç—å, —â–æ–± –ø—Ä–∏—Å–∫–æ—Ä–∏—Ç–∏ –ø—Ä–æ—Ü–µ—Å –æ–±—Ä–æ–±–∫–∏.
    supplier_data_dict = {}
    supplier_list = [
        ("1", supplier_csv_path_1, supplier_delimiter_1, supplier_1_columns, supplier_1_match_column),
        ("2", supplier_csv_path_2, supplier_delimiter_2, supplier_2_columns, supplier_2_match_column),
        ("3", supplier_csv_path_3, supplier_delimiter_3, supplier_3_columns, supplier_3_match_column),
        ("4", supplier_csv_path_4, supplier_delimiter_4, supplier_4_columns, supplier_4_match_column)
    ]
    
    for s_id, path, delimiter, columns, match_col in supplier_list:
        try:
            supplier_data_dict[s_id] = {}
            with open(path, "r", newline="", encoding="utf-8") as infile:
                reader = csv.reader(infile, delimiter=delimiter)
                try:
                    next(reader) 
                except StopIteration:
                    logging.warning(f"‚ö†Ô∏è –ü—Ä–∞–π—Å-–ª–∏—Å—Ç –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {s_id} –ø–æ—Ä–æ–∂–Ω—ñ–π. –ü—Ä–æ–ø—É—Å–∫–∞—é –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è.")
                    continue
                for row in reader:
                    if len(row) > max(int(c) for c in columns):
                        key = row[int(match_col)].strip()
                        values = [row[int(c)].strip() for c in columns]
                        supplier_data_dict[s_id][key] = values
            logging.info(f"‚úÖ –î–∞–Ω—ñ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {s_id} —É—Å–ø—ñ—à–Ω–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –≤ –ø–∞–º'—è—Ç—å. –ó–Ω–∞–π–¥–µ–Ω–æ {len(supplier_data_dict[s_id])} —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö –∑–∞–ø–∏—Å—ñ–≤.")
        except Exception as e:
            logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ —á–∏—Ç–∞–Ω–Ω—ñ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {s_id}: {e}", exc_info=True)
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ —á–∏—Ç–∞–Ω–Ω—ñ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {s_id}: {e}")
            return

    # 5. –û–±—Ä–æ–±–∫–∞ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ñ–∞–π–ª—É –∑–∞–ª–∏—à–∫—ñ–≤ —Ç–∞ –æ–±'—î–¥–Ω–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö
    # –¶–µ–π –±–ª–æ–∫ —á–∏—Ç–∞—î –æ—Å–Ω–æ–≤–Ω–∏–π —Ñ–∞–π–ª, –¥–æ–¥–∞—î –¥–æ –∫–æ–∂–Ω–æ–≥–æ —Ä—è–¥–∫–∞ –¥–∞–Ω—ñ –≤—ñ–¥ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫—ñ–≤
    # —Ç–∞ –æ–±—á–∏—Å–ª—é—î –Ω–æ–≤—ñ –∫–æ–ª–æ–Ω–∫–∏, —ñ–≥–Ω–æ—Ä—É—é—á–∏ –ø–æ—Ä–æ–∂–Ω—ñ –∞–±–æ –ø–æ—à–∫–æ–¥–∂–µ–Ω—ñ —Ä—è–¥–∫–∏.
    processed_rows = []
    processed_count = 0
    updated_by_s1_count = 0
    updated_by_s2_count = 0
    updated_by_s3_count = 0
    updated_by_s4_count = 0
    
    formula_cols = {
        'N': 13, 'Q': 16, 'S': 18, 'V': 21,
        'M': 12, 'P': 15, 'T': 19, 'W': 22,
        'H': 7,
        'I': 8,
        'X': 23,
        'G': 6,
        'Y': 24
    }
    
    suppliers_to_process = [
        ("1", zvedena_match_column_1, updated_by_s1_count),
        ("2", zvedena_match_column_2, updated_by_s2_count),
        ("3", zvedena_match_column_3, updated_by_s3_count),
        ("4", zvedena_match_column_4, updated_by_s4_count)
    ]

    try:
        with open(zalishki_path, "r", newline="", encoding="utf-8") as infile:
            reader = csv.reader(infile)
            try:
                next(reader)
            except StopIteration:
                logging.warning("‚ö†Ô∏è –§–∞–π–ª –∑–∞–ª–∏—à–∫—ñ–≤ –ø–æ—Ä–æ–∂–Ω—ñ–π. –ó–≤–µ–¥–µ–Ω–∞ —Ç–∞–±–ª–∏—Ü—è –±—É–¥–µ —Å—Ç–≤–æ—Ä–µ–Ω–∞ –ª–∏—à–µ —ñ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–º.")
                
            processed_rows.append(new_header)
            
            for row in reader:
                if not row or not any(row):
                    continue
                
                processed_count += 1
                if len(row) > 13:
                    new_row = [row[int(col_index)] for col_index in zalishki_columns]
                    
                    for s_id, match_col, counter in suppliers_to_process:
                        supplier_data = supplier_data_dict.get(s_id, {}).get(new_row[int(match_col)].strip(), ["", "", ""])
                        new_row.extend(supplier_data)
                        if supplier_data and supplier_data[0] != "":
                            if s_id == "1": updated_by_s1_count += 1
                            elif s_id == "2": updated_by_s2_count += 1
                            elif s_id == "3": updated_by_s3_count += 1
                            elif s_id == "4": updated_by_s4_count += 1

                    # –û–±—á–∏—Å–ª–µ–Ω–Ω—è –¥–ª—è –∫–æ–ª–æ–Ω–∫–∏ 23
                    quantities_to_compare = []
                    for col_name in ['N', 'Q', 'S', 'V']:
                        try:
                            index = formula_cols[col_name]
                            val = new_row[index].strip()
                            quantities_to_compare.append(int(val) if val else 0)
                        except (KeyError, IndexError):
                            quantities_to_compare.append(0)
                    
                    max_quantity = max(quantities_to_compare) if quantities_to_compare else 0
                    new_row.append(str(max_quantity))

                    # –û–±—á–∏—Å–ª–µ–Ω–Ω—è –¥–ª—è –∫–æ–ª–æ–Ω–∫–∏ 24
                    quantities_for_sum = []
                    valid_quantities_for_min = []
                    
                    for col_name in ['M', 'P', 'T', 'W']:
                        try:
                            index = formula_cols[col_name]
                            val = new_row[index].strip()
                            num_val = int(val) if val else 0
                            quantities_for_sum.append(num_val)
                            if num_val > 0:
                                valid_quantities_for_min.append(num_val)
                        except (KeyError, IndexError):
                            quantities_for_sum.append(0)
                    
                    if sum(quantities_for_sum) == 0:
                        try:
                            result_24 = new_row[formula_cols['H']]
                        except IndexError:
                            result_24 = "0"
                    else:
                        result_24 = min(valid_quantities_for_min) if valid_quantities_for_min else 0
                    
                    new_row.append(str(result_24))

                    # –û–±—á–∏—Å–ª–µ–Ω–Ω—è –¥–ª—è –∫–æ–ª–æ–Ω–∫–∏ 25
                    try:
                        i_val = new_row[formula_cols['I']].strip().lower()
                    except IndexError:
                        i_val = ""
                    
                    result_25 = 1 if i_val == "yes" else 0
                    new_row.append(str(result_25))
                    
                    # –û–±—á–∏—Å–ª–µ–Ω–Ω—è –¥–ª—è –∫–æ–ª–æ–Ω–∫–∏ 26
                    x_val = 0
                    g_val = 0
                    try:
                        x_val = int(new_row[formula_cols['X']])
                    except (ValueError, IndexError):
                        x_val = 0
                    
                    try:
                        g_val = int(new_row[formula_cols['G']])
                    except (ValueError, IndexError):
                        g_val = 0
                    
                    if (x_val - g_val) == 0:
                        result_26 = 0
                    else:
                        result_26 = 1
                    
                    new_row.append(str(result_26))
                    logging.debug(f"—Ä—è–¥–æ–∫ {processed_count}: X = \"{x_val}\", G = \"{g_val}\". (X - G) = \"{x_val - g_val}\". –†–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –∫–æ–ª–æ–Ω–∫–∏ 26 = \"{result_26}\"")

                    # –û–±—á–∏—Å–ª–µ–Ω–Ω—è –¥–ª—è –∫–æ–ª–æ–Ω–∫–∏ 27
                    y_val = 0
                    h_val = 0
                    try:
                        y_val = int(new_row[formula_cols['Y']])
                    except (ValueError, IndexError):
                        y_val = 0
                    
                    try:
                        h_val = int(new_row[formula_cols['H']])
                    except (ValueError, IndexError):
                        h_val = 0
                    
                    if (y_val - h_val) == 0:
                        result_27 = 0
                    else:
                        result_27 = 1
                    
                    new_row.append(str(result_27))
                    logging.debug(f"—Ä—è–¥–æ–∫ {processed_count}: Y = \"{y_val}\", H = \"{h_val}\". (Y - H) = \"{y_val - h_val}\". –†–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –∫–æ–ª–æ–Ω–∫–∏ 27 = \"{result_27}\"")
                    
                    processed_rows.append(new_row)
                else:
                    logging.warning(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ —Ä—è–¥–æ–∫ {processed_count} —á–µ—Ä–µ–∑ –Ω–µ–¥–æ—Å—Ç–∞—Ç–Ω—é –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫–æ–ª–æ–Ω–æ–∫.")
    
    except Exception as e:
        logging.error(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –æ–±—Ä–æ–±–∫–∏ –¥–∞–Ω–∏—Ö: {e}", exc_info=True)
        print(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –æ–±—Ä–æ–±–∫–∏ –¥–∞–Ω–∏—Ö: {e}")
        return

    # 6. –°–æ—Ä—Ç—É–≤–∞–Ω–Ω—è —Ç–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö —É –∑–≤–µ–¥–µ–Ω–∏–π —Ñ–∞–π–ª CSV
    # –¶–µ–π –±–ª–æ–∫ —Å–æ—Ä—Ç—É—î –æ–±—Ä–æ–±–ª–µ–Ω—ñ –¥–∞–Ω—ñ —Ç–∞ –∑–∞–ø–∏—Å—É—î —ó—Ö —É –Ω–æ–≤–∏–π —Ñ–∞–π–ª,
    # –ø–µ—Ä–µ–≤—ñ—Ä—è—é—á–∏, —á–∏ —î –¥–∞–Ω—ñ –¥–ª—è –∑–∞–ø–∏—Å—É.
    try:
        if len(processed_rows) <= 1:
            logging.warning("‚ö†Ô∏è –ù–µ–º–∞—î –¥–∞–Ω–∏—Ö –¥–ª—è –∑–∞–ø–∏—Å—É, –∫—Ä—ñ–º –∑–∞–≥–æ–ª–æ–≤–∫–∞.")
            print("‚ö†Ô∏è –ù–µ–º–∞—î –¥–∞–Ω–∏—Ö –¥–ª—è –∑–∞–ø–∏—Å—É, –∫—Ä—ñ–º –∑–∞–≥–æ–ª–æ–≤–∫–∞. –§–∞–π–ª –Ω–µ –±—É–¥–µ —Å—Ç–≤–æ—Ä–µ–Ω–æ.")
            return

        # –°–æ—Ä—Ç—É–≤–∞–Ω–Ω—è –∑–∞ –∫–æ–ª–æ–Ω–∫–æ—é B (—ñ–Ω–¥–µ–∫—Å 1)
        # –°–ø–æ—á–∞—Ç–∫—É –≤–∏–¥–∞–ª—è—î–º–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫, —Å–æ—Ä—Ç—É—î–º–æ, –∞ –ø–æ—Ç—ñ–º –¥–æ–¥–∞—î–º–æ –π–æ–≥–æ –Ω–∞–∑–∞–¥.
        header = processed_rows[0]
        data_rows = processed_rows[1:]
        data_rows.sort(key=lambda row: int(row[1]))
        sorted_rows = [header] + data_rows

        with open(zvedena_path, "w", newline="", encoding="utf-8") as outfile:
            writer = csv.writer(outfile, delimiter=',')
            writer.writerows(sorted_rows)

        logging.info("--- üéâ –ü–æ–≤–Ω–∏–π –ø—Ä–æ—Ü–µ—Å –æ–±—Ä–æ–±–∫–∏ —Ç–∞ –æ–±'—î–¥–Ω–∞–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ! ---")
        logging.info("--- –ü—ñ–¥—Å—É–º–æ–∫: ---")
        logging.info(f"üì¶ –í—Å—å–æ–≥–æ —Ä—è–¥–∫—ñ–≤ —É —Ñ–∞–π–ª—ñ –∑–∞–ª–∏—à–∫—ñ–≤: {processed_count}")
        logging.info(f"‚úÖ –û–Ω–æ–≤–ª–µ–Ω–æ –¥–∞–Ω–∏–º–∏ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 1: {updated_by_s1_count} —Ä—è–¥–∫—ñ–≤.")
        logging.info(f"‚úÖ –û–Ω–æ–≤–ª–µ–Ω–æ –¥–∞–Ω–∏–º–∏ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 2: {updated_by_s2_count} —Ä—è–¥–∫—ñ–≤.")
        logging.info(f"‚úÖ –û–Ω–æ–≤–ª–µ–Ω–æ –¥–∞–Ω–∏–º–∏ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 3: {updated_by_s3_count} —Ä—è–¥–∫—ñ–≤.")
        logging.info(f"‚úÖ –û–Ω–æ–≤–ª–µ–Ω–æ –¥–∞–Ω–∏–º–∏ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 4: {updated_by_s4_count} —Ä—è–¥–∫—ñ–≤.")
        logging.info(f"üìÑ –°—Ç–≤–æ—Ä–µ–Ω–æ –∑–≤–µ–¥–µ–Ω–∏—Ö —Ä—è–¥–∫—ñ–≤: {len(processed_rows) - 1}")
        print("‚úÖ –ü–æ–≤–Ω–∏–π –ø—Ä–æ—Ü–µ—Å –æ–±—Ä–æ–±–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –î–µ—Ç–∞–ª—ñ –≤ –ª–æ–≥-—Ñ–∞–π–ª—ñ.")

    except Exception as e:
        logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—ñ –∑–≤–µ–¥–µ–Ω–æ—ó —Ç–∞–±–ª–∏—Ü—ñ: {e}", exc_info=True)
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: {e}")

def prepare_for_website_upload():
    """
    –ì–æ—Ç—É—î –¥–∞–Ω—ñ –∑—ñ –∑–≤–µ–¥–µ–Ω–æ—ó —Ç–∞–±–ª–∏—Ü—ñ –¥–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –Ω–∞ —Å–∞–π—Ç,
    –≤–∏–∫–æ–Ω—É—é—á–∏ –∫–æ–∂–µ–Ω –∫—Ä–æ–∫ –æ–∫—Ä–µ–º–æ –∑ –∑–∞–ø–∏—Å–æ–º —É —Ñ–∞–π–ª.
    """
    settings = load_settings()
    if not settings:
        logging.error("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è. –ü—Ä–æ—Ü–µ—Å –ø–µ—Ä–µ—Ä–≤–∞–Ω–æ.")
        return

    base_dir = os.path.join(os.path.dirname(__file__), "..")
    source_file_path = os.path.join(base_dir, settings["paths"]["csv_path_zvedena"])
    intermediate_file_path = os.path.join(base_dir, "csv", "process", "na_sait.csv")
    
    logging.info("‚öôÔ∏è –ó–∞–ø—É—Å–∫–∞—é –ø—ñ–¥–≥–æ—Ç–æ–≤–∫—É –¥–∞–Ω–∏—Ö –¥–ª—è —Å–∞–π—Ç—É...")

    # –ö—Ä–æ–∫ 1: –û—á–∏—â–∞—î–º–æ –ø—Ä–æ–º—ñ–∂–Ω–∏–π —Ñ–∞–π–ª na_sait.csv
    try:
        logging.info("‚öôÔ∏è –ö—Ä–æ–∫ 1: –û—á–∏—â–∞—é —Ñ–∞–π–ª 'na_sait.csv'...")
        with open(intermediate_file_path, 'w', newline='', encoding='utf-8') as f:
            pass
        logging.info("‚úÖ –§–∞–π–ª 'na_sait.csv' —É—Å–ø—ñ—à–Ω–æ –æ—á–∏—â–µ–Ω–æ.")
    except Exception as e:
        logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ—á–∏—â–µ–Ω–Ω—ñ —Ñ–∞–π–ª—É {os.path.basename(intermediate_file_path)}: {e}")
        return

    # –ö—Ä–æ–∫ 2: –ö–æ–ø—ñ—é—î–º–æ –∫–æ–ª–æ–Ω–∫–∏ 1, 23-30 —ñ–∑ zvedena.csv
    try:
        logging.info("‚öôÔ∏è –ö—Ä–æ–∫ 2: –ö–æ–ø—ñ—é—é –¥–∞–Ω—ñ –∑—ñ 'zvedena.csv'...")
        with open(source_file_path, 'r', newline='', encoding='utf-8') as infile, \
             open(intermediate_file_path, 'w', newline='', encoding='utf-8') as outfile:
            
            reader = csv.reader(infile)
            writer = csv.writer(outfile)
            
            try:
                header = next(reader)
                columns_to_copy = [1] + list(range(23, min(31, len(header))))
                new_header = [header[i] for i in columns_to_copy]
                writer.writerow(new_header)
            except StopIteration:
                logging.error("‚ùå –ü–æ–º–∏–ª–∫–∞: –í—Ö—ñ–¥–Ω–∏–π —Ñ–∞–π–ª –ø–æ—Ä–æ–∂–Ω—ñ–π.")
                return
            
            copied_count = 0
            for i, row in enumerate(reader):
                selected_columns = [row[1]] if len(row) > 1 else [""]
                
                for j in range(23, 31):
                    if j < len(row):
                        selected_columns.append(row[j])
                    else:
                        selected_columns.append("")
                
                if len(selected_columns) > 1:
                    writer.writerow(selected_columns)
                    copied_count += 1
        
        logging.info(f"‚úÖ –ö—Ä–æ–∫ 2 –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –°–∫–æ–ø—ñ–π–æ–≤–∞–Ω–æ {copied_count} —Ä—è–¥–∫—ñ–≤.")
    except FileNotFoundError:
        logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞: –í—Ö—ñ–¥–Ω–∏–π —Ñ–∞–π–ª {os.path.basename(source_file_path)} –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return
    except Exception as e:
        logging.error(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –∫–æ–ø—ñ—é–≤–∞–Ω–Ω—è: {e}")
        return

    # –ö—Ä–æ–∫ 3: –î–æ–¥–∞—î–º–æ 4 –Ω–æ–≤—ñ –∫–æ–ª–æ–Ω–∫–∏ –∑ –Ω–∞–∑–≤–∞–º–∏
    try:
        logging.info("‚öôÔ∏è –ö—Ä–æ–∫ 3: –î–æ–¥–∞—é 4 –Ω–æ–≤—ñ –∫–æ–ª–æ–Ω–∫–∏...")
        with open(intermediate_file_path, 'r', newline='', encoding='utf-8') as infile:
            reader = csv.reader(infile)
            header = next(reader)
            rows = list(reader)
        
        new_header = header + ["sale_price", "sale_price_dates_from", "sale_price_dates_to", "–ó–Ω–∏–∂–∫–∞%"]
        
        with open(intermediate_file_path, 'w', newline='', encoding='utf-8') as outfile:
            writer = csv.writer(outfile)
            writer.writerow(new_header)
            for row in rows:
                row += [""] * 4
                writer.writerow(row)
        
        logging.info(f"‚úÖ –ö—Ä–æ–∫ 3 –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –î–æ–¥–∞–Ω–æ 4 –Ω–æ–≤—ñ –∫–æ–ª–æ–Ω–∫–∏. –†—è–¥–∫—ñ–≤ —É —Ñ–∞–π–ª—ñ: {len(rows)}",)
    except Exception as e:
        logging.error(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –¥–æ–¥–∞–≤–∞–Ω–Ω—è –∫–æ–ª–æ–Ω–æ–∫: {e}")
        return

    # –ö—Ä–æ–∫ 4: –í–∏–¥–∞–ª—è—î–º–æ –≤—Å—ñ —Ä—è–¥–∫–∏, –¥–µ –≤ –∫–æ–ª–æ–Ω—Ü—ñ –∑ —ñ–Ω–¥–µ–∫—Å–æ–º 3 —Å—Ç–æ—ó—Ç—å "0"
    try:
        logging.info("‚öôÔ∏è –ö—Ä–æ–∫ 4: –í–∏–¥–∞–ª—è—é —Ä—è–¥–∫–∏ –∑ –Ω—É–ª—å–æ–≤–∏–º–∏ –∑–Ω–∞—á–µ–Ω–Ω—è–º–∏...")
        with open(intermediate_file_path, 'r', newline='', encoding='utf-8') as infile:
            reader = csv.reader(infile)
            header = next(reader)
            rows = list(reader)

        original_count = len(rows)
        filtered_rows = [row for row in rows if row[3] != "0"]
        deleted_count = original_count - len(filtered_rows)

        with open(intermediate_file_path, 'w', newline='', encoding='utf-8') as outfile:
            writer = csv.writer(outfile)
            writer.writerow(header)
            writer.writerows(filtered_rows)
        
        logging.info(f"‚úÖ –ö—Ä–æ–∫ 4 –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –í–∏–¥–∞–ª–µ–Ω–æ {deleted_count} —Ä—è–¥–∫—ñ–≤. –ó–∞–ª–∏—à–∏–ª–æ—Å—å {len(filtered_rows)}.")
    except Exception as e:
        logging.error(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –≤–∏–¥–∞–ª–µ–Ω–Ω—è —Ä—è–¥–∫—ñ–≤: {e}")
        return

    # –ö—Ä–æ–∫ 5: –ó–∞–ø–æ–≤–Ω—é—î–º–æ –∫–æ–ª–æ–Ω–∫—É –∑ —ñ–Ω–¥–µ–∫—Å–æ–º 12 —Ä–∞–Ω–¥–æ–º–Ω–∏–º–∏ –∑–Ω–∞—á–µ–Ω–Ω—è–º–∏
    try:
        logging.info("‚öôÔ∏è –ö—Ä–æ–∫ 5: –ó–∞–ø–æ–≤–Ω—é—é –∫–æ–ª–æ–Ω–∫—É 12 —Ä–∞–Ω–¥–æ–º–Ω–∏–º–∏ –∑–Ω–∞—á–µ–Ω–Ω—è–º–∏...")
        with open(intermediate_file_path, 'r', newline='', encoding='utf-8') as infile:
            reader = csv.reader(infile)
            header = next(reader)
            rows = list(reader)
        
        random_choices = [0, 2, 3, 5]
        weights = [94, 3, 2, 1]
        
        updated_count = 0
        for row in rows:
            try:
                if len(row) > 2 and float(row[1]) > 0 and float(row[2].replace(',', '.')) > 800:
                    random_value = random.choices(random_choices, weights=weights, k=1)[0]
                    row[12] = str(random_value)
                    if random_value > 0:
                        updated_count += 1
            except (ValueError, IndexError):
                continue
        
        with open(intermediate_file_path, 'w', newline='', encoding='utf-8') as outfile:
            writer = csv.writer(outfile)
            writer.writerow(header)
            writer.writerows(rows)
            
        logging.info(f"‚úÖ –ö—Ä–æ–∫ 5 –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –£—Å–ø—ñ—à–Ω–æ –∑–∞–ø–æ–≤–Ω–µ–Ω–æ {updated_count} —Ä—è–¥–∫—ñ–≤.")
    except Exception as e:
        logging.error(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –∑–∞–ø–æ–≤–Ω–µ–Ω–Ω—è: {e}")
        return

    # –ö—Ä–æ–∫ 6: –ó–∞–ø–æ–≤–Ω—é—î–º–æ –∫–æ–ª–æ–Ω–∫—É –∑ —ñ–Ω–¥–µ–∫—Å–æ–º 9 –∑–∞ —Ñ–æ—Ä–º—É–ª–æ—é
    try:
        logging.info("‚öôÔ∏è –ö—Ä–æ–∫ 6: –ó–∞–ø–æ–≤–Ω—é—é –∫–æ–ª–æ–Ω–∫—É 9 –∑–∞ —Ñ–æ—Ä–º—É–ª–æ—é...")
        with open(intermediate_file_path, 'r', newline='', encoding='utf-8') as infile:
            reader = csv.reader(infile)
            header = next(reader)
            rows = list(reader)

        updated_count = 0
        for row in rows:
            try:
                c_val = float(row[2].replace(',', '.') if row[2] else 0)
                m_val = float(row[12]) if row[12] else 0
                
                if m_val > 0:
                    result = round(c_val * (100 - m_val) / 100, 0)
                    row[9] = str(int(result))
                    updated_count += 1
                else:
                    row[9] = ""
            except (ValueError, IndexError):
                row[9] = ""
                continue
        
        with open(intermediate_file_path, 'w', newline='', encoding='utf-8') as outfile:
            writer = csv.writer(outfile)
            writer.writerow(header)
            writer.writerows(rows)
            
        logging.info(f"‚úÖ –ö—Ä–æ–∫ 6 –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –ó–∞–ø–æ–≤–Ω–µ–Ω–æ {updated_count} —Ä—è–¥–∫—ñ–≤.")
    except Exception as e:
        logging.error(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –∑–∞–ø–æ–≤–Ω–µ–Ω–Ω—è –∫–æ–ª–æ–Ω–∫–∏ 9: {e}")
        return

    # –ö—Ä–æ–∫ 7: –í–∏–¥–∞–ª—è—î–º–æ —Ä—è–¥–∫–∏, –¥–µ –∫–æ–ª–æ–Ω–∫–∞ 9 –ø—É—Å—Ç–∞, –∞ 4 —Ç–∞ 5 –¥–æ—Ä—ñ–≤–Ω—é—é—Ç—å "0"
    try:
        logging.info("‚öôÔ∏è –ö—Ä–æ–∫ 7: –í–∏–¥–∞–ª—è—é —Ä—è–¥–∫–∏, –¥–µ –∫–æ–ª–æ–Ω–∫–∞ 9 –ø—É—Å—Ç–∞, –∞ 4 —ñ 5 –¥–æ—Ä—ñ–≤–Ω—é—é—Ç—å '0'...")
        with open(intermediate_file_path, 'r', newline='', encoding='utf-8') as infile:
            reader = csv.reader(infile)
            header = next(reader)
            rows = list(reader)
        
        original_count = len(rows)
        
        filtered_rows = []
        for row in rows:
            if not (row[9] == "" and row[4] == "0" and row[5] == "0"):
                filtered_rows.append(row)
        
        deleted_count = original_count - len(filtered_rows)

        with open(intermediate_file_path, 'w', newline='', encoding='utf-8') as outfile:
            writer = csv.writer(outfile)
            writer.writerow(header)
            writer.writerows(filtered_rows)

        logging.info(f"‚úÖ –ö—Ä–æ–∫ 7 –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –í–∏–¥–∞–ª–µ–Ω–æ {deleted_count} —Ä—è–¥–∫—ñ–≤. –ó–∞–ª–∏—à–∏–ª–æ—Å—å {len(filtered_rows)}.")
    except Exception as e:
        logging.error(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –≤–∏–¥–∞–ª–µ–Ω–Ω—è —Ä—è–¥–∫—ñ–≤: {e}")
        return

    # –ö—Ä–æ–∫ 8: –î–æ–¥–∞—î–º–æ –¥–∞—Ç–∏ –≤ –∫–æ–ª–æ–Ω–∫–∏ 10 —Ç–∞ 11
    try:
        logging.info("‚öôÔ∏è –ö—Ä–æ–∫ 8: –î–æ–¥–∞—é –¥–∞—Ç–∏ –≤ –∫–æ–ª–æ–Ω–∫–∏ 10 —Ç–∞ 11...")
        with open(intermediate_file_path, 'r', newline='', encoding='utf-8') as infile:
            reader = csv.reader(infile)
            header = next(reader)
            rows = list(reader)

        today = datetime.now()
        seven_days_later = today + timedelta(days=7)
        
        today_formatted = today.strftime("%Y-%m-%dT00:00:00")
        seven_days_later_formatted = seven_days_later.strftime("%Y-%m-%dT00:00:00")
        
        updated_count = 0
        for row in rows:
            try:
                if len(row) > 12 and row[12] and float(row[12]) > 0:
                    if len(row) > 10:
                        row[10] = today_formatted
                    if len(row) > 11:
                        row[11] = seven_days_later_formatted
                    updated_count += 1
            except (ValueError, IndexError):
                continue

        with open(intermediate_file_path, 'w', newline='', encoding='utf-8') as outfile:
            writer = csv.writer(outfile)
            writer.writerow(header)
            writer.writerows(rows)
        
        logging.info(f"‚úÖ –ö—Ä–æ–∫ 8 –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –î–∞—Ç–∏ –¥–æ–¥–∞–Ω–æ –¥–æ {updated_count} —Ä—è–¥–∫—ñ–≤.")
    except Exception as e:
        logging.error(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –¥–æ–¥–∞–≤–∞–Ω–Ω—è –¥–∞—Ç: {e}")
        return
        
   # –ö—Ä–æ–∫ 9: –†–æ–∑–¥—ñ–ª—è—î–º–æ –¥–∞–Ω—ñ –Ω–∞ –¥–≤–∞ –≤–∏—Ö—ñ–¥–Ω—ñ —Ñ–∞–π–ª–∏
    try:
        logging.info("‚öôÔ∏è –ö—Ä–æ–∫ 9: –°—Ç–≤–æ—Ä—é—é –¥–≤–∞ –æ–∫—Ä–µ–º—ñ —Ñ–∞–π–ª–∏ –¥–ª—è –æ–Ω–æ–≤–ª–µ–Ω–Ω—è...")
        
        source_file_path = os.path.join(base_dir, "csv", "process", "na_sait.csv")
        zalishky_output_path = os.path.join(base_dir, "csv", "output", "zalishky.csv")
        akcii_output_path = os.path.join(base_dir, "csv", "output", "akcii.csv")
        
        # 9.1 –û—á–∏—â–∞—î–º–æ –≤–∏—Ö—ñ–¥–Ω—ñ —Ñ–∞–π–ª–∏
        with open(zalishky_output_path, 'w', newline='', encoding='utf-8') as f:
            pass
        with open(akcii_output_path, 'w', newline='', encoding='utf-8') as f:
            pass

        # 9.2 –ö–æ–ø—ñ—é—î–º–æ –¥–∞–Ω—ñ –≤ –¥–≤–∞ –æ–∫—Ä–µ–º—ñ —Ñ–∞–π–ª–∏
        with open(source_file_path, 'r', newline='', encoding='utf-8') as infile:
            reader = csv.reader(infile)
            
            # –í–∏–∑–Ω–∞—á–∞—î–º–æ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Ñ–∞–π–ª—É
            zalishky_cols = [0, 1, 2] # sku, stock_quantity, regular_price
            akcii_cols = [0, 9, 10, 11] # sku, sale_price, sale_price_dates_from, sale_price_dates_to

            # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –Ω–æ–≤–∏—Ö –∑–∞–≥–æ–ª–æ–≤–∫—ñ–≤
            try:
                header = next(reader)
            except StopIteration:
                logging.error("‚ùå –ü–æ–º–∏–ª–∫–∞: –í—Ö—ñ–¥–Ω–∏–π —Ñ–∞–π–ª 'na_sait.csv' –ø–æ—Ä–æ–∂–Ω—ñ–π.")
                return

            zalishky_header = [header[i] for i in zalishky_cols]
            akcii_header = [header[i] for i in akcii_cols]

            with open(zalishky_output_path, 'w', newline='', encoding='utf-8') as zalishky_outfile:
                zalishky_writer = csv.writer(zalishky_outfile)
                zalishky_writer.writerow(zalishky_header)
                
                with open(akcii_output_path, 'w', newline='', encoding='utf-8') as akcii_outfile:
                    akcii_writer = csv.writer(akcii_outfile)
                    akcii_writer.writerow(akcii_header)

                    copied_zalishky_count = 0
                    copied_akcii_count = 0
                    
                    for row in reader:
                        # –ö–æ–ø—ñ—é—î–º–æ –¥–∞–Ω—ñ –≤ —Ñ–∞–π–ª –∑–∞–ª–∏—à–∫—ñ–≤
                        zalishky_row = [row[i] for i in zalishky_cols]
                        zalishky_writer.writerow(zalishky_row)
                        copied_zalishky_count += 1
                        
                        # –ö–æ–ø—ñ—é—î–º–æ –¥–∞–Ω—ñ –≤ —Ñ–∞–π–ª –∞–∫—Ü—ñ–π, —Ç—ñ–ª—å–∫–∏ —è–∫—â–æ —î –∑–Ω–∞—á–µ–Ω–Ω—è –≤ –∫–æ–ª–æ–Ω—Ü—ñ sale_price
                        if row[9]:
                            akcii_row = [row[i] for i in akcii_cols]
                            akcii_writer.writerow(akcii_row)
                            copied_akcii_count += 1
        
        logging.info(f"‚úÖ –ö—Ä–æ–∫ 9 –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –°—Ç–≤–æ—Ä–µ–Ω–æ 'zalishky.csv' ({copied_zalishky_count} —Ä—è–¥–∫—ñ–≤) —Ç–∞ 'akcii.csv' ({copied_akcii_count} —Ä—è–¥–∫—ñ–≤).")
    except FileNotFoundError:
        logging.error("‚ùå –ü–æ–º–∏–ª–∫–∞: –í—Ö—ñ–¥–Ω–∏–π —Ñ–∞–π–ª 'na_sait.csv' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return
    except Exception as e:
        logging.error(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –≤–∏—Ö—ñ–¥–Ω–∏—Ö —Ñ–∞–π–ª—ñ–≤: {e}")
        return

    logging.info("üéâ –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö –¥–ª—è —Å–∞–π—Ç—É –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    print("‚úÖ –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö –¥–ª—è —Å–∞–π—Ç—É –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")


def update_products():
    """
    –û–Ω–æ–≤–ª—é—î –¥–∞–Ω—ñ –ø—Ä–æ —Ç–æ–≤–∞—Ä –Ω–∞ —Å–∞–π—Ç—ñ, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—á–∏ API.
    –î–∞–Ω—ñ –±–µ—Ä—É—Ç—å—Å—è –∑ —Ñ–∞–π–ª—É zalishky_akcii.csv.
    """
    log_file_path = update_log()
    
    settings = load_settings()
    if not settings:
        log_message("‚ùå –ù–µ–º–æ–∂–ª–∏–≤–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è. –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ —Ñ–∞–π–ª.", log_file_path)
        print("‚ùå –ù–µ–º–æ–∂–ª–∏–≤–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è. –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ —Ñ–∞–π–ª.")
        return
        
    source_file_path = "/var/www/scripts/update/csv/output/zalishky_akcii.csv"
    
    url = settings.get("url")
    consumer_key = settings.get("consumer_key")
    consumer_secret = settings.get("consumer_secret")
    
    if not url or not consumer_key or not consumer_secret:
        error_msg = "URL –∞–±–æ –∫–ª—é—á—ñ (consumer_key, consumer_secret) –≤—ñ–¥—Å—É—Ç–Ω—ñ –≤ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è—Ö."
        log_message(f"‚ùå {error_msg}", log_file_path)
        print(f"‚ùå {error_msg}")
        return

    api_url = f"{url}/wp-json/wc/v3/products/batch"

    start_time = time.time()
    total_items = 0
    updated_count = 0
    error_count = 0

    log_message("üöÄ –ü–æ—á–∞—Ç–æ–∫ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è —Ç–æ–≤–∞—Ä—ñ–≤ —á–µ—Ä–µ–∑ API.", log_file_path)

    try:
        with open(source_file_path, 'r', newline='', encoding='utf-8') as infile:
            reader = csv.DictReader(infile)
            data_to_update = list(reader)
            total_items = len(data_to_update)

            log_message(f"üîé –ó–Ω–∞–π–¥–µ–Ω–æ {total_items} —Ç–æ–≤–∞—Ä—ñ–≤ –¥–ª—è –æ–Ω–æ–≤–ª–µ–Ω–Ω—è.", log_file_path)

            payloads = []
            for row in data_to_update:
                product_id = row.get('id')
                
                if not product_id:
                    log_message(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ —Ç–æ–≤–∞—Ä: –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ ID.", log_file_path)
                    continue

                regular_price = row.get('regular_price')
                sale_price = row.get('sale_price')
                stock_quantity = row.get('stock')
                date_on_sale_from = row.get('date_on_sale_from')
                date_on_sale_to = row.get('date_on_sale_to')
                
                # –ü–µ—Ä–µ—Ç–≤–æ—Ä—é—î–º–æ –ø–æ—Ä–æ–∂–Ω—ñ —Ä—è–¥–∫–∏ —Ü—ñ–Ω –Ω–∞ None
                if not regular_price:
                    regular_price = None
                
                if not sale_price:
                    sale_price = None
                    # –Ø–∫—â–æ –∞–∫—Ü—ñ–π–Ω–∞ —Ü—ñ–Ω–∞ –≤—ñ–¥—Å—É—Ç–Ω—è, —Ç–∞–∫–æ–∂ –≤–∏–¥–∞–ª—è—î–º–æ –¥–∞—Ç–∏ –∞–∫—Ü—ñ—ó
                    date_on_sale_from = None
                    date_on_sale_to = None
                
                log_message(f"üîç –ì–æ—Ç—É—î–º–æ —Ç–æ–≤–∞—Ä ID {product_id}. –¶—ñ–Ω–∞: {regular_price} -> {sale_price}. –ó–∞–ª–∏—à–æ–∫: {stock_quantity}. –î–∞—Ç–∏: {date_on_sale_from} - {date_on_sale_to}.", log_file_path)

                payload = {
                    "id": product_id,
                    "regular_price": regular_price,
                    "sale_price": sale_price,
                    "stock_quantity": stock_quantity,
                    "date_on_sale_from": date_on_sale_from,
                    "date_on_sale_to": date_on_sale_to
                }
                payloads.append(payload)
            
            response = requests.post(api_url, json={"update": payloads}, auth=(consumer_key, consumer_secret))
            response.raise_for_status()

            result = response.json()
            if 'update' in result:
                updated_count = len(result['update'])
                error_count = len(result.get('errors', []))
                for error in result.get('errors', []):
                    error_msg = f"‚ùå –ü–æ–º–∏–ª–∫–∞ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è: {error.get('message', '–ù–µ–≤—ñ–¥–æ–º–∞ –ø–æ–º–∏–ª–∫–∞')}"
                    log_message(error_msg, log_file_path)
                    print(error_msg)

            status_message = f"‚úÖ –û–±—Ä–æ–±–ª–µ–Ω–æ {total_items} —Ç–æ–≤–∞—Ä—ñ–≤."
            log_message(status_message, log_file_path)
            print(status_message)
            
    except FileNotFoundError:
        error_msg = f"‚ùå –ü–æ–º–∏–ª–∫–∞: –§–∞–π–ª '{source_file_path}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ."
        print(error_msg)
        log_message(error_msg, log_file_path)
        error_count += total_items
    except requests.exceptions.RequestException as e:
        error_msg = f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑'—î–¥–Ω–∞–Ω–Ω—è –∞–±–æ –∑–∞–ø–∏—Ç—É: {e}"
        print(error_msg)
        log_message(error_msg, log_file_path)
        error_count += total_items
    except Exception as e:
        error_msg = f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –Ω–µ–≤—ñ–¥–æ–º–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è: {e}"
        print(error_msg)
        log_message(error_msg, log_file_path)
        error_count += total_items
    finally:
        end_time = time.time()
        elapsed_time = int(end_time - start_time)
        
        print(f"üéâ –û–Ω–æ–≤–ª–µ–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –û–Ω–æ–≤–ª–µ–Ω–æ {updated_count} —Ç–æ–≤–∞—Ä—ñ–≤ –∑–∞ {elapsed_time} —Å–µ–∫.")
        if error_count > 0:
            print(f"‚ö†Ô∏è –ó–∞–≤–µ—Ä—à–µ–Ω–æ –∑ {error_count} –ø–æ–º–∏–ª–∫–∞–º–∏. –î–µ—Ç–∞–ª—å–Ω—ñ—à–µ –≤ –ª–æ–≥-—Ñ–∞–π–ª—ñ.")
        
        log_message(f"--- –ü—ñ–¥—Å—É–º–æ–∫ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è ---", log_file_path)
        log_message(f"–°—Ç–∞—Ç—É—Å: {'–£—Å–ø—ñ—à–Ω–æ' if error_count == 0 else '–ó–∞–≤–µ—Ä—à–µ–Ω–æ –∑ –ø–æ–º–∏–ª–∫–∞–º–∏'}", log_file_path)
        log_message(f"–ö—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–æ–≤–∞—Ä—ñ–≤: {updated_count} –∑ {total_items}", log_file_path)
        log_message(f"–¢—Ä–∏–≤–∞–ª—ñ—Å—Ç—å: {elapsed_time} —Å–µ–∫.", log_file_path)
        if error_count > 0:
            log_message(f"–ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø–æ–º–∏–ª–æ–∫: {error_count}. –î–µ—Ç–∞–ª—å–Ω—ñ –ø–æ–º–∏–ª–∫–∏ –¥–∏–≤—ñ—Ç—å—Å—è –≤–∏—â–µ.", log_file_path)