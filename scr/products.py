import csv
import json
import os
import time
import requests
import shutil
import re
import pandas as pd
import random # –ù–æ–≤–∏–π —ñ–º–ø–æ—Ä—Ç
from scr.updater import get_wc_api
from datetime import datetime, timedelta

def load_settings():
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó –∑ settings.json
    """
    config_path = os.path.join(os.path.dirname(__file__), "..", "config", "settings.json")
    try:
        with open(config_path, "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: —Ñ–∞–π–ª –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∑–∞ —à–ª—è—Ö–æ–º: {config_path}")
        return None
    except json.JSONDecodeError:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: —Ñ–∞–π–ª –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó –ø–æ—à–∫–æ–¥–∂–µ–Ω–∏–π: {config_path}")
        return None

def setup_log_file():
    """
    –ü–µ—Ä–µ–≤—ñ—Ä—è—î –Ω–∞—è–≤–Ω—ñ—Å—Ç—å logs.log, –ø–µ—Ä–µ–π–º–µ–Ω–æ–≤—É—î –π–æ–≥–æ, —è–∫—â–æ —ñ—Å–Ω—É—î,
    —Ç–∞ –ø–æ–≤–µ—Ä—Ç–∞—î —à–ª—è—Ö –¥–æ –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª—É.
    """
    log_dir = os.path.join(os.path.dirname(__file__), "..", "logs")
    os.makedirs(log_dir, exist_ok=True)
    
    current_log_path = os.path.join(log_dir, "logs.log")
    
    if os.path.exists(current_log_path):
        timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        new_log_path = os.path.join(log_dir, f"logs_{timestamp}.log")
        try:
            os.rename(current_log_path, new_log_path)
            print(f"‚úÖ –°—Ç–∞—Ä–∏–π –ª–æ–≥-—Ñ–∞–π–ª –ø–µ—Ä–µ–π–º–µ–Ω–æ–≤–∞–Ω–æ –Ω–∞ {os.path.basename(new_log_path)}")
        except OSError as e:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–π–º–µ–Ω—É–≤–∞–Ω–Ω—ñ –ª–æ–≥-—Ñ–∞–π–ª—É: {e}")
            return current_log_path

    return current_log_path

def log_message(message, log_file_path=os.path.join(os.path.dirname(__file__), "..", "logs", "logs.log")):
    """
    –ó–∞–ø–∏—Å—É—î –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –≤ –ª–æ–≥-—Ñ–∞–π–ª.
    """
    with open(log_file_path, "a", encoding="utf-8") as log_file:
        log_file.write(f"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} - {message}\n")


def export_products():
    """
    –ï–∫—Å–ø–æ—Ä—Ç —É—Å—ñ—Ö —Ç–æ–≤–∞—Ä—ñ–≤ —É CSV –ø–∞—á–∫–∞–º–∏ –ø–æ 100.
    """
    settings = load_settings()
    if not settings:
        return
        
    log_file_path = setup_log_file()
    
    csv_path = os.path.join(os.path.dirname(__file__), "..", "csv", "input", "zalishki.csv")
    
    headers = [
        "ID", "–ê—Ä—Ç–∏–∫—É–ª", "–ù–∞–∑–≤–∞", "–û–ø—É–±–ª—ñ–∫–æ–≤–∞–Ω–æ", "–ó–∞–ø–∞—Å–∏", "–ó–≤–∏—á–∞–π–Ω–∞ —Ü—ñ–Ω–∞", "–ö–∞—Ç–µ–≥–æ—Ä—ñ—ó",
        "–ú–µ—Ç–∞: shtrih_cod", "–ú–µ—Ç–∞: postachalnyk", "–ú–µ—Ç–∞: artykul_lutsk", "–ú–µ—Ç–∞: url_lutsk",
        "–ú–µ—Ç–∞: artykul_blizklub", "–ú–µ—Ç–∞: url_blizklub",
        "–ú–µ—Ç–∞: artykul_sexopt", "–ú–µ—Ç–∞: url_sexopt",
        "–ú–µ—Ç–∞: artykul_biorytm", "–ú–µ—Ç–∞: url_biorytm",
        "–ú–µ—Ç–∞: artykul_berdiansk"
    ]

    wcapi = get_wc_api()
    start_time = time.time()
    total_products = 0
    exported_count = 0
    errors = []

    log_message("üöÄ –ü–æ—á–∞—Ç–æ–∫ –µ–∫—Å–ø–æ—Ä—Ç—É —Ç–æ–≤–∞—Ä—ñ–≤.", log_file_path)

    try:
        response = wcapi.get("products", params={"per_page": 1})
        if response.status_code != 200:
            error_msg = f"–ü–æ–º–∏–ª–∫–∞ {response.status_code} –ø—Ä–∏ –ø—ñ–¥—Ä–∞—Ö—É–Ω–∫—É —Ç–æ–≤–∞—Ä—ñ–≤: {response.text}"
            print(f"‚ùå {error_msg}")
            log_message(f"‚ùå {error_msg}", log_file_path)
            errors.append(error_msg)
            return

        total_products = int(response.headers.get("X-WP-Total", 0))
        print(f"üîé –ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–æ–≤–∞—Ä—ñ–≤: {total_products}")
        log_message(f"üîé –ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–æ–≤–∞—Ä—ñ–≤: {total_products}", log_file_path)

        with open(csv_path, "w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow(headers)

            page = 1
            while exported_count < total_products:
                response = wcapi.get(
                    "products",
                    params={
                        "per_page": 100,
                        "page": page,
                        "_fields": "id,sku,name,status,stock_quantity,regular_price,categories,meta_data"
                    }
                )

                if response.status_code != 200:
                    error_msg = f"–ü–æ–º–∏–ª–∫–∞ {response.status_code} –Ω–∞ —Å—Ç–æ—Ä—ñ–Ω—Ü—ñ {page}: {response.text}"
                    print(f"‚ùå {error_msg}")
                    log_message(f"‚ùå {error_msg}", log_file_path)
                    errors.append(error_msg)
                    break

                products = response.json()
                if not products:
                    break

                for product in products:
                    product["meta_data_dict"] = {m["key"]: m["value"] for m in product.get("meta_data", [])}
                    row = [
                        product.get("id"),
                        product.get("sku"),
                        product.get("name"),
                        "yes" if product.get("status") == "publish" else "no",
                        product.get("stock_quantity"),
                        product.get("regular_price"),
                        ", ".join([cat["name"] for cat in product.get("categories", [])]),
                        product["meta_data_dict"].get("shtrih_cod", ""),
                        product["meta_data_dict"].get("postachalnyk", ""),
                        product["meta_data_dict"].get("artykul_lutsk", ""),
                        product["meta_data_dict"].get("url_lutsk", ""),
                        product["meta_data_dict"].get("artykul_blizklub", ""),
                        product["meta_data_dict"].get("url_blizklub", ""),
                        product["meta_data_dict"].get("artykul_sexopt", ""),
                        product["meta_data_dict"].get("url_sexopt", ""),
                        product["meta_data_dict"].get("artykul_biorytm", ""),
                        product["meta_data_dict"].get("url_biorytm", ""),
                        product["meta_data_dict"].get("artykul_berdiansk", "")
                    ]
                    writer.writerow(row)
                    exported_count += 1
                
                if exported_count % 100 == 0 or exported_count == total_products:
                    elapsed = int(time.time() - start_time)
                    status_message = f"‚úÖ –í–∏–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {exported_count} –∑ {total_products} ({elapsed} —Å–µ–∫)"
                    print(status_message)
                    log_message(status_message, log_file_path)

                page += 1
                time.sleep(1)

    except Exception as e:
        error_msg = f"–í–∏–Ω–∏–∫–ª–∞ –Ω–µ–≤—ñ–¥–æ–º–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –µ–∫—Å–ø–æ—Ä—Ç—É: {e}"
        print(f"‚ùå {error_msg}")
        log_message(f"‚ùå {error_msg}", log_file_path)
        errors.append(error_msg)
    finally:
        end_time = time.time()
        elapsed_time = int(end_time - start_time)
        
        print(f"üéâ –ï–∫—Å–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –í–∏–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {exported_count} –∑ {total_products} —Ç–æ–≤–∞—Ä—ñ–≤ –∑–∞ {elapsed_time} —Å–µ–∫.")
        if errors:
            print(f"‚ö†Ô∏è –ï–∫—Å–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–∏–≤—Å—è –∑ {len(errors)} –ø–æ–º–∏–ª–∫–∞–º–∏. –î–µ—Ç–∞–ª—ñ –≤ –ª–æ–≥-—Ñ–∞–π–ª—ñ.")
        
        log_message(f"--- –ü—ñ–¥—Å—É–º–æ–∫ –µ–∫—Å–ø–æ—Ä—Ç—É ---", log_file_path)
        log_message(f"–°—Ç–∞—Ç—É—Å: {'–£—Å–ø—ñ—à–Ω–æ' if not errors else '–ó–∞–≤–µ—Ä—à–µ–Ω–æ –∑ –ø–æ–º–∏–ª–∫–∞–º–∏'}", log_file_path)
        log_message(f"–ö—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–æ–≤–∞—Ä—ñ–≤: {exported_count} –∑ {total_products}", log_file_path)
        log_message(f"–¢—Ä–∏–≤–∞–ª—ñ—Å—Ç—å: {elapsed_time} —Å–µ–∫.", log_file_path)
        if errors:
            log_message(f"–ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø–æ–º–∏–ª–æ–∫: {len(errors)}", log_file_path)
            log_message("–ü–µ—Ä–µ–ª—ñ–∫ –ø–æ–º–∏–ª–æ–∫:", log_file_path)
            for err in errors:
                log_message(f"- {err}", log_file_path)


def check_exported_csv():
    """
    –ü–µ—Ä–µ–≤—ñ—Ä—è—î —ñ –æ—á–∏—â–∞—î –¥–∞–Ω—ñ –≤ –µ–∫—Å–ø–æ—Ä—Ç–æ–≤–∞–Ω–æ–º—É CSV —Ñ–∞–π–ª—ñ.
    """
    settings = load_settings()
    if not settings:
        return

    csv_path = os.path.join(os.path.dirname(__file__), "..", "csv", "input", "zalishki.csv")
    if not os.path.exists(csv_path):
        print("‚ùå –§–∞–π–ª –µ–∫—Å–ø–æ—Ä—Ç—É –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return

    log_file_path = os.path.join(os.path.dirname(__file__), "..", "logs", "logs.log")
    log_message("üîç –ü–æ—á–∞—Ç–æ–∫ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ –µ–∫—Å–ø–æ—Ä—Ç–æ–≤–∞–Ω–æ–≥–æ CSV.", log_file_path)

    temp_file_path = f"{csv_path}.temp"
    validation_errors = []
    processed_rows = []

    try:
        with open(csv_path, "r", newline="", encoding="utf-8") as infile:
            reader = csv.reader(infile)
            headers = next(reader)
            
            row_number = 1
            for row in reader:
                row_number += 1
                row_id = row[0] if len(row) > 0 else "–ù–µ–≤—ñ–¥–æ–º–∏–π ID"

                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ç–∞ –æ—á–∏—â–µ–Ω–Ω—è –∫–æ–ª–æ–Ω–∫–∏ 1 (ID)
                try:
                    int(row[0])
                except (ValueError, IndexError):
                    validation_errors.append(f"‚ùå –†—è–¥–æ–∫ {row_number}, ID {row_id}: –ö–æ–ª–æ–Ω–∫–∞ 1 (ID) –Ω–µ —î —Ü—ñ–ª–∏–º —á–∏—Å–ª–æ–º. –ó–Ω–∞—á–µ–Ω–Ω—è: '{row[0]}'")
                
                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ç–∞ –æ—á–∏—â–µ–Ω–Ω—è –∫–æ–ª–æ–Ω–∫–∏ 2 (–ê—Ä—Ç–∏–∫—É–ª)
                try:
                    int(row[1])
                except (ValueError, IndexError):
                    validation_errors.append(f"‚ùå –†—è–¥–æ–∫ {row_number}, ID {row_id}: –ö–æ–ª–æ–Ω–∫–∞ 2 (–ê—Ä—Ç–∏–∫—É–ª) –Ω–µ —î —Ü—ñ–ª–∏–º —á–∏—Å–ª–æ–º. –ó–Ω–∞—á–µ–Ω–Ω—è: '{row[1]}'")
                
                 # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∫–æ–ª–æ–Ω–∫–∏ 3 (–ù–∞–∑–≤–∞)
                if len(row) > 2 and not row[2].strip():
                    validation_errors.append(f"‚ùå –†—è–¥–æ–∫ {row_number}, ID {row_id}: –ö–æ–ª–æ–Ω–∫–∞ 3 (–ù–∞–∑–≤–∞) –Ω–µ –º–æ–∂–µ –±—É—Ç–∏ –ø—É—Å—Ç–æ—é.")

                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ç–∞ –æ—á–∏—â–µ–Ω–Ω—è –∫–æ–ª–æ–Ω–∫–∏ 4 (–û–ø—É–±–ª—ñ–∫–æ–≤–∞–Ω–æ)
                if len(row) > 3 and row[3].lower() not in ["yes", "no"]:
                    validation_errors.append(f"‚ùå –†—è–¥–æ–∫ {row_number}, ID {row_id}: –ö–æ–ª–æ–Ω–∫–∞ 4 (–û–ø—É–±–ª—ñ–∫–æ–≤–∞–Ω–æ) –æ—á—ñ–∫—É—î 'yes' –∞–±–æ 'no'. –ó–Ω–∞—á–µ–Ω–Ω—è: '{row[3]}'")
                
                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ç–∞ –æ—á–∏—â–µ–Ω–Ω—è –∫–æ–ª–æ–Ω–∫–∏ 5 (–ó–∞–ø–∞—Å–∏)
                if len(row) > 4:
                    if row[4] == "":
                        row[4] = "0"
                        log_message(f"‚ÑπÔ∏è –†—è–¥–æ–∫ {row_number}, ID {row_id}: –ö–æ–ª–æ–Ω–∫–∞ 5 (–ó–∞–ø–∞—Å–∏) –±—É–ª–∞ –ø—É—Å—Ç–æ—é, –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –∑–Ω–∞—á–µ–Ω–Ω—è '0'.", log_file_path)
                    try:
                        int(row[4])
                    except ValueError:
                        validation_errors.append(f"‚ùå –†—è–¥–æ–∫ {row_number}, ID {row_id}: –ö–æ–ª–æ–Ω–∫–∞ 5 (–ó–∞–ø–∞—Å–∏) –Ω–µ —î —Ü—ñ–ª–∏–º —á–∏—Å–ª–æ–º. –ó–Ω–∞—á–µ–Ω–Ω—è: '{row[4]}'")
                
                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ç–∞ –æ—á–∏—â–µ–Ω–Ω—è –∫–æ–ª–æ–Ω–∫–∏ 6 (–ó–≤–∏—á–∞–π–Ω–∞ —Ü—ñ–Ω–∞)
                try:
                    int(row[5])
                except (ValueError, IndexError):
                    validation_errors.append(f"‚ùå –†—è–¥–æ–∫ {row_number}, ID {row_id}: –ö–æ–ª–æ–Ω–∫–∞ 6 (–ó–≤–∏—á–∞–π–Ω–∞ —Ü—ñ–Ω–∞) –Ω–µ —î —Ü—ñ–ª–∏–º —á–∏—Å–ª–æ–º. –ó–Ω–∞—á–µ–Ω–Ω—è: '{row[5]}'")
                
                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∫–æ–ª–æ–Ω–∫–∏ 7 (–ö–∞—Ç–µ–≥–æ—Ä—ñ—ó)
                if len(row) > 6 and not row[6].strip():
                    validation_errors.append(f"‚ùå –†—è–¥–æ–∫ {row_number}, ID {row_id}: –ö–æ–ª–æ–Ω–∫–∞ 7 (–ö–∞—Ç–µ–≥–æ—Ä—ñ—ó) –Ω–µ –º–æ–∂–µ –±—É—Ç–∏ –ø—É—Å—Ç–æ—é.")

                # –û—á–∏—â–µ–Ω–Ω—è –∫–æ–ª–æ–Ω–∫–∏ 9 (–ü–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫)
                if len(row) > 8:
                    row[8] = row[8].replace("[", "").replace("'", "").replace("]", "")
                
                # –û—á–∏—â–µ–Ω–Ω—è –∫–æ–ª–æ–Ω–æ–∫ 11, 13, 15, 17
                for i in [10, 12, 14, 16]:
                    if len(row) > i:
                        row[i] = row[i].replace("{'title': '', 'url': '", "").replace("', 'target': ''}", "")
                
                processed_rows.append(row)
    
    except Exception as e:
        print(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ —Ñ–∞–π–ª—É: {e}")
        log_message(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ —Ñ–∞–π–ª—É: {e}", log_file_path)
        return

    # –ó–∞–ø–∏—Å –≤—ñ–¥—Å–æ—Ä—Ç–æ–≤–∞–Ω–æ–≥–æ —Ç–∞ –æ—á–∏—â–µ–Ω–æ–≥–æ —Ñ–∞–π–ª—É
    print("‚è≥ –°–æ—Ä—Ç—É—é –¥–∞–Ω—ñ —Ç–∞ –∑–∞–ø–∏—Å—É—é –æ–Ω–æ–≤–ª–µ–Ω–∏–π —Ñ–∞–π–ª...")
    try:
        processed_rows.sort(key=lambda x: int(x[0]))
    except (ValueError, IndexError) as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ —Å–æ—Ä—Ç—É–≤–∞–Ω–Ω—è: –Ω–µ–º–æ–∂–ª–∏–≤–æ –ø–µ—Ä–µ—Ç–≤–æ—Ä–∏—Ç–∏ ID –Ω–∞ —á–∏—Å–ª–æ. {e}")
        log_message(f"‚ùå –ü–æ–º–∏–ª–∫–∞ —Å–æ—Ä—Ç—É–≤–∞–Ω–Ω—è: –Ω–µ–º–æ–∂–ª–∏–≤–æ –ø–µ—Ä–µ—Ç–≤–æ—Ä–∏—Ç–∏ ID –Ω–∞ —á–∏—Å–ª–æ. {e}", log_file_path)

    with open(temp_file_path, "w", newline="", encoding="utf-8") as outfile:
        writer = csv.writer(outfile)
        writer.writerow(headers)
        writer.writerows(processed_rows)

    os.replace(temp_file_path, csv_path)

    # –õ–æ–≥—É–≤–∞–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
    log_message("üéâ –ü–µ—Ä–µ–≤—ñ—Ä–∫—É —Ç–∞ –æ—á–∏—â–µ–Ω–Ω—è —Ñ–∞–π–ª—É –∑–∞–≤–µ—Ä—à–µ–Ω–æ.", log_file_path)
    if validation_errors:
        log_message(f"‚ö†Ô∏è –ó–Ω–∞–π–¥–µ–Ω–æ {len(validation_errors)} –ø–æ–º–∏–ª–æ–∫:", log_file_path)
        for error in validation_errors:
            log_message(error, log_file_path)
        print(f"‚ö†Ô∏è –ó–Ω–∞–π–¥–µ–Ω–æ {len(validation_errors)} –ø–æ–º–∏–ª–æ–∫. –î–µ—Ç–∞–ª—ñ –≤ –ª–æ–≥-—Ñ–∞–π–ª—ñ.")
    else:
        log_message("‚úÖ –í—Å—ñ –¥–∞–Ω—ñ –∫–æ—Ä–µ–∫—Ç–Ω—ñ. –ü–æ–º–∏–ª–æ–∫ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.", log_file_path)
        print("‚úÖ –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞, –ø–æ–º–∏–ª–æ–∫ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")



def download_supplier_price_list(supplier_id):
    """
    –°–∫–∞—á—É—î –ø—Ä–∞–π—Å-–ª–∏—Å—Ç –≤—ñ–¥ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ –∑–∞ –π–æ–≥–æ ID.
    """
    settings = load_settings()
    if not settings:
        return
    
    supplier_info = settings.get("suppliers", {}).get(str(supplier_id))
    if not supplier_info:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ –∑ ID '{supplier_id}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return

    base_dir = os.path.join(os.path.dirname(__file__), "..")
    log_file_path = os.path.join(base_dir, settings.get("log_file_path"))
    
    url = supplier_info.get("download_url")
    csv_path = os.path.join(base_dir, supplier_info.get("csv_path"))
   
    log_message(f"‚è≥ –ó–∞–ø—É—Å–∫–∞—é –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –≤—ñ–¥ {supplier_id} (ID: {supplier_id}).", log_file_path)

    # –í–∏–¥–∞–ª–µ–Ω–Ω—è —Å—Ç–∞—Ä–æ–≥–æ —Ñ–∞–π–ª—É, —è–∫—â–æ –≤—ñ–Ω —ñ—Å–Ω—É—î
    if os.path.exists(csv_path):
        try:
            os.remove(csv_path)
            log_message(f"‚úÖ –°—Ç–∞—Ä–∏–π —Ñ–∞–π–ª {os.path.basename(csv_path)} —É—Å–ø—ñ—à–Ω–æ –≤–∏–¥–∞–ª–µ–Ω–æ.", log_file_path)
        except OSError as e:
            log_message(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –≤–∏–¥–∞–ª–µ–Ω–Ω—ñ —Å—Ç–∞—Ä–æ–≥–æ —Ñ–∞–π–ª—É: {e}", log_file_path)
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: {e}")
            return
    
    try:
        # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ñ–∞–π–ª—É
        with requests.get(url, stream=True) as r:
            r.raise_for_status()
            with open(csv_path, 'wb') as f:
                shutil.copyfileobj(r.raw, f)
        
        log_message(f"üéâ –ü—Ä–∞–π—Å-–ª–∏—Å—Ç –≤—ñ–¥ {supplier_id} —É—Å–ø—ñ—à–Ω–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ.", log_file_path)
        print(f"‚úÖ –ü—Ä–∞–π—Å-–ª–∏—Å—Ç –≤—ñ–¥ {supplier_id} —É—Å–ø—ñ—à–Ω–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ.")
    except requests.exceptions.RequestException as e:
        log_message(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ñ–∞–π–ª—É –≤—ñ–¥ {supplier_id}: {e}", log_file_path)
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ñ–∞–π–ª—É: {e}")


def process_supplier_1_price_list():
    """
    –û–±—Ä–æ–±–ª—è—î —Ç–∞ –æ—á–∏—â–∞—î –ø—Ä–∞–π—Å-–ª–∏—Å—Ç –≤—ñ–¥ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 1.
    """
    settings = load_settings()
    if not settings:
        return

    supplier_id = "1"
    supplier_info = settings.get("suppliers", {}).get(supplier_id)
    if not supplier_info:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ –∑ ID '{supplier_id}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return

    base_dir = os.path.join(os.path.dirname(__file__), "..")
    log_file_path = os.path.join(base_dir, settings.get("log_file_path"))
    csv_path = os.path.join(base_dir, supplier_info.get("csv_path"))
    delimiter = supplier_info.get("delimiter", ",")

    if not os.path.exists(csv_path):
        print(f"‚ùå –§–∞–π–ª –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –¥–ª—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {supplier_id} –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∑–∞ —à–ª—è—Ö–æ–º: {csv_path}")
        return

    log_message(f"‚öôÔ∏è –ó–∞–ø—É—Å–∫–∞—é –æ–±—Ä–æ–±–∫—É –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –¥–ª—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {supplier_id}.", log_file_path)

    # –°–ø–∏—Å–æ–∫ —Å–ª—ñ–≤ –¥–ª—è –≤–∏–¥–∞–ª–µ–Ω–Ω—è —Ä—è–¥–∫—ñ–≤
    words_to_filter_from_name = ["jos", "a-toys"]
    words_to_filter_from_brand = ["toyfa"]

    temp_file_path = f"{csv_path}.temp"
    processed_rows = []
    skipped_rows = 0
    total_rows = 0

    try:
        with open(csv_path, "r", newline="", encoding="utf-8") as infile:
            reader = csv.reader(infile, delimiter=delimiter)
            headers = next(reader)
            processed_rows.append(headers)
            
            row_number = 1
            for row in reader:
                row_number += 1
                total_rows += 1

                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∫–æ–ª–æ–Ω–∫–∏ 4 (—Ü—ñ–Ω–∞) –Ω–∞ –Ω–∞—è–≤–Ω—ñ—Å—Ç—å –ª—ñ—Ç–µ—Ä
                if len(row) > 3:
                    price_value = row[3]
                    if re.search(r'[a-zA-Z]', price_value):
                        log_message(f"üö´ –í–∏–¥–∞–ª–µ–Ω–æ —Ä—è–¥–æ–∫ {row_number} —á–µ—Ä–µ–∑ –Ω–∞—è–≤–Ω—ñ—Å—Ç—å –ª—ñ—Ç–µ—Ä —É –∫–æ–ª–æ–Ω—Ü—ñ 4 (—Ü—ñ–Ω–∞): '{price_value}'.", log_file_path)
                        skipped_rows += 1
                        continue

                # –§—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è –∑–∞ –∫–æ–ª–æ–Ω–∫–æ—é 3 (–Ω–∞–∑–≤–∞)
                if len(row) > 2:
                    product_name = row[2].lower()
                    if any(word in product_name for word in words_to_filter_from_name):
                        log_message(f"üö´ –í–∏–¥–∞–ª–µ–Ω–æ —Ä—è–¥–æ–∫ {row_number} —á–µ—Ä–µ–∑ –∑–∞–±–æ—Ä–æ–Ω–µ–Ω–µ —Å–ª–æ–≤–æ –≤ –Ω–∞–∑–≤—ñ ('{row[2]}').", log_file_path)
                        skipped_rows += 1
                        continue
                
                # –§—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è –∑–∞ –∫–æ–ª–æ–Ω–∫–æ—é 8 (–±—Ä–µ–Ω–¥)
                if len(row) > 7:
                    brand_name = row[7].lower()
                    if any(word in brand_name for word in words_to_filter_from_brand):
                        log_message(f"üö´ –í–∏–¥–∞–ª–µ–Ω–æ —Ä—è–¥–æ–∫ {row_number} —á–µ—Ä–µ–∑ –∑–∞–±–æ—Ä–æ–Ω–µ–Ω–µ —Å–ª–æ–≤–æ –≤ –±—Ä–µ–Ω–¥—ñ ('{row[7]}').", log_file_path)
                        skipped_rows += 1
                        continue

                # –ü–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è –∫–æ–ª–æ–Ω–∫–∏ 4 (—Ü—ñ–Ω–∞) –∑ float –Ω–∞ int
                if len(row) > 3 and row[3]:
                    try:
                        row[3] = str(int(float(row[3])))
                    except (ValueError, IndexError):
                        log_message(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –ø–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ü—ñ–Ω–∏ –≤ —Ä—è–¥–∫—É {row_number}. –ó–Ω–∞—á–µ–Ω–Ω—è: '{row[3]}'", log_file_path)
                
                # –ó–∞–º—ñ–Ω–∞ –∑–Ω–∞—á–µ–Ω–Ω—è –≤ –∫–æ–ª–æ–Ω—Ü—ñ 7 (–∫–∞—Ç–µ–≥–æ—Ä—ñ—è)
                if len(row) > 6 and row[6] == ">3":
                    row[6] = "4"
                    
                processed_rows.append(row)
    
    except Exception as e:
        log_message(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –æ–±—Ä–æ–±–∫–∏ —Ñ–∞–π–ª—É: {e}", log_file_path)
        print(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –æ–±—Ä–æ–±–∫–∏ —Ñ–∞–π–ª—É: {e}")
        return

    with open(temp_file_path, "w", newline="", encoding="utf-8") as outfile:
        writer = csv.writer(outfile, delimiter=delimiter)
        writer.writerows(processed_rows)

    os.replace(temp_file_path, csv_path)

    log_message(f"üéâ –û–±—Ä–æ–±–∫—É –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –¥–ª—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {supplier_id} –∑–∞–≤–µ—Ä—à–µ–Ω–æ.", log_file_path)
    log_message(f"--- –ü—ñ–¥—Å—É–º–æ–∫ –æ–±—Ä–æ–±–∫–∏: ---", log_file_path)
    log_message(f"üì¶ –í—Å—å–æ–≥–æ —Ä—è–¥–∫—ñ–≤ —É —Ñ–∞–π–ª—ñ: {total_rows}", log_file_path)
    log_message(f"üóëÔ∏è –í–∏–¥–∞–ª–µ–Ω–æ —Ä—è–¥–∫—ñ–≤: {skipped_rows}", log_file_path)
    log_message(f"‚úÖ –û–±—Ä–æ–±–ª–µ–Ω—ñ —Ä—è–¥–∫–∏: {len(processed_rows) - 1}", log_file_path)
    print("‚úÖ –û–±—Ä–æ–±–∫–∞ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –î–µ—Ç–∞–ª—ñ –≤ –ª–æ–≥-—Ñ–∞–π–ª—ñ.")



def process_supplier_2_price_list():
    """
    –û–±—Ä–æ–±–ª—è—î —Ç–∞ –æ—á–∏—â–∞—î –ø—Ä–∞–π—Å-–ª–∏—Å—Ç –≤—ñ–¥ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 2.
    """
    settings = load_settings()
    if not settings:
        return

    supplier_id = "2"
    supplier_info = settings.get("suppliers", {}).get(supplier_id)
    if not supplier_info:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ –∑ ID '{supplier_id}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return

    base_dir = os.path.join(os.path.dirname(__file__), "..")
    log_file_path = os.path.join(base_dir, settings.get("log_file_path"))
    csv_path = os.path.join(base_dir, supplier_info.get("csv_path"))
    delimiter = supplier_info.get("delimiter", ",")

    if not os.path.exists(csv_path):
        print(f"‚ùå –§–∞–π–ª –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –¥–ª—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {supplier_id} –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∑–∞ —à–ª—è—Ö–æ–º: {csv_path}")
        return

    log_message(f"‚öôÔ∏è –ó–∞–ø—É—Å–∫–∞—é –æ–±—Ä–æ–±–∫—É –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –¥–ª—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {supplier_id}.", log_file_path)

    temp_file_path = f"{csv_path}.temp"
    processed_rows = []
    skipped_rows = 0
    total_rows = 0
    modifications_count = 0

    try:
        with open(csv_path, "r", newline="", encoding="utf-8") as infile:
            reader = csv.reader(infile, delimiter=delimiter)
            headers = next(reader)
            processed_rows.append(headers)
            
            row_number = 1
            for row in reader:
                row_number += 1
                total_rows += 1

                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∫–æ–ª–æ–Ω–∫–∏ 5 (–≤–∞–ª—é—Ç–∞)
                if len(row) > 4:
                    currency_value = row[4].strip().upper()
                    if currency_value != "UAH":
                        log_message(f"üö´ –í–∏–¥–∞–ª–µ–Ω–æ —Ä—è–¥–æ–∫ {row_number} —á–µ—Ä–µ–∑ –Ω–µ–∫–æ—Ä–µ–∫—Ç–Ω—É –≤–∞–ª—é—Ç—É —É –∫–æ–ª–æ–Ω—Ü—ñ 5: '{row[4]}'.", log_file_path)
                        skipped_rows += 1
                        continue
                else:
                    log_message(f"üö´ –í–∏–¥–∞–ª–µ–Ω–æ —Ä—è–¥–æ–∫ {row_number} —á–µ—Ä–µ–∑ –≤—ñ–¥—Å—É—Ç–Ω—ñ—Å—Ç—å –∑–Ω–∞—á–µ–Ω–Ω—è —É –∫–æ–ª–æ–Ω—Ü—ñ 5 (–≤–∞–ª—é—Ç–∞).", log_file_path)
                    skipped_rows += 1
                    continue

                # –ü–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è –∫–æ–ª–æ–Ω–∫–∏ 4 (—Ü—ñ–Ω–∞) –∑ float –Ω–∞ int
                if len(row) > 3 and row[3]:
                    try:
                        row[3] = str(int(float(row[3])))
                    except (ValueError, IndexError):
                        log_message(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –ø–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ü—ñ–Ω–∏ –≤ —Ä—è–¥–∫—É {row_number}. –ó–Ω–∞—á–µ–Ω–Ω—è: '{row[3]}'", log_file_path)
                
                # –ó–∞–º—ñ–Ω–∞ –∑–Ω–∞—á–µ–Ω–Ω—è –≤ –∫–æ–ª–æ–Ω—Ü—ñ 7 (–∫–∞—Ç–µ–≥–æ—Ä—ñ—è)
                if len(row) > 6 and row[6] == ">3":
                    row[6] = "4"
                    modifications_count += 1

                processed_rows.append(row)
    
    except Exception as e:
        log_message(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –æ–±—Ä–æ–±–∫–∏ —Ñ–∞–π–ª—É: {e}", log_file_path)
        print(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –æ–±—Ä–æ–±–∫–∏ —Ñ–∞–π–ª—É: {e}")
        return

    with open(temp_file_path, "w", newline="", encoding="utf-8") as outfile:
        writer = csv.writer(outfile, delimiter=delimiter)
        writer.writerows(processed_rows)

    os.replace(temp_file_path, csv_path)

    log_message(f"üéâ –û–±—Ä–æ–±–∫—É –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –¥–ª—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {supplier_id} –∑–∞–≤–µ—Ä—à–µ–Ω–æ.", log_file_path)
    log_message(f"--- –ü—ñ–¥—Å—É–º–æ–∫ –æ–±—Ä–æ–±–∫–∏: ---", log_file_path)
    log_message(f"üì¶ –í—Å—å–æ–≥–æ —Ä—è–¥–∫—ñ–≤ —É —Ñ–∞–π–ª—ñ: {total_rows}", log_file_path)
    log_message(f"üóëÔ∏è –í–∏–¥–∞–ª–µ–Ω–æ —Ä—è–¥–∫—ñ–≤: {skipped_rows}", log_file_path)
    log_message(f"üìù –ó–º—ñ–Ω–µ–Ω–æ –∫–∞—Ç–µ–≥–æ—Ä—ñ–π: {modifications_count}", log_file_path)
    log_message(f"‚úÖ –û–±—Ä–æ–±–ª–µ–Ω—ñ —Ä—è–¥–∫–∏: {len(processed_rows) - 1}", log_file_path)
    print("‚úÖ –û–±—Ä–æ–±–∫–∞ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –î–µ—Ç–∞–ª—ñ –≤ –ª–æ–≥-—Ñ–∞–π–ª—ñ.")


def process_supplier_3_price_list():
    """
    –û–±—Ä–æ–±–ª—è—î —Ç–∞ –∫–æ–Ω–≤–µ—Ä—Ç—É—î –ø—Ä–∞–π—Å-–ª–∏—Å—Ç –≤—ñ–¥ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 3 (—Ñ–æ—Ä–º–∞—Ç .xls),
    –∞ –ø–æ—Ç—ñ–º —Ñ—ñ–ª—å—Ç—Ä—É—î –¥–∞–Ω—ñ.
    """
    settings = load_settings()
    if not settings:
        return

    supplier_id = "3"
    supplier_info = settings.get("suppliers", {}).get(supplier_id)
    if not supplier_info:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ –∑ ID '{supplier_id}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return

    base_dir = os.path.join(os.path.dirname(__file__), "..")
    log_file_path = os.path.join(base_dir, settings.get("log_file_path"))
    
    # –®–ª—è—Ö –¥–æ –≤—Ö—ñ–¥–Ω–æ–≥–æ XLS-—Ñ–∞–π–ª—É
    xls_path = os.path.join(base_dir, supplier_info.get("csv_path"))
    
    # –®–ª—è—Ö –¥–æ –≤–∏—Ö—ñ–¥–Ω–æ–≥–æ CSV-—Ñ–∞–π–ª—É
    csv_name = os.path.join(base_dir, supplier_info.get("csv_name"))

    log_message(f"‚öôÔ∏è –ó–∞–ø—É—Å–∫–∞—é –æ–±—Ä–æ–±–∫—É –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –¥–ª—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {supplier_id}...", log_file_path)

    # 1. –í–∏–¥–∞–ª–µ–Ω–Ω—è —Å—Ç–∞—Ä–æ–≥–æ CSV-—Ñ–∞–π–ª—É
    if os.path.exists(csv_name):
        try:
            os.remove(csv_name)
            log_message(f"‚úÖ –°—Ç–∞—Ä–∏–π —Ñ–∞–π–ª {os.path.basename(csv_name)} —É—Å–ø—ñ—à–Ω–æ –≤–∏–¥–∞–ª–µ–Ω–æ.", log_file_path)
        except OSError as e:
            log_message(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –≤–∏–¥–∞–ª–µ–Ω–Ω—ñ —Å—Ç–∞—Ä–æ–≥–æ CSV-—Ñ–∞–π–ª—É: {e}", log_file_path)
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: {e}")
            return

    # 2. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è XLS –≤ CSV
    if not os.path.exists(xls_path):
        log_message(f"‚ùå –§–∞–π–ª .xls –¥–ª—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {supplier_id} –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∑–∞ —à–ª—è—Ö–æ–º: {xls_path}", log_file_path)
        print("‚ùå –§–∞–π–ª .xls –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return

    try:
        df = pd.read_excel(xls_path)
        df.to_csv(csv_name, index=False, encoding="utf-8")
        
        log_message(f"üéâ –§–∞–π–ª .xls –¥–ª—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {supplier_id} —É—Å–ø—ñ—à–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–æ–≤–∞–Ω–æ –≤ {os.path.basename(csv_name)}.", log_file_path)
        print("‚úÖ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")

    except Exception as e:
        log_message(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—ó —Ñ–∞–π–ª—É: {e}", log_file_path)
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—ó: {e}")
        return

    # 3. –§—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è —Ç–∞ –æ—á–∏—â–µ–Ω–Ω—è CSV-—Ñ–∞–π–ª—É
    log_message(f"üîç –ó–∞–ø—É—Å–∫–∞—é —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—é –¥–∞–Ω–∏—Ö —É {os.path.basename(csv_name)}.", log_file_path)

    temp_file_path = f"{csv_name}.temp"
    processed_rows = []
    skipped_rows = 0
    total_rows = 0

    try:
        with open(csv_name, "r", newline="", encoding="utf-8") as infile:
            reader = csv.reader(infile)
            headers = next(reader)
            processed_rows.append(headers)
            
            row_number = 1
            for row in reader:
                row_number += 1
                total_rows += 1

                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞, —â–æ —Ä—è–¥–æ–∫ –º—ñ—Å—Ç–∏—Ç—å –¥–æ—Å—Ç–∞—Ç–Ω—å–æ –∫–æ–ª–æ–Ω–æ–∫
                if len(row) < 4:
                    log_message(f"üö´ –í–∏–¥–∞–ª–µ–Ω–æ —Ä—è–¥–æ–∫ {row_number} —á–µ—Ä–µ–∑ –Ω–µ–¥–æ—Å—Ç–∞—Ç–Ω—é –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫–æ–ª–æ–Ω–æ–∫.", log_file_path)
                    skipped_rows += 1
                    continue

                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∫–æ–ª–æ–Ω–æ–∫ 3 —Ç–∞ 4 –Ω–∞ —Ü—ñ–ª–µ —á–∏—Å–ª–æ >= 0
                is_valid = True
                for col_index in [2, 3]:
                    value = row[col_index]
                    try:
                        int_value = int(float(value)) # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ float, —â–æ–± –æ–±—Ä–æ–±–ª—è—Ç–∏ —á–∏—Å–ª–∞ –∑ .00
                        if int_value < 0:
                            log_message(f"üö´ –í–∏–¥–∞–ª–µ–Ω–æ —Ä—è–¥–æ–∫ {row_number} —á–µ—Ä–µ–∑ –≤—ñ–¥'—î–º–Ω–µ –∑–Ω–∞—á–µ–Ω–Ω—è –≤ –∫–æ–ª–æ–Ω—Ü—ñ {col_index + 1}: '{value}'.", log_file_path)
                            is_valid = False
                            break
                    except (ValueError, IndexError):
                        log_message(f"üö´ –í–∏–¥–∞–ª–µ–Ω–æ —Ä—è–¥–æ–∫ {row_number} —á–µ—Ä–µ–∑ –Ω–µ–∫–æ—Ä–µ–∫—Ç–Ω–µ —á–∏—Å–ª–æ–≤–µ –∑–Ω–∞—á–µ–Ω–Ω—è –≤ –∫–æ–ª–æ–Ω—Ü—ñ {col_index + 1}: '{value}'.", log_file_path)
                        is_valid = False
                        break

                if is_valid:
                    processed_rows.append(row)
                else:
                    skipped_rows += 1
    
    except Exception as e:
        log_message(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—ó —Ñ–∞–π–ª—É: {e}", log_file_path)
        print(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—ó —Ñ–∞–π–ª—É: {e}")
        return

    # –ó–∞–ø–∏—Å –≤—ñ–¥—Ñ—ñ–ª—å—Ç—Ä–æ–≤–∞–Ω–∏—Ö –¥–∞–Ω–∏—Ö —É —Ñ–∞–π–ª
    with open(temp_file_path, "w", newline="", encoding="utf-8") as outfile:
        writer = csv.writer(outfile)
        writer.writerows(processed_rows)

    os.replace(temp_file_path, csv_name)

    log_message(f"üéâ –û–±—Ä–æ–±–∫—É —Ç–∞ —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—é –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –¥–ª—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {supplier_id} –∑–∞–≤–µ—Ä—à–µ–Ω–æ.", log_file_path)
    log_message(f"--- –ü—ñ–¥—Å—É–º–æ–∫ –æ–±—Ä–æ–±–∫–∏: ---", log_file_path)
    log_message(f"üì¶ –í—Å—å–æ–≥–æ —Ä—è–¥–∫—ñ–≤ —É —Ñ–∞–π–ª—ñ: {total_rows}", log_file_path)
    log_message(f"üóëÔ∏è –í–∏–¥–∞–ª–µ–Ω–æ —Ä—è–¥–∫—ñ–≤: {skipped_rows}", log_file_path)
    log_message(f"‚úÖ –û–±—Ä–æ–±–ª–µ–Ω—ñ —Ä—è–¥–∫–∏: {len(processed_rows) - 1}", log_file_path)
    print("‚úÖ –û–±—Ä–æ–±–∫–∞ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –î–µ—Ç–∞–ª—ñ –≤ –ª–æ–≥-—Ñ–∞–π–ª—ñ.")


def process_and_combine_all_data():
    """
    –û–±—Ä–æ–±–ª—è—î –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∏ —Ç–∞ –æ–±'—î–¥–Ω—É—î –¥–∞–Ω—ñ —É –∑–≤–µ–¥–µ–Ω—É —Ç–∞–±–ª–∏—Ü—é.
    """
    settings = load_settings()
    if not settings:
        return

    base_dir = os.path.join(os.path.dirname(__file__), "..")
    log_file_path = os.path.join(base_dir, settings.get("log_file_path"))
    
    zalishki_path = os.path.join(base_dir, settings.get("csv_path_zalishki"))
    zvedena_path = os.path.join(base_dir, "csv", "process", "zvedena.csv")
    
    # –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫—ñ–≤
    supplier_info_1 = settings.get("suppliers", {}).get("1")
    supplier_csv_path_1 = os.path.join(base_dir, supplier_info_1.get("csv_path"))
    supplier_delimiter_1 = supplier_info_1.get("delimiter", ",")
    
    supplier_info_2 = settings.get("suppliers", {}).get("2")
    supplier_csv_path_2 = os.path.join(base_dir, supplier_info_2.get("csv_path"))
    supplier_delimiter_2 = supplier_info_2.get("delimiter", ",")

    supplier_info_3 = settings.get("suppliers", {}).get("3")
    supplier_csv_path_3 = os.path.join(base_dir, supplier_info_3.get("csv_name"))
    supplier_delimiter_3 = supplier_info_3.get("delimiter", ",")
    
    supplier_info_4 = settings.get("suppliers", {}).get("4")
    supplier_csv_path_4 = os.path.join(base_dir, supplier_info_4.get("csv_path"))
    supplier_delimiter_4 = supplier_info_4.get("delimiter", ",")

    zvedena_names_map = settings.get("column_zvedena_name")
    new_header = [zvedena_names_map.get(str(i)) for i in range(len(zvedena_names_map))]
    
    zalishki_columns = ["0", "1", "7", "9", "11", "13", "4", "5", "3", "2", "6"]
    
    supplier_1_columns = ["0", "3", "6"]
    supplier_1_match_column = "0"
    zvedena_match_column_1 = "3"
    
    supplier_2_columns = ["0", "3", "6"]
    supplier_2_match_column = "0"
    zvedena_match_column_2 = "4"

    supplier_3_columns = ["0", "2", "3"]
    supplier_3_match_column = "0"
    zvedena_match_column_3 = "5"
    
    supplier_4_columns = ["5", "4", "6"]
    supplier_4_match_column = "5"
    zvedena_match_column_4 = "1"

    if not os.path.exists(zalishki_path):
        log_message(f"‚ùå –§–∞–π–ª –∑–∞–ª–∏—à–∫—ñ–≤ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {zalishki_path}", log_file_path)
        print("‚ùå –§–∞–π–ª –∑–∞–ª–∏—à–∫—ñ–≤ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return
    if not os.path.exists(supplier_csv_path_1):
        log_message(f"‚ùå –ü—Ä–∞–π—Å-–ª–∏—Å—Ç –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 1 –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {supplier_csv_path_1}", log_file_path)
        print("‚ùå –ü—Ä–∞–π—Å-–ª–∏—Å—Ç –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 1 –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return
    if not os.path.exists(supplier_csv_path_2):
        log_message(f"‚ùå –ü—Ä–∞–π—Å-–ª–∏—Å—Ç –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 2 –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {supplier_csv_path_2}", log_file_path)
        print("‚ùå –ü—Ä–∞–π—Å-–ª–∏—Å—Ç –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 2 –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return
    if not os.path.exists(supplier_csv_path_3):
        log_message(f"‚ùå –ü—Ä–∞–π—Å-–ª–∏—Å—Ç –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 3 –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {supplier_csv_path_3}", log_file_path)
        print("‚ùå –ü—Ä–∞–π—Å-–ª–∏—Å—Ç –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 3 –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return
    if not os.path.exists(supplier_csv_path_4):
        log_message(f"‚ùå –ü—Ä–∞–π—Å-–ª–∏—Å—Ç –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 4 –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {supplier_csv_path_4}", log_file_path)
        print("‚ùå –ü—Ä–∞–π—Å-–ª–∏—Å—Ç –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 4 –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return

    log_message("‚öôÔ∏è –ó–∞–ø—É—Å–∫–∞—é –ø–æ–≤–Ω–∏–π –ø—Ä–æ—Ü–µ—Å –æ–±—Ä–æ–±–∫–∏ —Ç–∞ –æ–±'—î–¥–Ω–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö...", log_file_path)
    
    if os.path.exists(zvedena_path):
        try:
            os.remove(zvedena_path)
            log_message(f"‚úÖ –°—Ç–∞—Ä–∏–π —Ñ–∞–π–ª {os.path.basename(zvedena_path)} —É—Å–ø—ñ—à–Ω–æ –≤–∏–¥–∞–ª–µ–Ω–æ.", log_file_path)
        except OSError as e:
            log_message(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –≤–∏–¥–∞–ª–µ–Ω–Ω—ñ —Å—Ç–∞—Ä–æ–≥–æ —Ñ–∞–π–ª—É: {e}", log_file_path)
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: {e}")
            return
    
    supplier_data_dict_1 = {}
    try:
        with open(supplier_csv_path_1, "r", newline="", encoding="utf-8") as infile:
            reader = csv.reader(infile, delimiter=supplier_delimiter_1)
            next(reader) 
            for row in reader:
                if len(row) > max(int(col) for col in supplier_1_columns):
                    key = row[int(supplier_1_match_column)].strip()
                    values = [row[int(col)].strip() for col in supplier_1_columns]
                    supplier_data_dict_1[key] = values
    except Exception as e:
        log_message(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ —á–∏—Ç–∞–Ω–Ω—ñ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 1: {e}", log_file_path)
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ —á–∏—Ç–∞–Ω–Ω—ñ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 1: {e}")
        return

    supplier_data_dict_2 = {}
    try:
        with open(supplier_csv_path_2, "r", newline="", encoding="utf-8") as infile:
            reader = csv.reader(infile, delimiter=supplier_delimiter_2)
            next(reader) 
            for row in reader:
                if len(row) > max(int(col) for col in supplier_2_columns):
                    key = row[int(supplier_2_match_column)].strip()
                    values = [row[int(col)].strip() for col in supplier_2_columns]
                    supplier_data_dict_2[key] = values
    except Exception as e:
        log_message(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ —á–∏—Ç–∞–Ω–Ω—ñ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 2: {e}", log_file_path)
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ —á–∏—Ç–∞–Ω–Ω—ñ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 2: {e}")
        return

    supplier_data_dict_3 = {}
    try:
        with open(supplier_csv_path_3, "r", newline="", encoding="utf-8") as infile:
            reader = csv.reader(infile, delimiter=supplier_delimiter_3)
            next(reader) 
            for row in reader:
                if len(row) > max(int(col) for col in supplier_3_columns):
                    key = row[int(supplier_3_match_column)].strip()
                    values = [row[int(col)].strip() for col in supplier_3_columns]
                    supplier_data_dict_3[key] = values
    except Exception as e:
        log_message(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ —á–∏—Ç–∞–Ω–Ω—ñ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 3: {e}", log_file_path)
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ —á–∏—Ç–∞–Ω–Ω—ñ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 3: {e}")
        return

    supplier_data_dict_4 = {}
    try:
        with open(supplier_csv_path_4, "r", newline="", encoding="utf-8") as infile:
            reader = csv.reader(infile, delimiter=supplier_delimiter_4)
            next(reader) 
            for row in reader:
                if len(row) > max(int(col) for col in supplier_4_columns):
                    key = row[int(supplier_4_match_column)].strip()
                    values = [row[int(col)].strip() for col in supplier_4_columns]
                    supplier_data_dict_4[key] = values
    except Exception as e:
        log_message(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ —á–∏—Ç–∞–Ω–Ω—ñ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 4: {e}", log_file_path)
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ —á–∏—Ç–∞–Ω–Ω—ñ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 4: {e}")
        return

    processed_rows = []
    processed_count = 0
    updated_by_s1_count = 0
    updated_by_s2_count = 0
    updated_by_s3_count = 0
    updated_by_s4_count = 0

    # –í–∏–∑–Ω–∞—á–∞—î–º–æ —ñ–Ω–¥–µ–∫—Å–∏ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è —Ñ–æ—Ä–º—É–ª –∑–≥—ñ–¥–Ω–æ –∑ –≤–∞—à–∏–º–∏ –¥–∞–Ω–∏–º–∏
    formula_cols = {
        'N': 13, 'Q': 16, 'S': 18, 'V': 21,
        'M': 12, 'P': 15, 'T': 19, 'W': 22,
        'H': 7,
        'I': 8,
        'X': 23,
        'G': 6,
        'Y': 24
    }

    try:
        with open(zalishki_path, "r", newline="", encoding="utf-8") as infile:
            reader = csv.reader(infile)
            next(reader)
            
            # –î–æ–¥–∞—î–º–æ –Ω–æ–≤—ñ –∫–æ–ª–æ–Ω–∫–∏ –∑ –Ω–∞–∑–≤–∞–º–∏ –∑ settings.json
            processed_rows.append(new_header)
            
            for row in reader:
                processed_count += 1
                if len(row) > 13:
                    new_row = [row[int(col_index)] for col_index in zalishki_columns]
                    
                    supplier_data_1 = supplier_data_dict_1.get(new_row[int(zvedena_match_column_1)].strip(), ["", "", ""])
                    supplier_data_2 = supplier_data_dict_2.get(new_row[int(zvedena_match_column_2)].strip(), ["", "", ""])
                    supplier_data_3 = supplier_data_dict_3.get(new_row[int(zvedena_match_column_3)].strip(), ["", "", ""])
                    supplier_data_4 = supplier_data_dict_4.get(new_row[int(zvedena_match_column_4)].strip(), ["", "", ""])
                    
                    new_row.extend(supplier_data_1)
                    new_row.extend(supplier_data_2)
                    new_row.extend(supplier_data_3)
                    new_row.extend(supplier_data_4)

                    # –û–±—á–∏—Å–ª–µ–Ω–Ω—è –¥–ª—è –∫–æ–ª–æ–Ω–∫–∏ 23: max(N, Q, S, V)
                    quantities_to_compare = []
                    for col_name in ['N', 'Q', 'S', 'V']:
                        try:
                            index = formula_cols[col_name]
                            val = new_row[index].strip()
                            quantities_to_compare.append(int(val) if val else 0)
                        except (KeyError, IndexError):
                            quantities_to_compare.append(0)
                    
                    max_quantity = max(quantities_to_compare) if quantities_to_compare else 0
                    new_row.append(str(max_quantity))

                    # –û–±—á–∏—Å–ª–µ–Ω–Ω—è –¥–ª—è –∫–æ–ª–æ–Ω–∫–∏ 24: if((M + P + T + W) = 0; H; min(M; P; T; W))
                    quantities_for_sum = []
                    valid_quantities_for_min = []
                    
                    for col_name in ['M', 'P', 'T', 'W']:
                        try:
                            index = formula_cols[col_name]
                            val = new_row[index].strip()
                            num_val = int(val) if val else 0
                            quantities_for_sum.append(num_val)
                            if num_val > 0:
                                valid_quantities_for_min.append(num_val)
                        except (KeyError, IndexError):
                            quantities_for_sum.append(0)
                    
                    if sum(quantities_for_sum) == 0:
                        result_24 = new_row[formula_cols['H']]
                    else:
                        if valid_quantities_for_min:
                            result_24 = min(valid_quantities_for_min)
                        else:
                            result_24 = 0

                    new_row.append(str(result_24))

                    # –û–±—á–∏—Å–ª–µ–Ω–Ω—è –¥–ª—è –∫–æ–ª–æ–Ω–∫–∏ 25: if(I = "yes"; 1; 0)
                    try:
                        i_val = new_row[formula_cols['I']].strip().lower()
                    except IndexError:
                        i_val = ""
                    
                    result_25 = 1 if i_val == "yes" else 0
                    new_row.append(str(result_25))
                    
                    # –û–±—á–∏—Å–ª–µ–Ω–Ω—è –¥–ª—è –∫–æ–ª–æ–Ω–∫–∏ 26: IF((X - G) = 0; 0; 1)
                    x_val = 0
                    g_val = 0
                    try:
                        x_val = int(new_row[formula_cols['X']])
                    except (ValueError, IndexError):
                        x_val = 0
                    
                    try:
                        g_val = int(new_row[formula_cols['G']])
                    except (ValueError, IndexError):
                        g_val = 0
                    
                    if (x_val - g_val) == 0:
                        result_26 = 0
                    else:
                        result_26 = 1
                    
                    new_row.append(str(result_26))
                    #log_message(f"—Ä—è–¥–æ–∫ {processed_count}: X = \"{x_val}\", G = \"{g_val}\". (X - G) = \"{x_val - g_val}\". –†–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –∫–æ–ª–æ–Ω–∫–∏ 26 = \"{result_26}\"", log_file_path)

                    # –û–±—á–∏—Å–ª–µ–Ω–Ω—è –¥–ª—è –∫–æ–ª–æ–Ω–∫–∏ 27: IF((Y - H) = 0; 0; 1)
                    y_val = 0
                    h_val = 0
                    try:
                        y_val = int(new_row[formula_cols['Y']])
                    except (ValueError, IndexError):
                        y_val = 0
                    
                    try:
                        h_val = int(new_row[formula_cols['H']])
                    except (ValueError, IndexError):
                        h_val = 0
                    
                    if (y_val - h_val) == 0:
                        result_27 = 0
                    else:
                        result_27 = 1
                    
                    new_row.append(str(result_27))
                    #log_message(f"—Ä—è–¥–æ–∫ {processed_count}: Y = \"{y_val}\", H = \"{h_val}\". (Y - H) = \"{y_val - h_val}\". –†–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –∫–æ–ª–æ–Ω–∫–∏ 27 = \"{result_27}\"", log_file_path)

                    if supplier_data_1[0] != "":
                        updated_by_s1_count += 1
                    if supplier_data_2[0] != "":
                        updated_by_s2_count += 1
                    if supplier_data_3[0] != "":
                        updated_by_s3_count += 1
                    if supplier_data_4[0] != "":
                        updated_by_s4_count += 1
                    
                    processed_rows.append(new_row)
    
    except Exception as e:
        log_message(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –æ–±—Ä–æ–±–∫–∏ –¥–∞–Ω–∏—Ö: {e}", log_file_path)
        print(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –æ–±—Ä–æ–±–∫–∏ –¥–∞–Ω–∏—Ö: {e}")
        return

    try:
        with open(zvedena_path, "w", newline="", encoding="utf-8") as outfile:
            writer = csv.writer(outfile)
            writer.writerows(processed_rows)

        log_message("üéâ –ü–æ–≤–Ω–∏–π –ø—Ä–æ—Ü–µ—Å –æ–±—Ä–æ–±–∫–∏ —Ç–∞ –æ–±'—î–¥–Ω–∞–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ!", log_file_path)
        log_message(f"--- –ü—ñ–¥—Å—É–º–æ–∫: ---", log_file_path)
        log_message(f"üì¶ –í—Å—å–æ–≥–æ —Ä—è–¥–∫—ñ–≤ —É —Ñ–∞–π–ª—ñ –∑–∞–ª–∏—à–∫—ñ–≤: {processed_count}", log_file_path)
        log_message(f"‚úÖ –û–Ω–æ–≤–ª–µ–Ω–æ –¥–∞–Ω–∏–º–∏ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 1: {updated_by_s1_count} —Ä—è–¥–∫—ñ–≤.", log_file_path)
        log_message(f"‚úÖ –û–Ω–æ–≤–ª–µ–Ω–æ –¥–∞–Ω–∏–º–∏ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 2: {updated_by_s2_count} —Ä—è–¥–∫—ñ–≤.", log_file_path)
        log_message(f"‚úÖ –û–Ω–æ–≤–ª–µ–Ω–æ –¥–∞–Ω–∏–º–∏ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 3: {updated_by_s3_count} —Ä—è–¥–∫—ñ–≤.", log_file_path)
        log_message(f"‚úÖ –û–Ω–æ–≤–ª–µ–Ω–æ –¥–∞–Ω–∏–º–∏ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 4: {updated_by_s4_count} —Ä—è–¥–∫—ñ–≤.", log_file_path)
        log_message(f"üìÑ –°—Ç–≤–æ—Ä–µ–Ω–æ –∑–≤–µ–¥–µ–Ω–∏—Ö —Ä—è–¥–∫—ñ–≤: {len(processed_rows) - 1}", log_file_path)
        print("‚úÖ –ü–æ–≤–Ω–∏–π –ø—Ä–æ—Ü–µ—Å –æ–±—Ä–æ–±–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –î–µ—Ç–∞–ª—ñ –≤ –ª–æ–≥-—Ñ–∞–π–ª—ñ.")

    except Exception as e:
        log_message(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—ñ –∑–≤–µ–¥–µ–Ω–æ—ó —Ç–∞–±–ª–∏—Ü—ñ: {e}", log_file_path)
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: {e}")


def prepare_for_website_upload():
    """
    –ì–æ—Ç—É—î –¥–∞–Ω—ñ –∑—ñ –∑–≤–µ–¥–µ–Ω–æ—ó —Ç–∞–±–ª–∏—Ü—ñ –¥–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –Ω–∞ —Å–∞–π—Ç,
    –≤–∏–∫–æ–Ω—É—é—á–∏ –∫–æ–∂–µ–Ω –∫—Ä–æ–∫ –æ–∫—Ä–µ–º–æ –∑ –∑–∞–ø–∏—Å–æ–º —É —Ñ–∞–π–ª.
    """
    base_dir = os.path.join(os.path.dirname(__file__), "..")
    log_file_path = os.path.join(base_dir, "logs", "logs.log")
    source_file_path = os.path.join(base_dir, "csv", "process", "zvedena.csv")
    target_file_path = os.path.join(base_dir, "csv", "process", "na_sait.csv")
    
    log_message("‚öôÔ∏è –ó–∞–ø—É—Å–∫–∞—é –ø—ñ–¥–≥–æ—Ç–æ–≤–∫—É –¥–∞–Ω–∏—Ö –¥–ª—è —Å–∞–π—Ç—É...", log_file_path)

    # –ö—Ä–æ–∫ 1: –û—á–∏—â–∞—î–º–æ —Ç–∞–±–ª–∏—á–∫—É na_sait.csv
    try:
        log_message("‚öôÔ∏è –ö—Ä–æ–∫ 1: –û—á–∏—â–∞—é —Ñ–∞–π–ª 'na_sait.csv'...", log_file_path)
        with open(target_file_path, 'w', newline='', encoding='utf-8') as f:
            pass
        log_message("‚úÖ –§–∞–π–ª 'na_sait.csv' —É—Å–ø—ñ—à–Ω–æ –æ—á–∏—â–µ–Ω–æ.", log_file_path)
    except Exception as e:
        log_message(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ—á–∏—â–µ–Ω–Ω—ñ —Ñ–∞–π–ª—É {os.path.basename(target_file_path)}: {e}", log_file_path)
        return

    # –ö—Ä–æ–∫ 2: –ö–æ–ø—ñ—é—î–º–æ –∫–æ–ª–æ–Ω–∫–∏ 1, 23-30 —ñ–∑ zvedena.csv
    try:
        log_message("‚öôÔ∏è –ö—Ä–æ–∫ 2: –ö–æ–ø—ñ—é—é –¥–∞–Ω—ñ –∑—ñ 'zvedena.csv'...", log_file_path)
        with open(source_file_path, 'r', newline='', encoding='utf-8') as infile, \
             open(target_file_path, 'w', newline='', encoding='utf-8') as outfile:
            
            reader = csv.reader(infile)
            writer = csv.writer(outfile)
            
            try:
                header = next(reader)
                columns_to_copy = [1] + list(range(23, min(31, len(header))))
                new_header = [header[i] for i in columns_to_copy]
                writer.writerow(new_header)
            except StopIteration:
                log_message("‚ùå –ü–æ–º–∏–ª–∫–∞: –í—Ö—ñ–¥–Ω–∏–π —Ñ–∞–π–ª –ø–æ—Ä–æ–∂–Ω—ñ–π.", log_file_path)
                return
            
            copied_count = 0
            for i, row in enumerate(reader):
                selected_columns = [row[1]] if len(row) > 1 else [""]
                
                for j in range(23, 31):
                    if j < len(row):
                        selected_columns.append(row[j])
                    else:
                        selected_columns.append("")
                
                if len(selected_columns) > 1:
                    writer.writerow(selected_columns)
                    copied_count += 1
        
        log_message(f"‚úÖ –ö—Ä–æ–∫ 2 –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –°–∫–æ–ø—ñ–π–æ–≤–∞–Ω–æ {copied_count} —Ä—è–¥–∫—ñ–≤.", log_file_path)
    except FileNotFoundError:
        log_message(f"‚ùå –ü–æ–º–∏–ª–∫–∞: –í—Ö—ñ–¥–Ω–∏–π —Ñ–∞–π–ª {os.path.basename(source_file_path)} –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.", log_file_path)
        return
    except Exception as e:
        log_message(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –∫–æ–ø—ñ—é–≤–∞–Ω–Ω—è: {e}", log_file_path)
        return

    # –ö—Ä–æ–∫ 3: –î–æ–¥–∞—î–º–æ 4 –Ω–æ–≤—ñ –∫–æ–ª–æ–Ω–∫–∏ –∑ –Ω–∞–∑–≤–∞–º–∏
    try:
        log_message("‚öôÔ∏è –ö—Ä–æ–∫ 3: –î–æ–¥–∞—é 4 –Ω–æ–≤—ñ –∫–æ–ª–æ–Ω–∫–∏...", log_file_path)
        with open(target_file_path, 'r', newline='', encoding='utf-8') as infile:
            reader = csv.reader(infile)
            header = next(reader)
            rows = list(reader)
        
        new_header = header + ["sale_price", "sale_price_dates_from", "sale_price_dates_to", "–ó–Ω–∏–∂–∫–∞%"]
        
        with open(target_file_path, 'w', newline='', encoding='utf-8') as outfile:
            writer = csv.writer(outfile)
            writer.writerow(new_header)
            for row in rows:
                row += [""] * 4
                writer.writerow(row)
        
        log_message(f"‚úÖ –ö—Ä–æ–∫ 3 –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –î–æ–¥–∞–Ω–æ 4 –Ω–æ–≤—ñ –∫–æ–ª–æ–Ω–∫–∏. –†—è–¥–∫—ñ–≤ —É —Ñ–∞–π–ª—ñ: {len(rows)}", log_file_path)
    except Exception as e:
        log_message(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –¥–æ–¥–∞–≤–∞–Ω–Ω—è –∫–æ–ª–æ–Ω–æ–∫: {e}", log_file_path)
        return

    # –ö—Ä–æ–∫ 4: –í–∏–¥–∞–ª—è—î–º–æ –≤—Å—ñ —Ä—è–¥–∫–∏, –¥–µ –≤ –∫–æ–ª–æ–Ω—Ü—ñ –∑ —ñ–Ω–¥–µ–∫—Å–æ–º 3 —Å—Ç–æ—ó—Ç—å "0"
    try:
        log_message("‚öôÔ∏è –ö—Ä–æ–∫ 4: –í–∏–¥–∞–ª—è—é —Ä—è–¥–∫–∏ –∑ –Ω—É–ª—å–æ–≤–∏–º–∏ –∑–Ω–∞—á–µ–Ω–Ω—è–º–∏...", log_file_path)
        with open(target_file_path, 'r', newline='', encoding='utf-8') as infile:
            reader = csv.reader(infile)
            header = next(reader)
            rows = list(reader)

        original_count = len(rows)
        filtered_rows = [row for row in rows if row[3] != "0"]
        deleted_count = original_count - len(filtered_rows)

        with open(target_file_path, 'w', newline='', encoding='utf-8') as outfile:
            writer = csv.writer(outfile)
            writer.writerow(header)
            writer.writerows(filtered_rows)
        
        log_message(f"‚úÖ –ö—Ä–æ–∫ 4 –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –í–∏–¥–∞–ª–µ–Ω–æ {deleted_count} —Ä—è–¥–∫—ñ–≤. –ó–∞–ª–∏—à–∏–ª–æ—Å—å {len(filtered_rows)}.", log_file_path)
    except Exception as e:
        log_message(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –≤–∏–¥–∞–ª–µ–Ω–Ω—è —Ä—è–¥–∫—ñ–≤: {e}", log_file_path)
        return

    # –ö—Ä–æ–∫ 5: –ó–∞–ø–æ–≤–Ω—é—î–º–æ –∫–æ–ª–æ–Ω–∫—É –∑ —ñ–Ω–¥–µ–∫—Å–æ–º 12 —Ä–∞–Ω–¥–æ–º–Ω–∏–º–∏ –∑–Ω–∞—á–µ–Ω–Ω—è–º–∏
    try:
        log_message("‚öôÔ∏è –ö—Ä–æ–∫ 5: –ó–∞–ø–æ–≤–Ω—é—é –∫–æ–ª–æ–Ω–∫—É 12 —Ä–∞–Ω–¥–æ–º–Ω–∏–º–∏ –∑–Ω–∞—á–µ–Ω–Ω—è–º–∏...", log_file_path)
        with open(target_file_path, 'r', newline='', encoding='utf-8') as infile:
            reader = csv.reader(infile)
            header = next(reader)
            rows = list(reader)
        
        random_choices = [0, 2, 3, 5]
        weights = [94, 3, 2, 1]
        
        updated_count = 0
        for row in rows:
            try:
                if len(row) > 2 and float(row[1]) > 0 and float(row[2].replace(',', '.')) > 800:
                    random_value = random.choices(random_choices, weights=weights, k=1)[0]
                    row[12] = str(random_value)
                    if random_value > 0:
                        updated_count += 1
            except (ValueError, IndexError):
                continue
        
        with open(target_file_path, 'w', newline='', encoding='utf-8') as outfile:
            writer = csv.writer(outfile)
            writer.writerow(header)
            writer.writerows(rows)
            
        log_message(f"‚úÖ –ö—Ä–æ–∫ 5 –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –£—Å–ø—ñ—à–Ω–æ –∑–∞–ø–æ–≤–Ω–µ–Ω–æ {updated_count} —Ä—è–¥–∫—ñ–≤.", log_file_path)
    except Exception as e:
        log_message(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –∑–∞–ø–æ–≤–Ω–µ–Ω–Ω—è: {e}", log_file_path)
        return

    # –ö—Ä–æ–∫ 6: –ó–∞–ø–æ–≤–Ω—é—î–º–æ –∫–æ–ª–æ–Ω–∫—É –∑ —ñ–Ω–¥–µ–∫—Å–æ–º 9 –∑–∞ —Ñ–æ—Ä–º—É–ª–æ—é
    try:
        log_message("‚öôÔ∏è –ö—Ä–æ–∫ 6: –ó–∞–ø–æ–≤–Ω—é—é –∫–æ–ª–æ–Ω–∫—É 9 –∑–∞ —Ñ–æ—Ä–º—É–ª–æ—é...", log_file_path)
        with open(target_file_path, 'r', newline='', encoding='utf-8') as infile:
            reader = csv.reader(infile)
            header = next(reader)
            rows = list(reader)

        updated_count = 0
        for row in rows:
            try:
                c_val = float(row[2].replace(',', '.') if row[2] else 0)
                m_val = float(row[12]) if row[12] else 0
                
                if m_val > 0:
                    result = round(c_val * (100 - m_val) / 100, 0)
                    row[9] = str(int(result))
                    updated_count += 1
                else:
                    row[9] = ""
            except (ValueError, IndexError):
                row[9] = ""
                continue
        
        with open(target_file_path, 'w', newline='', encoding='utf-8') as outfile:
            writer = csv.writer(outfile)
            writer.writerow(header)
            writer.writerows(rows)
            
        log_message(f"‚úÖ –ö—Ä–æ–∫ 6 –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –ó–∞–ø–æ–≤–Ω–µ–Ω–æ {updated_count} —Ä—è–¥–∫—ñ–≤.", log_file_path)
    except Exception as e:
        log_message(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –∑–∞–ø–æ–≤–Ω–µ–Ω–Ω—è –∫–æ–ª–æ–Ω–∫–∏ 9: {e}", log_file_path)
        return

    # –ö—Ä–æ–∫ 7: –í–∏–¥–∞–ª—è—î–º–æ —Ä—è–¥–∫–∏, –¥–µ –∫–æ–ª–æ–Ω–∫–∞ 9 –ø—É—Å—Ç–∞, –∞ 4 —Ç–∞ 5 –¥–æ—Ä—ñ–≤–Ω—é—é—Ç—å "0"
    try:
        log_message("‚öôÔ∏è –ö—Ä–æ–∫ 7: –í–∏–¥–∞–ª—è—é —Ä—è–¥–∫–∏, –¥–µ –∫–æ–ª–æ–Ω–∫–∞ 9 –ø—É—Å—Ç–∞, –∞ 4 —ñ 5 –¥–æ—Ä—ñ–≤–Ω—é—é—Ç—å '0'...", log_file_path)
        with open(target_file_path, 'r', newline='', encoding='utf-8') as infile:
            reader = csv.reader(infile)
            header = next(reader)
            rows = list(reader)
        
        original_count = len(rows)
        
        filtered_rows = []
        for row in rows:
            if not (row[9] == "" and row[4] == "0" and row[5] == "0"):
                filtered_rows.append(row)
        
        deleted_count = original_count - len(filtered_rows)

        with open(target_file_path, 'w', newline='', encoding='utf-8') as outfile:
            writer = csv.writer(outfile)
            writer.writerow(header)
            writer.writerows(filtered_rows)

        log_message(f"‚úÖ –ö—Ä–æ–∫ 7 –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –í–∏–¥–∞–ª–µ–Ω–æ {deleted_count} —Ä—è–¥–∫—ñ–≤. –ó–∞–ª–∏—à–∏–ª–æ—Å—å {len(filtered_rows)}.", log_file_path)
    except Exception as e:
        log_message(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –≤–∏–¥–∞–ª–µ–Ω–Ω—è —Ä—è–¥–∫—ñ–≤: {e}", log_file_path)
        return

    # –ö—Ä–æ–∫ 8: –î–æ–¥–∞—î–º–æ –¥–∞—Ç–∏ –≤ –∫–æ–ª–æ–Ω–∫–∏ 10 —Ç–∞ 11 (–∫–æ–ª–∏—à–Ω—ñ–π –ö—Ä–æ–∫ 7)
    try:
        log_message("‚öôÔ∏è –ö—Ä–æ–∫ 8: –î–æ–¥–∞—é –¥–∞—Ç–∏ –≤ –∫–æ–ª–æ–Ω–∫–∏ 10 —Ç–∞ 11...", log_file_path)
        with open(target_file_path, 'r', newline='', encoding='utf-8') as infile:
            reader = csv.reader(infile)
            header = next(reader)
            rows = list(reader)

        today = datetime.now()
        seven_days_later = today + timedelta(days=7)
        
        today_formatted = today.strftime("%Y-%m-%d 00:00:00")
        seven_days_later_formatted = seven_days_later.strftime("%Y-%m-%d 00:00:00")
        
        updated_count = 0
        for row in rows:
            try:
                if len(row) > 12 and row[12] and float(row[12]) > 0:
                    if len(row) > 10:
                        row[10] = today_formatted
                    if len(row) > 11:
                        row[11] = seven_days_later_formatted
                    updated_count += 1
            except (ValueError, IndexError):
                continue

        with open(target_file_path, 'w', newline='', encoding='utf-8') as outfile:
            writer = csv.writer(outfile)
            writer.writerow(header)
            writer.writerows(rows)
        
        log_message(f"‚úÖ –ö—Ä–æ–∫ 8 –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –î–∞—Ç–∏ –¥–æ–¥–∞–Ω–æ –¥–æ {updated_count} —Ä—è–¥–∫—ñ–≤.", log_file_path)
    except Exception as e:
        log_message(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –¥–æ–¥–∞–≤–∞–Ω–Ω—è –¥–∞—Ç: {e}", log_file_path)
        return
        
    # –ö—Ä–æ–∫ 9: –ö–æ–ø—ñ—é—î–º–æ –¥–∞–Ω—ñ –≤ —Ñ–∞–π–ª zalishky_akcii.csv
    try:
        log_message("‚öôÔ∏è –ö—Ä–æ–∫ 9: –ì–æ—Ç—É—é —Ñ–∞–π–ª 'zalishky_akcii.csv'...", log_file_path)
        
        source_copy_file_path = os.path.join(base_dir, "csv", "process", "na_sait.csv")
        target_copy_file_path = "/var/www/scripts/update/csv/output/zalishky_akcii.csv"
        
        # 9.1 –û—á–∏—â–∞—î–º–æ —Ñ–∞–π–ª
        with open(target_copy_file_path, 'w', newline='', encoding='utf-8') as f:
            pass

        # 9.2 –ö–æ–ø—ñ—é—î–º–æ –¥–∞–Ω—ñ
        with open(source_copy_file_path, 'r', newline='', encoding='utf-8') as infile, \
             open(target_copy_file_path, 'w', newline='', encoding='utf-8') as outfile:

            reader = csv.reader(infile)
            writer = csv.writer(outfile)
            
            # –ß–∏—Ç–∞—î–º–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫ —ñ –≤–∏–∑–Ω–∞—á–∞—î–º–æ —ñ–Ω–¥–µ–∫—Å–∏ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –∫–æ–ø—ñ—é–≤–∞–Ω–Ω—è
            try:
                header = next(reader)
                columns_to_copy = [0, 1, 2, 9, 10, 11]
                new_header = [header[i] for i in columns_to_copy if i < len(header)]
                writer.writerow(new_header)
            except StopIteration:
                log_message("‚ùå –ü–æ–º–∏–ª–∫–∞: –í—Ö—ñ–¥–Ω–∏–π —Ñ–∞–π–ª 'na_sait.csv' –ø–æ—Ä–æ–∂–Ω—ñ–π.", log_file_path)
                return

            copied_count = 0
            for row in reader:
                selected_columns = [row[i] for i in columns_to_copy if i < len(row)]
                writer.writerow(selected_columns)
                copied_count += 1
        
        log_message(f"‚úÖ –ö—Ä–æ–∫ 9 –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –°–∫–æ–ø—ñ–π–æ–≤–∞–Ω–æ {copied_count} —Ä—è–¥–∫—ñ–≤ –≤ 'zalishky_akcii.csv'.", log_file_path)
    except FileNotFoundError:
        log_message(f"‚ùå –ü–æ–º–∏–ª–∫–∞: –í—Ö—ñ–¥–Ω–∏–π –∞–±–æ –≤–∏—Ö—ñ–¥–Ω–∏–π —Ñ–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {e}", log_file_path)
        return
    except Exception as e:
        log_message(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –∫–æ–ø—ñ—é–≤–∞–Ω–Ω—è –≤ 'zalishky_akcii.csv': {e}", log_file_path)
        return

    log_message("üéâ –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö –¥–ª—è —Å–∞–π—Ç—É –∑–∞–≤–µ—Ä—à–µ–Ω–∞!", log_file_path)
    print("‚úÖ –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö –¥–ª—è —Å–∞–π—Ç—É –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")