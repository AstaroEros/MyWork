import csv
import json
import os
import time
import requests
import shutil
import re
from scr.updater import get_wc_api
from datetime import datetime

def load_settings():
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó –∑ settings.json
    """
    config_path = os.path.join(os.path.dirname(__file__), "..", "config", "settings.json")
    try:
        with open(config_path, "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: —Ñ–∞–π–ª –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∑–∞ —à–ª—è—Ö–æ–º: {config_path}")
        return None
    except json.JSONDecodeError:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: —Ñ–∞–π–ª –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó –ø–æ—à–∫–æ–¥–∂–µ–Ω–∏–π: {config_path}")
        return None

def setup_log_file():
    """
    –ü–µ—Ä–µ–≤—ñ—Ä—è—î –Ω–∞—è–≤–Ω—ñ—Å—Ç—å logs.log, –ø–µ—Ä–µ–π–º–µ–Ω–æ–≤—É—î –π–æ–≥–æ, —è–∫—â–æ —ñ—Å–Ω—É—î,
    —Ç–∞ –ø–æ–≤–µ—Ä—Ç–∞—î —à–ª—è—Ö –¥–æ –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª—É.
    """
    log_dir = os.path.join(os.path.dirname(__file__), "..", "logs")
    os.makedirs(log_dir, exist_ok=True)
    
    current_log_path = os.path.join(log_dir, "logs.log")
    
    if os.path.exists(current_log_path):
        timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        new_log_path = os.path.join(log_dir, f"logs_{timestamp}.log")
        try:
            os.rename(current_log_path, new_log_path)
            print(f"‚úÖ –°—Ç–∞—Ä–∏–π –ª–æ–≥-—Ñ–∞–π–ª –ø–µ—Ä–µ–π–º–µ–Ω–æ–≤–∞–Ω–æ –Ω–∞ {os.path.basename(new_log_path)}")
        except OSError as e:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–π–º–µ–Ω—É–≤–∞–Ω–Ω—ñ –ª–æ–≥-—Ñ–∞–π–ª—É: {e}")
            return current_log_path

    return current_log_path

def log_message(message, log_file_path=os.path.join(os.path.dirname(__file__), "..", "logs", "logs.log")):
    """
    –ó–∞–ø–∏—Å—É—î –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –≤ –ª–æ–≥-—Ñ–∞–π–ª.
    """
    with open(log_file_path, "a", encoding="utf-8") as log_file:
        log_file.write(f"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} - {message}\n")


def export_products():
    """
    –ï–∫—Å–ø–æ—Ä—Ç —É—Å—ñ—Ö —Ç–æ–≤–∞—Ä—ñ–≤ —É CSV –ø–∞—á–∫–∞–º–∏ –ø–æ 100.
    """
    settings = load_settings()
    if not settings:
        return
        
    log_file_path = setup_log_file()
    
    csv_path = os.path.join(os.path.dirname(__file__), "..", "csv", "input", "zalishki.csv")
    
    headers = [
        "ID", "–ê—Ä—Ç–∏–∫—É–ª", "–ù–∞–∑–≤–∞", "–û–ø—É–±–ª—ñ–∫–æ–≤–∞–Ω–æ", "–ó–∞–ø–∞—Å–∏", "–ó–≤–∏—á–∞–π–Ω–∞ —Ü—ñ–Ω–∞", "–ö–∞—Ç–µ–≥–æ—Ä—ñ—ó",
        "–ú–µ—Ç–∞: shtrih_cod", "–ú–µ—Ç–∞: postachalnyk", "–ú–µ—Ç–∞: artykul_lutsk", "–ú–µ—Ç–∞: url_lutsk",
        "–ú–µ—Ç–∞: artykul_blizklub", "–ú–µ—Ç–∞: url_blizklub",
        "–ú–µ—Ç–∞: artykul_sexopt", "–ú–µ—Ç–∞: url_sexopt",
        "–ú–µ—Ç–∞: artykul_biorytm", "–ú–µ—Ç–∞: url_biorytm",
        "–ú–µ—Ç–∞: artykul_berdiansk"
    ]

    wcapi = get_wc_api()
    start_time = time.time()
    total_products = 0
    exported_count = 0
    errors = []

    log_message("üöÄ –ü–æ—á–∞—Ç–æ–∫ –µ–∫—Å–ø–æ—Ä—Ç—É —Ç–æ–≤–∞—Ä—ñ–≤.", log_file_path)

    try:
        response = wcapi.get("products", params={"per_page": 1})
        if response.status_code != 200:
            error_msg = f"–ü–æ–º–∏–ª–∫–∞ {response.status_code} –ø—Ä–∏ –ø—ñ–¥—Ä–∞—Ö—É–Ω–∫—É —Ç–æ–≤–∞—Ä—ñ–≤: {response.text}"
            print(f"‚ùå {error_msg}")
            log_message(f"‚ùå {error_msg}", log_file_path)
            errors.append(error_msg)
            return

        total_products = int(response.headers.get("X-WP-Total", 0))
        print(f"üîé –ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–æ–≤–∞—Ä—ñ–≤: {total_products}")
        log_message(f"üîé –ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–æ–≤–∞—Ä—ñ–≤: {total_products}", log_file_path)

        with open(csv_path, "w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow(headers)

            page = 1
            while exported_count < total_products:
                response = wcapi.get(
                    "products",
                    params={
                        "per_page": 100,
                        "page": page,
                        "_fields": "id,sku,name,status,stock_quantity,regular_price,categories,meta_data"
                    }
                )

                if response.status_code != 200:
                    error_msg = f"–ü–æ–º–∏–ª–∫–∞ {response.status_code} –Ω–∞ —Å—Ç–æ—Ä—ñ–Ω—Ü—ñ {page}: {response.text}"
                    print(f"‚ùå {error_msg}")
                    log_message(f"‚ùå {error_msg}", log_file_path)
                    errors.append(error_msg)
                    break

                products = response.json()
                if not products:
                    break

                for product in products:
                    product["meta_data_dict"] = {m["key"]: m["value"] for m in product.get("meta_data", [])}
                    row = [
                        product.get("id"),
                        product.get("sku"),
                        product.get("name"),
                        "yes" if product.get("status") == "publish" else "no",
                        product.get("stock_quantity"),
                        product.get("regular_price"),
                        ", ".join([cat["name"] for cat in product.get("categories", [])]),
                        product["meta_data_dict"].get("shtrih_cod", ""),
                        product["meta_data_dict"].get("postachalnyk", ""),
                        product["meta_data_dict"].get("artykul_lutsk", ""),
                        product["meta_data_dict"].get("url_lutsk", ""),
                        product["meta_data_dict"].get("artykul_blizklub", ""),
                        product["meta_data_dict"].get("url_blizklub", ""),
                        product["meta_data_dict"].get("artykul_sexopt", ""),
                        product["meta_data_dict"].get("url_sexopt", ""),
                        product["meta_data_dict"].get("artykul_biorytm", ""),
                        product["meta_data_dict"].get("url_biorytm", ""),
                        product["meta_data_dict"].get("artykul_berdiansk", "")
                    ]
                    writer.writerow(row)
                    exported_count += 1
                
                if exported_count % 100 == 0 or exported_count == total_products:
                    elapsed = int(time.time() - start_time)
                    status_message = f"‚úÖ –í–∏–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {exported_count} –∑ {total_products} ({elapsed} —Å–µ–∫)"
                    print(status_message)
                    log_message(status_message, log_file_path)

                page += 1
                time.sleep(1)

    except Exception as e:
        error_msg = f"–í–∏–Ω–∏–∫–ª–∞ –Ω–µ–≤—ñ–¥–æ–º–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –µ–∫—Å–ø–æ—Ä—Ç—É: {e}"
        print(f"‚ùå {error_msg}")
        log_message(f"‚ùå {error_msg}", log_file_path)
        errors.append(error_msg)
    finally:
        end_time = time.time()
        elapsed_time = int(end_time - start_time)
        
        print(f"üéâ –ï–∫—Å–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –í–∏–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {exported_count} –∑ {total_products} —Ç–æ–≤–∞—Ä—ñ–≤ –∑–∞ {elapsed_time} —Å–µ–∫.")
        if errors:
            print(f"‚ö†Ô∏è –ï–∫—Å–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–∏–≤—Å—è –∑ {len(errors)} –ø–æ–º–∏–ª–∫–∞–º–∏. –î–µ—Ç–∞–ª—ñ –≤ –ª–æ–≥-—Ñ–∞–π–ª—ñ.")
        
        log_message(f"--- –ü—ñ–¥—Å—É–º–æ–∫ –µ–∫—Å–ø–æ—Ä—Ç—É ---", log_file_path)
        log_message(f"–°—Ç–∞—Ç—É—Å: {'–£—Å–ø—ñ—à–Ω–æ' if not errors else '–ó–∞–≤–µ—Ä—à–µ–Ω–æ –∑ –ø–æ–º–∏–ª–∫–∞–º–∏'}", log_file_path)
        log_message(f"–ö—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–æ–≤–∞—Ä—ñ–≤: {exported_count} –∑ {total_products}", log_file_path)
        log_message(f"–¢—Ä–∏–≤–∞–ª—ñ—Å—Ç—å: {elapsed_time} —Å–µ–∫.", log_file_path)
        if errors:
            log_message(f"–ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø–æ–º–∏–ª–æ–∫: {len(errors)}", log_file_path)
            log_message("–ü–µ—Ä–µ–ª—ñ–∫ –ø–æ–º–∏–ª–æ–∫:", log_file_path)
            for err in errors:
                log_message(f"- {err}", log_file_path)


def check_exported_csv():
    """
    –ü–µ—Ä–µ–≤—ñ—Ä—è—î —ñ –æ—á–∏—â–∞—î –¥–∞–Ω—ñ –≤ –µ–∫—Å–ø–æ—Ä—Ç–æ–≤–∞–Ω–æ–º—É CSV —Ñ–∞–π–ª—ñ.
    """
    settings = load_settings()
    if not settings:
        return

    csv_path = os.path.join(os.path.dirname(__file__), "..", "csv", "input", "zalishki.csv")
    if not os.path.exists(csv_path):
        print("‚ùå –§–∞–π–ª –µ–∫—Å–ø–æ—Ä—Ç—É –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return

    log_file_path = os.path.join(os.path.dirname(__file__), "..", "logs", "logs.log")
    log_message("üîç –ü–æ—á–∞—Ç–æ–∫ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ –µ–∫—Å–ø–æ—Ä—Ç–æ–≤–∞–Ω–æ–≥–æ CSV.", log_file_path)

    temp_file_path = f"{csv_path}.temp"
    validation_errors = []
    processed_rows = []

    try:
        with open(csv_path, "r", newline="", encoding="utf-8") as infile:
            reader = csv.reader(infile)
            headers = next(reader)
            
            row_number = 1
            for row in reader:
                row_number += 1
                row_id = row[0] if len(row) > 0 else "–ù–µ–≤—ñ–¥–æ–º–∏–π ID"

                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ç–∞ –æ—á–∏—â–µ–Ω–Ω—è –∫–æ–ª–æ–Ω–∫–∏ 1 (ID)
                try:
                    int(row[0])
                except (ValueError, IndexError):
                    validation_errors.append(f"‚ùå –†—è–¥–æ–∫ {row_number}, ID {row_id}: –ö–æ–ª–æ–Ω–∫–∞ 1 (ID) –Ω–µ —î —Ü—ñ–ª–∏–º —á–∏—Å–ª–æ–º. –ó–Ω–∞—á–µ–Ω–Ω—è: '{row[0]}'")
                
                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ç–∞ –æ—á–∏—â–µ–Ω–Ω—è –∫–æ–ª–æ–Ω–∫–∏ 2 (–ê—Ä—Ç–∏–∫—É–ª)
                try:
                    int(row[1])
                except (ValueError, IndexError):
                    validation_errors.append(f"‚ùå –†—è–¥–æ–∫ {row_number}, ID {row_id}: –ö–æ–ª–æ–Ω–∫–∞ 2 (–ê—Ä—Ç–∏–∫—É–ª) –Ω–µ —î —Ü—ñ–ª–∏–º —á–∏—Å–ª–æ–º. –ó–Ω–∞—á–µ–Ω–Ω—è: '{row[1]}'")
                
                 # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∫–æ–ª–æ–Ω–∫–∏ 3 (–ù–∞–∑–≤–∞)
                if len(row) > 2 and not row[2].strip():
                    validation_errors.append(f"‚ùå –†—è–¥–æ–∫ {row_number}, ID {row_id}: –ö–æ–ª–æ–Ω–∫–∞ 3 (–ù–∞–∑–≤–∞) –Ω–µ –º–æ–∂–µ –±—É—Ç–∏ –ø—É—Å—Ç–æ—é.")

                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ç–∞ –æ—á–∏—â–µ–Ω–Ω—è –∫–æ–ª–æ–Ω–∫–∏ 4 (–û–ø—É–±–ª—ñ–∫–æ–≤–∞–Ω–æ)
                if len(row) > 3 and row[3].lower() not in ["yes", "no"]:
                    validation_errors.append(f"‚ùå –†—è–¥–æ–∫ {row_number}, ID {row_id}: –ö–æ–ª–æ–Ω–∫–∞ 4 (–û–ø—É–±–ª—ñ–∫–æ–≤–∞–Ω–æ) –æ—á—ñ–∫—É—î 'yes' –∞–±–æ 'no'. –ó–Ω–∞—á–µ–Ω–Ω—è: '{row[3]}'")
                
                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ç–∞ –æ—á–∏—â–µ–Ω–Ω—è –∫–æ–ª–æ–Ω–∫–∏ 5 (–ó–∞–ø–∞—Å–∏)
                if len(row) > 4:
                    if row[4] == "":
                        row[4] = "0"
                        log_message(f"‚ÑπÔ∏è –†—è–¥–æ–∫ {row_number}, ID {row_id}: –ö–æ–ª–æ–Ω–∫–∞ 5 (–ó–∞–ø–∞—Å–∏) –±—É–ª–∞ –ø—É—Å—Ç–æ—é, –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –∑–Ω–∞—á–µ–Ω–Ω—è '0'.", log_file_path)
                    try:
                        int(row[4])
                    except ValueError:
                        validation_errors.append(f"‚ùå –†—è–¥–æ–∫ {row_number}, ID {row_id}: –ö–æ–ª–æ–Ω–∫–∞ 5 (–ó–∞–ø–∞—Å–∏) –Ω–µ —î —Ü—ñ–ª–∏–º —á–∏—Å–ª–æ–º. –ó–Ω–∞—á–µ–Ω–Ω—è: '{row[4]}'")
                
                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ç–∞ –æ—á–∏—â–µ–Ω–Ω—è –∫–æ–ª–æ–Ω–∫–∏ 6 (–ó–≤–∏—á–∞–π–Ω–∞ —Ü—ñ–Ω–∞)
                try:
                    int(row[5])
                except (ValueError, IndexError):
                    validation_errors.append(f"‚ùå –†—è–¥–æ–∫ {row_number}, ID {row_id}: –ö–æ–ª–æ–Ω–∫–∞ 6 (–ó–≤–∏—á–∞–π–Ω–∞ —Ü—ñ–Ω–∞) –Ω–µ —î —Ü—ñ–ª–∏–º —á–∏—Å–ª–æ–º. –ó–Ω–∞—á–µ–Ω–Ω—è: '{row[5]}'")
                
                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∫–æ–ª–æ–Ω–∫–∏ 7 (–ö–∞—Ç–µ–≥–æ—Ä—ñ—ó)
                if len(row) > 6 and not row[6].strip():
                    validation_errors.append(f"‚ùå –†—è–¥–æ–∫ {row_number}, ID {row_id}: –ö–æ–ª–æ–Ω–∫–∞ 7 (–ö–∞—Ç–µ–≥–æ—Ä—ñ—ó) –Ω–µ –º–æ–∂–µ –±—É—Ç–∏ –ø—É—Å—Ç–æ—é.")

                # –û—á–∏—â–µ–Ω–Ω—è –∫–æ–ª–æ–Ω–∫–∏ 9 (–ü–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫)
                if len(row) > 8:
                    row[8] = row[8].replace("[", "").replace("'", "").replace("]", "")
                
                # –û—á–∏—â–µ–Ω–Ω—è –∫–æ–ª–æ–Ω–æ–∫ 11, 13, 15, 17
                for i in [10, 12, 14, 16]:
                    if len(row) > i:
                        row[i] = row[i].replace("{'title': '', 'url': '", "").replace("', 'target': ''}", "")
                
                processed_rows.append(row)
    
    except Exception as e:
        print(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ —Ñ–∞–π–ª—É: {e}")
        log_message(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ —Ñ–∞–π–ª—É: {e}", log_file_path)
        return

    # –ó–∞–ø–∏—Å –≤—ñ–¥—Å–æ—Ä—Ç–æ–≤–∞–Ω–æ–≥–æ —Ç–∞ –æ—á–∏—â–µ–Ω–æ–≥–æ —Ñ–∞–π–ª—É
    print("‚è≥ –°–æ—Ä—Ç—É—é –¥–∞–Ω—ñ —Ç–∞ –∑–∞–ø–∏—Å—É—é –æ–Ω–æ–≤–ª–µ–Ω–∏–π —Ñ–∞–π–ª...")
    try:
        processed_rows.sort(key=lambda x: int(x[0]))
    except (ValueError, IndexError) as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ —Å–æ—Ä—Ç—É–≤–∞–Ω–Ω—è: –Ω–µ–º–æ–∂–ª–∏–≤–æ –ø–µ—Ä–µ—Ç–≤–æ—Ä–∏—Ç–∏ ID –Ω–∞ —á–∏—Å–ª–æ. {e}")
        log_message(f"‚ùå –ü–æ–º–∏–ª–∫–∞ —Å–æ—Ä—Ç—É–≤–∞–Ω–Ω—è: –Ω–µ–º–æ–∂–ª–∏–≤–æ –ø–µ—Ä–µ—Ç–≤–æ—Ä–∏—Ç–∏ ID –Ω–∞ —á–∏—Å–ª–æ. {e}", log_file_path)

    with open(temp_file_path, "w", newline="", encoding="utf-8") as outfile:
        writer = csv.writer(outfile)
        writer.writerow(headers)
        writer.writerows(processed_rows)

    os.replace(temp_file_path, csv_path)

    # –õ–æ–≥—É–≤–∞–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
    log_message("üéâ –ü–µ—Ä–µ–≤—ñ—Ä–∫—É —Ç–∞ –æ—á–∏—â–µ–Ω–Ω—è —Ñ–∞–π–ª—É –∑–∞–≤–µ—Ä—à–µ–Ω–æ.", log_file_path)
    if validation_errors:
        log_message(f"‚ö†Ô∏è –ó–Ω–∞–π–¥–µ–Ω–æ {len(validation_errors)} –ø–æ–º–∏–ª–æ–∫:", log_file_path)
        for error in validation_errors:
            log_message(error, log_file_path)
        print(f"‚ö†Ô∏è –ó–Ω–∞–π–¥–µ–Ω–æ {len(validation_errors)} –ø–æ–º–∏–ª–æ–∫. –î–µ—Ç–∞–ª—ñ –≤ –ª–æ–≥-—Ñ–∞–π–ª—ñ.")
    else:
        log_message("‚úÖ –í—Å—ñ –¥–∞–Ω—ñ –∫–æ—Ä–µ–∫—Ç–Ω—ñ. –ü–æ–º–∏–ª–æ–∫ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.", log_file_path)
        print("‚úÖ –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞, –ø–æ–º–∏–ª–æ–∫ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")



def download_supplier_price_list(supplier_id):
    """
    –°–∫–∞—á—É—î –ø—Ä–∞–π—Å-–ª–∏—Å—Ç –≤—ñ–¥ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ –∑–∞ –π–æ–≥–æ ID.
    """
    settings = load_settings()
    if not settings:
        return
    
    supplier_info = settings.get("suppliers", {}).get(str(supplier_id))
    if not supplier_info:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ –∑ ID '{supplier_id}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return

    base_dir = os.path.join(os.path.dirname(__file__), "..")
    log_file_path = os.path.join(base_dir, settings.get("log_file_path"))
    
    url = supplier_info.get("download_url")
    csv_path = os.path.join(base_dir, supplier_info.get("csv_path"))
   
    log_message(f"‚è≥ –ó–∞–ø—É—Å–∫–∞—é –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –≤—ñ–¥ {supplier_id} (ID: {supplier_id}).", log_file_path)

    # –í–∏–¥–∞–ª–µ–Ω–Ω—è —Å—Ç–∞—Ä–æ–≥–æ —Ñ–∞–π–ª—É, —è–∫—â–æ –≤—ñ–Ω —ñ—Å–Ω—É—î
    if os.path.exists(csv_path):
        try:
            os.remove(csv_path)
            log_message(f"‚úÖ –°—Ç–∞—Ä–∏–π —Ñ–∞–π–ª {os.path.basename(csv_path)} —É—Å–ø—ñ—à–Ω–æ –≤–∏–¥–∞–ª–µ–Ω–æ.", log_file_path)
        except OSError as e:
            log_message(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –≤–∏–¥–∞–ª–µ–Ω–Ω—ñ —Å—Ç–∞—Ä–æ–≥–æ —Ñ–∞–π–ª—É: {e}", log_file_path)
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: {e}")
            return
    
    try:
        # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ñ–∞–π–ª—É
        with requests.get(url, stream=True) as r:
            r.raise_for_status()
            with open(csv_path, 'wb') as f:
                shutil.copyfileobj(r.raw, f)
        
        log_message(f"üéâ –ü—Ä–∞–π—Å-–ª–∏—Å—Ç –≤—ñ–¥ {supplier_id} —É—Å–ø—ñ—à–Ω–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ.", log_file_path)
        print(f"‚úÖ –ü—Ä–∞–π—Å-–ª–∏—Å—Ç –≤—ñ–¥ {supplier_id} —É—Å–ø—ñ—à–Ω–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ.")
    except requests.exceptions.RequestException as e:
        log_message(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ñ–∞–π–ª—É –≤—ñ–¥ {supplier_id}: {e}", log_file_path)
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ñ–∞–π–ª—É: {e}")


def process_supplier_1_price_list():
    """
    –û–±—Ä–æ–±–ª—è—î —Ç–∞ –æ—á–∏—â–∞—î –ø—Ä–∞–π—Å-–ª–∏—Å—Ç –≤—ñ–¥ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 1.
    """
    settings = load_settings()
    if not settings:
        return

    supplier_id = "1"
    supplier_info = settings.get("suppliers", {}).get(supplier_id)
    if not supplier_info:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ –∑ ID '{supplier_id}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return

    base_dir = os.path.join(os.path.dirname(__file__), "..")
    log_file_path = os.path.join(base_dir, settings.get("log_file_path"))
    csv_path = os.path.join(base_dir, supplier_info.get("csv_path"))
    delimiter = supplier_info.get("delimiter", ",")

    if not os.path.exists(csv_path):
        print(f"‚ùå –§–∞–π–ª –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –¥–ª—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {supplier_id} –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∑–∞ —à–ª—è—Ö–æ–º: {csv_path}")
        return

    log_message(f"‚öôÔ∏è –ó–∞–ø—É—Å–∫–∞—é –æ–±—Ä–æ–±–∫—É –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –¥–ª—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {supplier_id}.", log_file_path)

    # –°–ø–∏—Å–æ–∫ —Å–ª—ñ–≤ –¥–ª—è –≤–∏–¥–∞–ª–µ–Ω–Ω—è —Ä—è–¥–∫—ñ–≤
    words_to_filter_from_name = ["jos", "a-toys"]
    words_to_filter_from_brand = ["toyfa"]

    temp_file_path = f"{csv_path}.temp"
    processed_rows = []
    skipped_rows = 0
    total_rows = 0

    try:
        with open(csv_path, "r", newline="", encoding="utf-8") as infile:
            reader = csv.reader(infile, delimiter=delimiter)
            headers = next(reader)
            processed_rows.append(headers)
            
            row_number = 1
            for row in reader:
                row_number += 1
                total_rows += 1

                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∫–æ–ª–æ–Ω–∫–∏ 4 (—Ü—ñ–Ω–∞) –Ω–∞ –Ω–∞—è–≤–Ω—ñ—Å—Ç—å –ª—ñ—Ç–µ—Ä
                if len(row) > 3:
                    price_value = row[3]
                    if re.search(r'[a-zA-Z]', price_value):
                        log_message(f"üö´ –í–∏–¥–∞–ª–µ–Ω–æ —Ä—è–¥–æ–∫ {row_number} —á–µ—Ä–µ–∑ –Ω–∞—è–≤–Ω—ñ—Å—Ç—å –ª—ñ—Ç–µ—Ä —É –∫–æ–ª–æ–Ω—Ü—ñ 4 (—Ü—ñ–Ω–∞): '{price_value}'.", log_file_path)
                        skipped_rows += 1
                        continue

                # –§—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è –∑–∞ –∫–æ–ª–æ–Ω–∫–æ—é 3 (–Ω–∞–∑–≤–∞)
                if len(row) > 2:
                    product_name = row[2].lower()
                    if any(word in product_name for word in words_to_filter_from_name):
                        log_message(f"üö´ –í–∏–¥–∞–ª–µ–Ω–æ —Ä—è–¥–æ–∫ {row_number} —á–µ—Ä–µ–∑ –∑–∞–±–æ—Ä–æ–Ω–µ–Ω–µ —Å–ª–æ–≤–æ –≤ –Ω–∞–∑–≤—ñ ('{row[2]}').", log_file_path)
                        skipped_rows += 1
                        continue
                
                # –§—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è –∑–∞ –∫–æ–ª–æ–Ω–∫–æ—é 8 (–±—Ä–µ–Ω–¥)
                if len(row) > 7:
                    brand_name = row[7].lower()
                    if any(word in brand_name for word in words_to_filter_from_brand):
                        log_message(f"üö´ –í–∏–¥–∞–ª–µ–Ω–æ —Ä—è–¥–æ–∫ {row_number} —á–µ—Ä–µ–∑ –∑–∞–±–æ—Ä–æ–Ω–µ–Ω–µ —Å–ª–æ–≤–æ –≤ –±—Ä–µ–Ω–¥—ñ ('{row[7]}').", log_file_path)
                        skipped_rows += 1
                        continue

                # –ü–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è –∫–æ–ª–æ–Ω–∫–∏ 4 (—Ü—ñ–Ω–∞) –∑ float –Ω–∞ int
                if len(row) > 3 and row[3]:
                    try:
                        row[3] = str(int(float(row[3])))
                    except (ValueError, IndexError):
                        log_message(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –ø–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ü—ñ–Ω–∏ –≤ —Ä—è–¥–∫—É {row_number}. –ó–Ω–∞—á–µ–Ω–Ω—è: '{row[3]}'", log_file_path)
                
                # –ó–∞–º—ñ–Ω–∞ –∑–Ω–∞—á–µ–Ω–Ω—è –≤ –∫–æ–ª–æ–Ω—Ü—ñ 7 (–∫–∞—Ç–µ–≥–æ—Ä—ñ—è)
                if len(row) > 6 and row[6] == ">3":
                    row[6] = "4"
                    
                processed_rows.append(row)
    
    except Exception as e:
        log_message(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –æ–±—Ä–æ–±–∫–∏ —Ñ–∞–π–ª—É: {e}", log_file_path)
        print(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –æ–±—Ä–æ–±–∫–∏ —Ñ–∞–π–ª—É: {e}")
        return

    with open(temp_file_path, "w", newline="", encoding="utf-8") as outfile:
        writer = csv.writer(outfile, delimiter=delimiter)
        writer.writerows(processed_rows)

    os.replace(temp_file_path, csv_path)

    log_message(f"üéâ –û–±—Ä–æ–±–∫—É –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –¥–ª—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {supplier_id} –∑–∞–≤–µ—Ä—à–µ–Ω–æ.", log_file_path)
    log_message(f"--- –ü—ñ–¥—Å—É–º–æ–∫ –æ–±—Ä–æ–±–∫–∏: ---", log_file_path)
    log_message(f"üì¶ –í—Å—å–æ–≥–æ —Ä—è–¥–∫—ñ–≤ —É —Ñ–∞–π–ª—ñ: {total_rows}", log_file_path)
    log_message(f"üóëÔ∏è –í–∏–¥–∞–ª–µ–Ω–æ —Ä—è–¥–∫—ñ–≤: {skipped_rows}", log_file_path)
    log_message(f"‚úÖ –û–±—Ä–æ–±–ª–µ–Ω—ñ —Ä—è–¥–∫–∏: {len(processed_rows) - 1}", log_file_path)
    print("‚úÖ –û–±—Ä–æ–±–∫–∞ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –î–µ—Ç–∞–ª—ñ –≤ –ª–æ–≥-—Ñ–∞–π–ª—ñ.")