import os
import yaml
import logging
import pymysql
import csv
from datetime import datetime


# --- 1. –ó–ê–í–ê–ù–¢–ê–ñ–ï–ù–ù–Ø –ù–ê–õ–ê–®–¢–£–í–ê–ù–¨ OPENCART ---
def load_oc_settings():
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó –∑ oc_settings.yaml
    """
    # –ë—É–¥—É—î–º–æ —à–ª—è—Ö –¥–æ —Ñ–∞–π–ª—É. 
    # os.path.dirname(__file__) ‚Äî —Ü–µ –ø–∞–ø–∫–∞, –¥–µ –ª–µ–∂–∏—Ç—å —Ü–µ–π —Å–∫—Ä–∏–ø—Ç.
    # ".." ‚Äî –≤–∏—Ö—ñ–¥ –Ω–∞ —Ä—ñ–≤–µ–Ω—å –≤–∏—â–µ.
    # –í–∫–∞–∑—É—î–º–æ –Ω–æ–≤–µ —ñ–º'—è —Ñ–∞–π–ª—É –∑ —Ä–æ–∑—à–∏—Ä–µ–Ω–Ω—è–º .yaml
    config_path = os.path.join(os.path.dirname(__file__), "..", "oc_config", "oc_settings.yaml")

    try:
        with open(config_path, "r", encoding="utf-8") as f:
            # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ safe_load, —Ü–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç –±–µ–∑–ø–µ–∫–∏ –¥–ª—è YAML
            return yaml.safe_load(f)

    except FileNotFoundError:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: oc_settings.yaml –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∑–∞ —à–ª—è—Ö–æ–º: {config_path}")
        return None

    except yaml.YAMLError as exc:
        # yaml.YAMLError ‚Äî —Ü–µ –∞–Ω–∞–ª–æ–≥ json.JSONDecodeError –¥–ª—è YAML
        if hasattr(exc, 'problem_mark'):
            mark = exc.problem_mark
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å—É YAML —É —Ä—è–¥–∫—É {mark.line + 1}, —Å—Ç–æ–≤–ø—á–∏–∫ {mark.column + 1}")
        else:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: —Ñ–∞–π–ª oc_settings.yaml –ø–æ—à–∫–æ–¥–∂–µ–Ω–∏–π.")
        return None

# --- 2. –ü–Ü–î–ö–õ–Æ–ß–ï–ù–ù–Ø –î–û –ë–î OPENCART ---
def oc_connect_db():
    """
    –ü–æ–≤–µ—Ä—Ç–∞—î –∞–∫—Ç–∏–≤–Ω–µ –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ –±–∞–∑–∏ OpenCart
    """
    settings = load_oc_settings()
    
    # –ë–∞–∑–æ–≤–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞: —á–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–∏–≤—Å—è —Ñ–∞–π–ª —ñ —á–∏ —î –≥–æ–ª–æ–≤–Ω–∏–π –±–ª–æ–∫
    if not settings or "db" not in settings:
        raise Exception("‚ùå –ù–µ–º–æ–∂–ª–∏–≤–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ DB-–Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –∑ oc_settings.yaml")

    db = settings["db"]

    try:
        connection = pymysql.connect(
            host=db["host"],       # –Ø–∫—â–æ –∫–ª—é—á–∞ –Ω–µ–º–∞—î –≤ YAML ‚Äî –≤–∏–ª–µ—Ç–∏—Ç—å KeyError
            user=db["user"],
            password=db["password"], 
            database=db["database"],
            port=db.get("port", 3306), # .get() –¥–æ–∑–≤–æ–ª—è—î –ø–æ—Ä—Ç—É –±—É—Ç–∏ –Ω–µ–æ–±–æ–≤'—è–∑–∫–æ–≤–∏–º
            charset="utf8mb4",
            cursorclass=pymysql.cursors.DictCursor
        )
        return connection

    # –û–∫—Ä–µ–º–æ –ª–æ–≤–∏–º–æ –≤—ñ–¥—Å—É—Ç–Ω—ñ—Å—Ç—å –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω—å ("–ª—ñ–Ω–∏–≤–∞" –≤–∞–ª—ñ–¥–∞—Ü—ñ—è)
    except KeyError as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó: —É —Ñ–∞–π–ª—ñ YAML –≤—ñ–¥—Å—É—Ç–Ω—ñ–π –æ–±–æ–≤'—è–∑–∫–æ–≤–∏–π –ø–∞—Ä–∞–º–µ—Ç—Ä {e}")
        return None

    # –û–∫—Ä–µ–º–æ –ª–æ–≤–∏–º–æ –ø–æ–º–∏–ª–∫–∏ —Å–∞–º–æ–≥–æ –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è (–Ω–µ–≤—ñ—Ä–Ω–∏–π –ø–∞—Ä–æ–ª—å, —Å–µ—Ä–≤–µ—Ä –ª–µ–∂–∏—Ç—å)
    except pymysql.MySQLError as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ –ë–î OpenCart: {e}")
        return None
        
    except Exception as e:
        print(f"‚ùå –ù–µ–ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–∞ –ø–æ–º–∏–ª–∫–∞: {e}")
        return None

# --- 3. –°–¢–í–û–†–ï–ù–ù–Ø –ù–û–í–û–ì–û –õ–û–ì-–§–ê–ô–õ–£ (–û–ß–ò–°–¢–ö–ê/–ê–†–•–Ü–í–ê–¶–Ü–Ø) ---
def oc_setup_new_log_file():
    """
    –°—Ç–≤–æ—Ä—é—î –Ω–æ–≤–∏–π –ª–æ–≥-—Ñ–∞–π–ª.
    """
    settings = load_oc_settings()
    
    # 1. –ë–µ—Ä–µ–º–æ —à–ª—è—Ö –ø—Ä—è–º–æ –∑ YAML 
    log_path = settings["paths"]["log_path"]
    
    # –í–∏–∑–Ω–∞—á–∞—î–º–æ –ø–∞–ø–∫—É (logs), —â–æ–± —Å—Ç–≤–æ—Ä–∏—Ç–∏ —ó—ó, —è–∫—â–æ –Ω–µ–º–∞—î
    log_dir = os.path.dirname(log_path)
    os.makedirs(log_dir, exist_ok=True)

    # 2. –ê—Ä—Ö—ñ–≤–∞—Ü—ñ—è —Å—Ç–∞—Ä–æ–≥–æ —Ñ–∞–π–ª—É
    if os.path.exists(log_path):
        try:
            timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
            archive_name = f"oc_logs_{timestamp}.log"
            
            # –ê—Ä—Ö—ñ–≤ –∫–ª–∞–¥–µ–º–æ –≤ —Ç—É –∂ –ø–∞–ø–∫—É
            archive_path = os.path.join(log_dir, archive_name)
            
            os.rename(log_path, archive_path)
            print(f"üì¶ –°—Ç–∞—Ä–∏–π –ª–æ–≥ –∞—Ä—Ö—ñ–≤–æ–≤–∞–Ω–æ: {archive_name}")
        except OSError as e:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∞—Ä—Ö—ñ–≤–∞—Ü—ñ—ó: {e}")

    # 3. –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ª–æ–≥—É–≤–∞–Ω–Ω—è
    try:
        logging.basicConfig(
            filename=log_path,
            level=logging.INFO,
            format="%(asctime)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            filemode="w",
            force=True
        )
        logging.info("--- –ù–æ–≤–∏–π —Å–µ–∞–Ω—Å –ª–æ–≥—É–≤–∞–Ω–Ω—è OpenCart —Ä–æ–∑–ø–æ—á–∞—Ç–æ ---")
        print(f"‚úÖ –õ–æ–≥ —Ñ–∞–π–ª —Å—Ç–≤–æ—Ä–µ–Ω–æ: {log_path}")
        
    except Exception as e:
        print(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ –ª–æ–≥-—Ñ–∞–π–ª: {e}")

# --- 4. –î–û–ü–ò–°–£–í–ê–ù–ù–Ø –í –Ü–°–ù–£–Æ–ß–ò–ô oc_logs.log ---
def oc_log_message(message=None):
    """
    –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î –ª–æ–≥—É–≤–∞–Ω–Ω—è –∞–±–æ –¥–æ–ø–∏—Å—É—î –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è.
    –ü—Ä–∏ –∑–∞–ø—É—Å–∫—É –Ω–æ–≤–æ–≥–æ —Å–∫—Ä–∏–ø—Ç–∞ –∑ –ª–∞–Ω—Ü—é–∂–∫–∞ ‚Äî —á–∏—Ç–∞—î —à–ª—è—Ö –∑ YAML —ñ –ø—ñ–¥—Ö–æ–ø–ª—é—î —ñ—Å–Ω—É—é—á–∏–π —Ñ–∞–π–ª.
    """
    
    # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞: —á–∏ –ª–æ–≥—É–≤–∞–Ω–Ω—è –í–ñ–ï –Ω–∞–ª–∞—à—Ç–æ–≤–∞–Ω–µ —É –ø–æ—Ç–æ—á–Ω–æ–º—É –∑–∞–ø—É—â–µ–Ω–æ–º—É —Å–∫—Ä–∏–ø—Ç—ñ?
    # –Ø–∫—â–æ –Ω—ñ (—Ü–µ –ø–µ—Ä—à–∏–π –≤–∏–∫–ª–∏–∫ —É —Ü—å–æ–º—É —Å–∫—Ä–∏–ø—Ç—ñ) ‚Äî –Ω–∞–ª–∞—à—Ç–æ–≤—É—î–º–æ.
    if not logging.getLogger().hasHandlers():
        
        # 1. –ß–∏—Ç–∞—î–º–æ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è, —â–æ–± –∑–Ω–∞—Ç–∏ –ö–£–î–ò –ø–∏—Å–∞—Ç–∏
        settings = load_oc_settings()
        log_path = settings["paths"]["log_path"]

        # 2. –ü–µ—Ä–µ–∫–æ–Ω—É—î–º–æ—Å—å, —â–æ –ø–∞–ø–∫–∞ —ñ—Å–Ω—É—î (–ø—Ä–æ –≤—Å—è–∫ –≤–∏–ø–∞–¥–æ–∫)
        log_dir = os.path.dirname(log_path)
        os.makedirs(log_dir, exist_ok=True)

        # 3. –ü—ñ–¥–∫–ª—é—á–∞—î–º–æ—Å—å –¥–æ —Ñ–∞–π–ª—É –≤ —Ä–µ–∂–∏–º—ñ 'a' (append - –¥–æ–ø–∏—Å—É–≤–∞–Ω–Ω—è)
        logging.basicConfig(
            filename=log_path,
            level=logging.INFO,
            format="%(asctime)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            filemode="a" 
        )

    # --- –õ–æ–≥—ñ–∫–∞ –∑–∞–ø–∏—Å—É ---
    
    # –Ø–∫—â–æ –ø–µ—Ä–µ–¥–∞–ª–∏ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è ‚Äî –ø–∏—à–µ–º–æ –π–æ–≥–æ —ñ –≤ —Ñ–∞–π–ª, —ñ –≤ –∫–æ–Ω—Å–æ–ª—å
    if message:
        logging.info(message)
        print(f"üìù {message}")
    
    # –Ø–∫—â–æ message=None, –º–∏ –Ω—ñ—á–æ–≥–æ –Ω–µ —Ä–æ–±–∏–º–æ (–ø—Ä–æ—Å—Ç–æ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É–≤–∞–ª–∏ –ª–æ–≥–µ—Ä –≤–∏—â–µ).

# --- 5. –ó–ê–í–ê–ù–¢–ê–ñ–ï–ù–ù–Ø –§–ê–ô–õ–£ attribute.csv ---
def load_attributes_csv():
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –∞—Ç—Ä–∏–±—É—Ç–∏. 
    –ü–æ–≤–µ—Ä—Ç–∞—î —Å–ª–æ–≤–Ω–∏–∫ –∑–∞–º—ñ–Ω, –¥–µ –∑–Ω–∞—á–µ–Ω–Ω—è ‚Äî —Ü–µ –∫–æ—Ä—Ç–µ–∂ (UA_Standard, RU_Translation).
    –û—Å—Ç–∞–Ω–Ω—è –∫–æ–ª–æ–Ω–∫–∞ —Ñ–∞–π–ª—É –≤–≤–∞–∂–∞—î—Ç—å—Å—è —Ä–æ—Å—ñ–π—Å—å–∫–∏–º –ø–µ—Ä–µ–∫–ª–∞–¥–æ–º.
    """
    settings = load_oc_settings()
    if not settings:
        return {}, []

    attribute_path = settings["paths"]["attribute"]
    replacements_map = {}
    raw_data = []
    
    # –û–Ω–æ–≤–ª–µ–Ω–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ (–¥–æ–¥–∞–Ω–æ Russian –≤ –∫—ñ–Ω—Ü—ñ)
    default_header = ["column_name", "attr_site_name", "atr_a", "atr_b", "atr_c", "atr_d", "atr_e", "atr_f", "atr_g", "atr_h", "atr_i", "Russian"]
    current_block_name = None

    try:
        with open(attribute_path, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            
            try:
                header = next(reader)
                raw_data.append(header)
                max_row_len = len(header)
            except StopIteration:
                return {}, [default_header]

            for row in reader:
                # –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è –¥–æ–≤–∂–∏–Ω–∏ —Ä—è–¥–∫–∞
                current_len = len(row)
                if current_len < max_row_len:
                    row = row + [''] * (max_row_len - current_len)
                else:
                    row = row[:max_row_len]
                
                raw_data.append(row)
                
                first_cell = row[0].strip()

                # 1. –ü–æ—á–∞—Ç–æ–∫ –±–ª–æ–∫—É (–Ω–∞–∑–≤–∞ –∞—Ç—Ä–∏–±—É—Ç–∞, –Ω–∞–ø—Ä–∏–∫–ª–∞–¥ "–û—Å–Ω–æ–≤–∞|ua")
                if first_cell:
                    current_block_name = first_cell
                    if current_block_name not in replacements_map:
                        replacements_map[current_block_name] = {}
                
                # 2. –†—è–¥–æ–∫ –∑—ñ –∑–Ω–∞—á–µ–Ω–Ω—è–º–∏
                elif current_block_name is not None and len(row) >= 3:
                    
                    # UA Standard - –∫–æ–ª–æ–Ω–∫–∞ 1
                    ua_std = row[1].strip()
                    
                    # RU Translation - –û–°–¢–ê–ù–ù–Ø –∫–æ–ª–æ–Ω–∫–∞ (-1)
                    ru_std = row[-1].strip()

                    # –Ø–∫—â–æ –Ω–µ–º–∞—î UA –∑–Ω–∞—á–µ–Ω–Ω—è, —Ä—è–¥–æ–∫ –ø–æ—Ä–æ–∂–Ω—ñ–π –∞–±–æ —Å–ª—É–∂–±–æ–≤–∏–π -> –ø—Ä–æ–ø—É—Å–∫–∞—î–º–æ –ª–æ–≥—ñ–∫—É –∑–∞–º—ñ–Ω
                    if not ua_std:
                        continue

                    # –°–∏–Ω–æ–Ω—ñ–º–∏ ‚Äî —Ü–µ –≤—Å–µ –º—ñ–∂ UA (index 1) —Ç–∞ RU (index -1)
                    # –¢–æ–±—Ç–æ slice [2:-1]
                    synonyms = row[2:-1]

                    for original in synonyms:
                        original = original.strip().lower()
                        if original:
                            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –ü–ê–†–£: (UA, RU)
                            replacements_map[current_block_name][original] = (ua_std, ru_std)

        return replacements_map, raw_data
    
    except Exception as e:
        logging.error(f"–ü–æ–º–∏–ª–∫–∞ attribute.csv: {e}")
        return {}, [default_header]

# --- 6. –ó–ë–ï–†–ï–ñ–ï–ù–ù–Ø –§–ê–ô–õ–£ attribute.csv ---    
def save_attributes_csv(raw_data):
    """
    –ó–±–µ—Ä—ñ–≥–∞—î –æ–Ω–æ–≤–ª–µ–Ω—ñ —Å–∏—Ä—ñ –¥–∞–Ω—ñ —É attribute.csv.
    """
    settings = load_oc_settings()
    if not settings or "paths" not in settings or "attribute" not in settings["paths"]:
        logging.error("‚ùå –£ settings.json –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ paths.attribute")
        return {}, []
    attribute_path = settings["paths"]["attribute"]
    try:
        # 'newline=''' –≤–∞–∂–ª–∏–≤–∏–π –¥–ª—è –∫–æ—Ä–µ–∫—Ç–Ω–æ–≥–æ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è CSV –Ω–∞ —Ä—ñ–∑–Ω–∏—Ö –û–°
        with open(attribute_path, 'w', encoding='utf-8', newline='') as f:
            writer = csv.writer(f)
            writer.writerows(raw_data)
        logging.info("–§–∞–π–ª –∞—Ç—Ä–∏–±—É—Ç—ñ–≤ attribute.csv –æ–Ω–æ–≤–ª–µ–Ω–æ.")
    except Exception as e:
        logging.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—ñ —Ñ–∞–π–ª—É –∞—Ç—Ä–∏–±—É—Ç—ñ–≤ attribute.csv: {e}")

# --- 7. –Ü–ú–ü–û–†–¢ –ö–ê–¢–ï–ì–û–†–Ü–ô –ó CSV –í –ë–î OPENCART ---
def oc_import_categories_from_csv():
    """
    –Ü–º–ø–æ—Ä—Ç –∫–∞—Ç–µ–≥–æ—Ä—ñ–π –∑ CSV —É OpenCart –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º path_id
    """
    oc_log_message("‚ñ∂ –°—Ç–∞—Ä—Ç —ñ–º–ø–æ—Ä—Ç—É –∫–∞—Ç–µ–≥–æ—Ä—ñ–π (CSV ‚Üí OpenCart, path_id)")

    csv_path = "/var/www/scripts/update/csv/output/oc_categorii.csv"

    if not os.path.exists(csv_path):
        oc_log_message(f"‚ùå CSV —Ñ–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {csv_path}")
        return

    conn = oc_connect_db()
    if not conn:
        oc_log_message("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –ø—ñ–¥–∫–ª—é—á–∏—Ç–∏—Å—å –¥–æ –ë–î")
        return

    cursor = conn.cursor()

    # –ú–æ–≤–∏ (–∑ —Ç–≤–æ—î—ó –ë–î)
    languages = {
        "uk-ua": 2,
        "ru-ru": 3
    }

    # --- –ª–æ–∫–∞–ª—å–Ω—ñ safe-—Ö–µ–ª–ø–µ—Ä–∏ ---
    def safe_int(v, default=0):
        if v is None:
            return default
        s = str(v).strip()
        if s == "":
            return default
        try:
            return int(s)
        except ValueError:
            try:
                return int(float(s))
            except Exception:
                return default

    def safe_bool(v, default=0):
        if v is None:
            return default
        s = str(v).strip().lower()
        if s in ("1", "true", "yes", "y", "on"):
            return 1
        if s in ("0", "false", "no", "n", "off"):
            return 0
        return default

    imported = 0

    try:
        with open(csv_path, newline="", encoding="utf-8") as f:
            reader = csv.DictReader(f, delimiter=";")

            for row in reader:
                # –ø—Ä–∏–±–∏—Ä–∞—î–º–æ BOM
                row = {k.lstrip("\ufeff").strip(): (v if v is not None else "") for k, v in row.items()}

                category_id = safe_int(row.get("category_id"), None)
                if category_id is None:
                    oc_log_message("‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ —Ä—è–¥–æ–∫ –±–µ–∑ category_id")
                    continue

                parent_id = safe_int(row.get("parent_id"), 0)
                sort_order = safe_int(row.get("sort_order"), 0)

                image = row.get("image_name") or None
                top = safe_bool(row.get("top"), 0)
                column_value = safe_int(row.get("column"), 1)
                status = safe_bool(row.get("status"), 1)

                page_group_links = row.get("page_group_links") or ""
                date_added = row.get("date_added") or "2000-01-01 00:00:00"
                date_modified = row.get("date_modified") or date_added

                # --- oc_category ---
                cursor.execute("""
                    DELETE FROM oc_seo_url
                    WHERE query = %s
                    """, (f"category_id={category_id}",))
                cursor.execute(
                    """
                    INSERT INTO oc_category
                    (category_id, image, parent_id, top, `column`,
                     sort_order, status, page_group_links,
                     date_added, date_modified)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                    ON DUPLICATE KEY UPDATE
                        image = VALUES(image),
                        parent_id = VALUES(parent_id),
                        top = VALUES(top),
                        `column` = VALUES(`column`),
                        sort_order = VALUES(sort_order),
                        status = VALUES(status),
                        page_group_links = VALUES(page_group_links),
                        date_modified = VALUES(date_modified)
                    """,
                    (
                        category_id,
                        image,
                        parent_id,
                        top,
                        column_value,
                        sort_order,
                        status,
                        page_group_links,
                        date_added,
                        date_modified
                    )
                )

                # --- oc_category_description ---
                for code, language_id in languages.items():
                    cursor.execute(
                        """
                        INSERT INTO oc_category_description
                        (category_id, language_id, name, description, description2,
                         meta_title, meta_description, meta_keyword)
                        VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                        ON DUPLICATE KEY UPDATE
                            name = VALUES(name),
                            description = VALUES(description),
                            description2 = VALUES(description2),
                            meta_title = VALUES(meta_title),
                            meta_description = VALUES(meta_description),
                            meta_keyword = VALUES(meta_keyword)
                        """,
                        (
                            category_id,
                            language_id,
                            row.get(f"name({code})", "") or "",
                            row.get(f"description({code})", "") or "",
                            row.get(f"description2({code})", "") or "",
                            row.get(f"meta_title({code})", "") or "",
                            row.get(f"meta_description({code})", "") or "",
                            row.get(f"meta_keywords({code})", "") or ""
                        )
                    )

                # --- oc_seo_url ---
                seo_map = [
                    (2, "uk-ua"),
                    (3, "ru-ru"),
                ]
                for lang_id, suffix in seo_map:
                    seo_keyword = row.get(f"seo_keyword({suffix})")

                    if seo_keyword:
                        cursor.execute("""
                            INSERT INTO oc_seo_url
                            (store_id, language_id, query, keyword)
                            VALUES (0, %s, %s, %s)
                        """, (
                            lang_id,
                            f"category_id={category_id}",
                            seo_keyword.strip()
                        ))
                # --- oc_category_to_store ---
                cursor.execute(
                    "INSERT IGNORE INTO oc_category_to_store (category_id, store_id) VALUES (%s, %s)",
                    (category_id, 0)
                )

                # --- oc_category_path (CSV path_id) ---
                cursor.execute(
                    "DELETE FROM oc_category_path WHERE category_id = %s",
                    (category_id,)
                )

                path_raw = row.get("path_id", "").strip()
                if path_raw:
                    path_parts = [safe_int(x) for x in path_raw.split(">") if safe_int(x) > 0]
                else:
                    path_parts = [category_id]

                for level, path_id in enumerate(path_parts):
                    cursor.execute(
                        """
                        INSERT INTO oc_category_path (category_id, path_id, level)
                        VALUES (%s, %s, %s)
                        """,
                        (category_id, path_id, level)
                    )

                imported += 1

        conn.commit()
        oc_log_message(f"‚úÖ –Ü–º–ø–æ—Ä—Ç –∫–∞—Ç–µ–≥–æ—Ä—ñ–π –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –û–±—Ä–æ–±–ª–µ–Ω–æ: {imported}")

    except Exception as e:
        conn.rollback()
        oc_log_message(f"‚ùå –ü–æ–º–∏–ª–∫–∞ —ñ–º–ø–æ—Ä—Ç—É –∫–∞—Ç–µ–≥–æ—Ä—ñ–π: {e}")

    finally:
        cursor.close()
        conn.close()

# --- 8. –ó–ê–í–ê–ù–¢–ê–ñ–ï–ù–ù–Ø –ö–ê–¢–ï–ì–û–†–Ü–ô (–ù–æ–≤–∞ –ª–æ–≥—ñ–∫–∞)
def load_category_csv():
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –ø—Ä–∞–≤–∏–ª–∞ –º–∞–ø—ñ–Ω–≥—É –∑ category.csv.
    –ü–æ–≤–µ—Ä—Ç–∞—î:
    1. category_map: –°–ª–æ–≤–Ω–∏–∫ {(name1, name2, name3): {'id':..., 'ua':..., 'ru':...}}
    2. fieldnames: –°–ø–∏—Å–æ–∫ –∑–∞–≥–æ–ª–æ–≤–∫—ñ–≤ —Ñ–∞–π–ª—É (—â–æ–± –∑–Ω–∞—Ç–∏, —è–∫ –¥–æ–ø–∏—Å—É–≤–∞—Ç–∏ –Ω–æ–≤—ñ).
    """
    settings = load_oc_settings()
    category_csv_path = settings['paths']['category_csv']
    category_map = {}
    
    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ñ –∑–∞–≥–æ–ª–æ–≤–∫–∏, —è–∫—â–æ —Ñ–∞–π–ª –ø–æ—Ä–æ–∂–Ω—ñ–π
    fieldnames = ['name_1', 'name_2', 'name_3', 'category_name', 'category', '–ö–∞—Ç–µ–≥–æ—Ä—ñ—è|ua', '–ö–∞—Ç–µ–≥–æ—Ä–∏—è|ru']

    try:
        with open(category_csv_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            
            if reader.fieldnames:
                fieldnames = reader.fieldnames

            for row in reader:
                # –û—á–∏—â–∞—î–º–æ —Ç–∞ –ø—Ä–∏–≤–æ–¥–∏–º–æ –¥–æ –Ω–∏–∂–Ω—å–æ–≥–æ —Ä–µ–≥—ñ—Å—Ç—Ä—É –≤—Ö—ñ–¥–Ω—ñ –Ω–∞–∑–≤–∏
                n1 = row.get('name_1', '').strip().lower()
                n2 = row.get('name_2', '').strip().lower()
                n3 = row.get('name_3', '').strip().lower()
                
                # –Ø–∫—â–æ —Ä—è–¥–æ–∫ –ø–æ—Ä–æ–∂–Ω—ñ–π (–Ω–µ–º–∞—î –Ω–∞–∑–≤), –ø—Ä–æ–ø—É—Å–∫–∞—î–º–æ
                if not any([n1, n2, n3]):
                    continue

                # –°–æ—Ä—Ç—É—î–º–æ –¥–ª—è —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è —É–Ω—ñ–∫–∞–ª—å–Ω–æ–≥–æ –∫–ª—é—á–∞ –Ω–µ–∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ –ø–æ—Ä—è–¥–∫—É —Å–ª—ñ–≤ —É —Ç–æ–≤–∞—Ä—ñ
                key = tuple(sorted([n1, n2, n3]))
                
                category_map[key] = {
                    'category': row.get('category', '').strip(),
                    'cat_ua':   row.get('–ö–∞—Ç–µ–≥–æ—Ä—ñ—è|ua', '').strip(),
                    'cat_ru':   row.get('–ö–∞—Ç–µ–≥–æ—Ä–∏—è|ru', '').strip()
                }

        return category_map, fieldnames

    except FileNotFoundError:
        logging.warning(f"–§–∞–π–ª 'category.csv' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ. –ë—É–¥–µ —Å—Ç–≤–æ—Ä–µ–Ω–æ –Ω–æ–≤–∏–π –ø—Ä–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—ñ.")
        return {}, fieldnames
    except Exception as e:
        logging.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ —á–∏—Ç–∞–Ω–Ω—ñ category.csv: {e}")
        return {}, fieldnames

# --- 9. –î–û–î–ê–í–ê–ù–ù–Ø –ù–û–í–ò–• –ö–ê–¢–ï–ì–û–†–Ü–ô (Append)
def append_new_categories(new_rows, fieldnames):
    """
    –î–æ–ø–∏—Å—É—î –Ω–æ–≤—ñ –∑–Ω–∞–π–¥–µ–Ω—ñ –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—ó –≤ –∫—ñ–Ω–µ—Ü—å category.csv.
    –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î DictWriter –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç—ñ.
    """
    if not new_rows:
        return

    settings = load_oc_settings()
    category_csv_path = settings['paths']['category_csv']
    
    try:
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ —Ñ–∞–π–ª —ñ—Å–Ω—É—î (—â–æ–± –∑–∞–ø–∏—Å–∞—Ç–∏ —Ö–µ–¥–µ—Ä, —è–∫—â–æ –Ω—ñ)
        file_exists = os.path.isfile(category_csv_path)
        
        with open(category_csv_path, 'a', encoding='utf-8', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            
            if not file_exists:
                writer.writeheader()
            
            # –ó–∞–ø–∏—Å—É—î–º–æ —Ç—ñ–ª—å–∫–∏ –Ω–æ–≤—ñ —Ä—è–¥–∫–∏
            for row in new_rows:
                # –§—ñ–ª—å—Ç—Ä—É—î–º–æ row, –∑–∞–ª–∏—à–∞—é—á–∏ —Ç—ñ–ª—å–∫–∏ —Ç—ñ –∫–ª—é—á—ñ, —â–æ —î –≤ fieldnames
                clean_row = {k: row.get(k, '') for k in fieldnames}
                writer.writerow(clean_row)
                
        logging.info(f"–£ —Ñ–∞–π–ª category.csv –¥–æ–¥–∞–Ω–æ {len(new_rows)} –Ω–æ–≤–∏—Ö –ø—Ä–∞–≤–∏–ª.")
        
    except Exception as e:
        logging.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å—É –≤ category.csv: {e}")

# --- 10.  –ó–ê–í–ê–ù–¢–ê–ñ–ï–ù–ù–Ø –ü–û–ó–ù–ê–ß–û–ö (–í–∏–ø—Ä–∞–≤–ª–µ–Ω–æ —à–ª—è—Ö)
def load_poznachky_csv():
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î —Å–ø–∏—Å–æ–∫ —Ç–µ–≥—ñ–≤ –∑ poznachky.csv.
    """
    settings = load_oc_settings()
    poznachky_csv_path = settings['paths']['poznachky_csv'] 
    
    poznachky_list = []
    
    try:
        with open(poznachky_csv_path, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            # –ü—Ä–æ–±—É—î–º–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫, —è–∫—â–æ –≤—ñ–Ω —î
            try:
                first_row = next(reader)
                # –Ø–∫—â–æ –ø–µ—Ä—à–∏–π —Ä—è–¥–æ–∫ —Å—Ö–æ–∂–∏–π –Ω–∞ –∑–∞–≥–æ–ª–æ–≤–æ–∫, —ñ–≥–Ω–æ—Ä—É—î–º–æ, —ñ–Ω–∞–∫—à–µ –¥–æ–¥–∞—î–º–æ
                if first_row and "poznachky" not in first_row[0].lower():
                     poznachky_list.append(first_row[0].strip().lower())
            except StopIteration:
                pass 

            for row in reader:
                if row and row[0].strip():
                    poznachky_list.append(row[0].strip().lower())

        # –°–æ—Ä—Ç—É—î–º–æ: —Å–ø–æ—á–∞—Ç–∫—É –¥–æ–≤–≥—ñ —Ñ—Ä–∞–∑–∏, —â–æ–± "–≤—ñ–±—Ä–∞—Ç–æ—Ä –∫—Ä–æ–ª–∏–∫" –∑–Ω–∞–π—à–æ–≤—Å—è —Ä–∞–Ω—ñ—à–µ –Ω—ñ–∂ –ø—Ä–æ—Å—Ç–æ "–≤—ñ–±—Ä–∞—Ç–æ—Ä"
        poznachky_list.sort(key=len, reverse=True)
        return poznachky_list
    
    except FileNotFoundError:
        logging.warning(f"–§–∞–π–ª –ø–æ–∑–Ω–∞—á–æ–∫ '{poznachky_csv_path}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ. –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ.")
        return []
    except Exception as e:
        logging.error(f"–ü–æ–º–∏–ª–∫–∞ poznachky.csv: {e}")
        return []

# --- –ü–ï–†–ï–í–Ü–†–ö–ê CSV ---
def check_csv_data(profile_id):
    """
    –ü–µ—Ä–µ–≤—ñ—Ä—è—î CSV-—Ñ–∞–π–ª –Ω–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω—ñ—Å—Ç—å –ø—Ä–∞–≤–∏–ª–∞–º, –≤–∏–∑–Ω–∞—á–µ–Ω–∏–º —É oc_settings.json.

    Args:
        profile_id (str): ID –ø—Ä–æ—Ñ—ñ–ª—é –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ –∑ 'validation_profiles' –≤ oc_settings.json.

    Returns:
        bool: True, —è–∫—â–æ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ –ø—Ä–æ–π—à–ª–∞ —É—Å–ø—ñ—à–Ω–æ, —ñ–Ω–∞–∫—à–µ False.
    """

    # 0. –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –ª–æ–≥—É–≤–∞–Ω–Ω—è
    oc_log_message(f"üîé –°—Ç–∞—Ä—Ç –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ CSV (–ø—Ä–æ—Ñ—ñ–ª—å: {profile_id})")

    # 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω—å
    settings = load_oc_settings()
    if not settings:
        oc_log_message("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ oc_settings.json")
        return False

    profiles = settings.get("validation_profiles", {})
    if profile_id not in profiles:
        oc_log_message(f"‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –ø—Ä–æ—Ñ—ñ–ª—å –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó –∑ ID '{profile_id}'")
        return False

    # 2. –î–∞–Ω—ñ –ø—Ä–æ—Ñ—ñ–ª—é
    profile = profiles[profile_id]
    csv_path_relative = profile.get("path")
    validation_rules = profile.get("rules")

    if not csv_path_relative or validation_rules is None:
        oc_log_message("‚ùå –ù–µ–ø–æ–≤–Ω—ñ –¥–∞–Ω—ñ –≤ –ø—Ä–æ—Ñ—ñ–ª—ñ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó")
        return False

    # 3. –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ñ–∞–π–ª—É
    base_dir = os.path.join(os.path.dirname(__file__), "..")
    full_csv_path = os.path.join(base_dir, csv_path_relative)

    if not os.path.exists(full_csv_path):
        oc_log_message(f"‚ùå CSV —Ñ–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {full_csv_path}")
        return False

    oc_log_message(f"üìÑ –ü–µ—Ä–µ–≤—ñ—Ä—è—î—Ç—å—Å—è —Ñ–∞–π–ª: {full_csv_path}")

    # 4. –ß–∏—Ç–∞–Ω–Ω—è —Ç–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—è CSV
    try:
        with open(full_csv_path, "r", encoding="utf-8") as f:
            reader = csv.reader(f)

            try:
                headers = next(reader)
            except StopIteration:
                oc_log_message("‚ùå CSV —Ñ–∞–π–ª –ø–æ—Ä–æ–∂–Ω—ñ–π (–≤—ñ–¥—Å—É—Ç–Ω—ñ –∑–∞–≥–æ–ª–æ–≤–∫–∏)")
                return False

            # 5. –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫—ñ–≤
            expected_columns = list(validation_rules.keys())
            headers_set = set(headers)

            for col_name in expected_columns:
                if col_name not in headers_set:
                    oc_log_message(f"‚ùå –í—ñ–¥—Å—É—Ç–Ω—è –æ–±–æ–≤ º—è–∑–∫–æ–≤–∞ –∫–æ–ª–æ–Ω–∫–∞: '{col_name}'")
                    return False

            header_map = {name: idx for idx, name in enumerate(headers)}

            # 6. –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ä—è–¥–∫—ñ–≤
            for i, row in enumerate(reader):
                row_number = i + 2

                if not row or all(not col.strip() for col in row):
                    oc_log_message(f"‚ÑπÔ∏è –†—è–¥–æ–∫ {row_number} –ø–æ—Ä–æ–∂–Ω—ñ–π ‚Äî –ø—Ä–æ–ø—É—â–µ–Ω–æ")
                    continue

                for col_name, rule_type in validation_rules.items():
                    col_index = header_map.get(col_name)

                    if col_index is None or col_index >= len(row):
                        oc_log_message(f"‚ùå –†—è–¥–æ–∫ {row_number}: –Ω–µ–∫–æ—Ä–µ–∫—Ç–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ CSV")
                        return False

                    value = row[col_index].strip()

                    # 6.1 not_empty
                    if rule_type == "not_empty":
                        if not value:
                            oc_log_message(f"‚ùå –†—è–¥–æ–∫ {row_number}, '{col_name}': –ø–æ–ª–µ –Ω–µ –ø–æ–≤–∏–Ω–Ω–æ –±—É—Ç–∏ –ø–æ—Ä–æ–∂–Ω—ñ–º")
                            return False
                        continue

                    # 6.2 integer
                    if rule_type == "integer":
                        if not value or not value.lstrip("-").isdigit():
                            oc_log_message(
                                f"‚ùå –†—è–¥–æ–∫ {row_number}, '{col_name}': –æ—á—ñ–∫—É—î—Ç—å—Å—è —Ü—ñ–ª–µ —á–∏—Å–ª–æ, –æ—Ç—Ä–∏–º–∞–Ω–æ '{value}'"
                            )
                            return False

                    # 6.3 integer_or_empty
                    elif rule_type == "integer_or_empty":
                        if value and not value.lstrip("-").isdigit():
                            oc_log_message(
                                f"‚ùå –†—è–¥–æ–∫ {row_number}, '{col_name}': –æ—á—ñ–∫—É—î—Ç—å—Å—è —Ü—ñ–ª–µ —á–∏—Å–ª–æ –∞–±–æ –ø–æ—Ä–æ–∂–Ω—î –ø–æ–ª–µ"
                            )
                            return False

                    # 6.4 float_or_empty
                    elif rule_type == "float_or_empty":
                        if value:
                            try:
                                float(value.replace(",", "."))
                            except ValueError:
                                oc_log_message(
                                    f"‚ùå –†—è–¥–æ–∫ {row_number}, '{col_name}': –æ—á—ñ–∫—É—î—Ç—å—Å—è float –∞–±–æ –ø–æ—Ä–æ–∂–Ω—î –ø–æ–ª–µ"
                                )
                                return False

                    # 6.5 datetime
                    elif rule_type == "datetime":
                        if value:
                            try:
                                datetime.strptime(value, "%Y-%m-%dT%H:%M:%S")
                            except ValueError:
                                oc_log_message(
                                    f"‚ùå –†—è–¥–æ–∫ {row_number}, '{col_name}': –Ω–µ–≤—ñ—Ä–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç datetime"
                                )
                                return False

                    # 6.6 —Å–ø–∏—Å–æ–∫ –¥–æ–ø—É—Å—Ç–∏–º–∏—Ö –∑–Ω–∞—á–µ–Ω—å
                    elif isinstance(rule_type, list):
                        if value not in rule_type:
                            oc_log_message(
                                f"‚ùå –†—è–¥–æ–∫ {row_number}, '{col_name}': –∑–Ω–∞—á–µ–Ω–Ω—è '{value}' –Ω–µ –≤—Ö–æ–¥–∏—Ç—å —É {rule_type}"
                            )
                            return False

    except Exception as e:
        oc_log_message(f"‚ùå –ù–µ–≤—ñ–¥–æ–º–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ CSV: {e}")
        return False

    oc_log_message("‚úÖ –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ CSV —É—Å–ø—ñ—à–Ω–∞")
    return True
