import os
import json
import logging
import pymysql
import csv
from datetime import datetime


# --- 1. –ó–ê–í–ê–ù–¢–ê–ñ–ï–ù–ù–Ø –ù–ê–õ–ê–®–¢–£–í–ê–ù–¨ OPENCART ---
def load_oc_settings():
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó –∑ oc_settings.json
    """
    config_path = os.path.join(os.path.dirname(__file__), "..", "config", "oc_settings.json")

    try:
        with open(config_path, "r", encoding="utf-8") as f:
            return json.load(f)

    except FileNotFoundError:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: oc_settings.json –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∑–∞ —à–ª—è—Ö–æ–º: {config_path}")
        return None

    except json.JSONDecodeError:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: —Ñ–∞–π–ª oc_settings.json –ø–æ—à–∫–æ–¥–∂–µ–Ω–∏–π: {config_path}")
        return None

# --- 2. –ü–Ü–î–ö–õ–Æ–ß–ï–ù–ù–Ø –î–û –ë–î OPENCART ---
def oc_connect_db():
    """
    –ü–æ–≤–µ—Ä—Ç–∞—î –∞–∫—Ç–∏–≤–Ω–µ –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ –±–∞–∑–∏ OpenCart
    """
    settings = load_oc_settings()
    if not settings or "db" not in settings:
        raise Exception("‚ùå –ù–µ–º–æ–∂–ª–∏–≤–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ DB-–Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –∑ oc_settings.json")

    db = settings["db"]

    try:
        connection = pymysql.connect(
            host=db["host"],
            user=db["user"],
            password=db["password"],
            database=db["database"],
            port=db.get("port", 3306),
            charset="utf8mb4",
            cursorclass=pymysql.cursors.DictCursor
        )
        return connection

    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ –ë–î OpenCart: {e}")
        return None

# --- 3. –°–¢–í–û–†–ï–ù–ù–Ø –ù–û–í–û–ì–û –õ–û–ì-–§–ê–ô–õ–£ (–û–ß–ò–°–¢–ö–ê/–ê–†–•–Ü–í–ê–¶–Ü–Ø) ---
def oc_setup_new_log_file():
    """
    –°—Ç–≤–æ—Ä—é—î –Ω–æ–≤–∏–π –ª–æ–≥-—Ñ–∞–π–ª oc_logs.log.
    –Ø–∫—â–æ —Ñ–∞–π–ª —ñ—Å–Ω—É—î ‚Äî –ø–µ—Ä–µ–π–º–µ–Ω–æ–≤—É—î –π–æ–≥–æ —É –∞—Ä—Ö—ñ–≤ —ñ–∑ –¥–∞—Ç–æ—é.
    """
    log_path = "/var/www/scripts/update/logs/oc_logs.log"
    log_dir = os.path.dirname(log_path)

    os.makedirs(log_dir, exist_ok=True)

    # –∞—Ä—Ö—ñ–≤–∞—Ü—ñ—è —Å—Ç–∞—Ä–æ–≥–æ —Ñ–∞–π–ª—É
    if os.path.exists(log_path):
        timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        archive_name = f"oc_logs_{timestamp}.log"
        archive_path = os.path.join(log_dir, archive_name)

        try:
            os.rename(log_path, archive_path)
            print(f"üì¶ –°—Ç–∞—Ä–∏–π –ª–æ–≥ oc_logs.log –∞—Ä—Ö—ñ–≤–æ–≤–∞–Ω–æ —è–∫ {archive_name}")
        except OSError as e:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∞—Ä—Ö—ñ–≤–∞—Ü—ñ—ó –ª–æ–≥-—Ñ–∞–π–ª—É: {e}")

    # —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –Ω–æ–≤–æ–≥–æ
    logging.basicConfig(
        filename=log_path,
        level=logging.INFO,
        format="%(asctime)s - %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S",
        filemode="w"
    )

    logging.info("--- –ù–æ–≤–∏–π —Å–µ–∞–Ω—Å –ª–æ–≥—É–≤–∞–Ω–Ω—è OpenCart —Ä–æ–∑–ø–æ—á–∞—Ç–æ ---")
    print("‚úÖ –°—Ç–≤–æ—Ä–µ–Ω–æ –Ω–æ–≤–∏–π —Ñ–∞–π–ª oc_logs.log")

# --- 4. –î–û–ü–ò–°–£–í–ê–ù–ù–Ø –í –Ü–°–ù–£–Æ–ß–ò–ô oc_logs.log ---
def oc_log_message(message=None):
    """
    –î–æ–ø–∏—Å—É—î –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è —É —ñ—Å–Ω—É—é—á–∏–π –ª–æ–≥-—Ñ–∞–π–ª oc_logs.log.
    –Ø–∫—â–æ message –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω–æ ‚Äî –ø—Ä–æ—Å—Ç–æ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î –ª–æ–≥.
    """
    log_path = "/var/www/scripts/update/logs/oc_logs.log"
    log_dir = os.path.dirname(log_path)

    os.makedirs(log_dir, exist_ok=True)

    if not logging.getLogger().hasHandlers():
        logging.basicConfig(
            filename=log_path,
            level=logging.INFO,
            format="%(asctime)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            filemode="a"
        )

    if message is not None:
        logging.info(message)
        print(f"üìù {message}")

# --- 5. –ó–ê–í–ê–ù–¢–ê–ñ–ï–ù–ù–Ø –§–ê–ô–õ–£ attribute.csv ---
def load_attributes_csv():
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –ø—Ä–∞–≤–∏–ª–∞ –∑–∞–º—ñ–Ω–∏ –∞—Ç—Ä–∏–±—É—Ç—ñ–≤ –∑ attribute.csv (–≥—ñ–±—Ä–∏–¥–Ω–∞ –±–ª–æ—á–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞).
    –ü–æ–≤–µ—Ä—Ç–∞—î:
    1. replacements_map: –°–ª–æ–≤–Ω–∏–∫ {col_index: {original_value: new_value}} –¥–ª—è —à–≤–∏–¥–∫–æ–≥–æ –ø–æ—à—É–∫—É.
    2. raw_data: –°–ø–∏—Å–æ–∫ —Å–∏—Ä–∏—Ö —Ä—è–¥–∫—ñ–≤ –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ —Ñ–∞–π–ª—É.
    """
    settings = load_oc_settings()
    if not settings or "paths" not in settings or "attribute" not in settings["paths"]:
        logging.error("‚ùå –£ settings.json –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ paths.attribute")
        return {}, []

    attribute_path = settings["paths"]["attribute"]
    replacements_map = {}
    raw_data = []          
    
    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
    default_header = ["column_number", "attr_site_name", "atr_a", "atr_b", "atr_c", "atr_d", "atr_e", "atr_f", "atr_g", "atr_h", "atr_i"]
    current_col_index = None # –í—ñ–¥—Å—Ç–µ–∂—É—î–º–æ –ø–æ—Ç–æ—á–Ω–∏–π –±–ª–æ–∫

    try:
        with open(attribute_path, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            
            try:
                header = next(reader)
                raw_data.append(header)
                max_row_len = len(header)
            except StopIteration:
                return {}, [default_header]

            for row in reader:
                # –ù–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ –¥–æ–≤–∂–∏–Ω—É —Ä—è–¥–∫–∞
                row = row[:max_row_len] + [''] * (max_row_len - len(row))
                raw_data.append(row)
                
                # 1. –Ø–∫—â–æ —Ü–µ —Ä—è–¥–æ–∫-–∑–∞–≥–æ–ª–æ–≤–æ–∫ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, "27",,,,,)
                if row and row[0].strip().isdigit():
                    try:
                        current_col_index = int(row[0].strip())
                        if current_col_index not in replacements_map:
                            replacements_map[current_col_index] = {}
                    except ValueError:
                        current_col_index = None
                        continue
                
                # 2. –Ø–∫—â–æ —Ü–µ —Ä—è–¥–æ–∫-–ø—Ä–∞–≤–∏–ª–æ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, ,,,—á–æ—Ä–Ω–∏–π,,)
                elif current_col_index is not None and len(row) >= 3:
                    
                    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–æ–≤–∞–Ω–µ –∑–Ω–∞—á–µ–Ω–Ω—è –∑–Ω–∞—Ö–æ–¥–∏—Ç—å—Å—è –≤ –∫–æ–ª–æ–Ω—Ü—ñ 1 (attr_site_name)
                    new_value = row[1].strip() 
                    
                    # –ü–µ—Ä–µ–≥–ª—è–¥–∞—î–º–æ –≤—Å—ñ –∑–Ω–∞—á–µ–Ω–Ω—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫—ñ–≤ (–ø–æ—á–∏–Ω–∞—é—á–∏ –∑ —ñ–Ω–¥–µ–∫—Å—É 2)
                    for original in row[2:]:
                        original = original.strip().lower()
                        if original:
                            # –ö–ª—é—á - –æ—Ä–∏–≥—ñ–Ω–∞–ª (lower), –ó–Ω–∞—á–µ–Ω–Ω—è - –∑–∞–º—ñ–Ω–∞ (–∑ attr_site_name)
                            replacements_map[current_col_index][original] = new_value

        return replacements_map, raw_data
    
    except FileNotFoundError:
        logging.warning(f"–§–∞–π–ª –∞—Ç—Ä–∏–±—É—Ç—ñ–≤ 'attribute.csv' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ. –ë—É–¥–µ —Å—Ç–≤–æ—Ä–µ–Ω–æ –Ω–æ–≤–∏–π.")
        return {}, [default_header]
    except Exception as e:
        logging.error(f"–í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ attribute.csv: {e}")
        return {}, [default_header]

# --- 6. –ó–ë–ï–†–ï–ñ–ï–ù–ù–Ø –§–ê–ô–õ–£ attribute.csv ---    
def save_attributes_csv(raw_data):
    """
    –ó–±–µ—Ä—ñ–≥–∞—î –æ–Ω–æ–≤–ª–µ–Ω—ñ —Å–∏—Ä—ñ –¥–∞–Ω—ñ —É attribute.csv.
    """
    settings = load_oc_settings()
    if not settings or "paths" not in settings or "attribute" not in settings["paths"]:
        logging.error("‚ùå –£ settings.json –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ paths.attribute")
        return {}, []
    attribute_path = settings["paths"]["attribute"]
    try:
        # 'newline=''' –≤–∞–∂–ª–∏–≤–∏–π –¥–ª—è –∫–æ—Ä–µ–∫—Ç–Ω–æ–≥–æ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è CSV –Ω–∞ —Ä—ñ–∑–Ω–∏—Ö –û–°
        with open(attribute_path, 'w', encoding='utf-8', newline='') as f:
            writer = csv.writer(f)
            writer.writerows(raw_data)
        logging.info("–§–∞–π–ª –∞—Ç—Ä–∏–±—É—Ç—ñ–≤ attribute.csv –æ–Ω–æ–≤–ª–µ–Ω–æ.")
    except Exception as e:
        logging.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—ñ —Ñ–∞–π–ª—É –∞—Ç—Ä–∏–±—É—Ç—ñ–≤ attribute.csv: {e}")

# --- 7. –Ü–ú–ü–û–†–¢ –ö–ê–¢–ï–ì–û–†–Ü–ô –ó CSV –í –ë–î OPENCART ---
def oc_import_categories_from_csv():
    """
    –Ü–º–ø–æ—Ä—Ç –∫–∞—Ç–µ–≥–æ—Ä—ñ–π –∑ CSV —É OpenCart –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º path_id
    """
    oc_log_message("‚ñ∂ –°—Ç–∞—Ä—Ç —ñ–º–ø–æ—Ä—Ç—É –∫–∞—Ç–µ–≥–æ—Ä—ñ–π (CSV ‚Üí OpenCart, path_id)")

    csv_path = "/var/www/scripts/update/csv/output/oc_categorii.csv"

    if not os.path.exists(csv_path):
        oc_log_message(f"‚ùå CSV —Ñ–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {csv_path}")
        return

    conn = oc_connect_db()
    if not conn:
        oc_log_message("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –ø—ñ–¥–∫–ª—é—á–∏—Ç–∏—Å—å –¥–æ –ë–î")
        return

    cursor = conn.cursor()

    # –ú–æ–≤–∏ (–∑ —Ç–≤–æ—î—ó –ë–î)
    languages = {
        "uk-ua": 2,
        "ru-ru": 3
    }

    # --- –ª–æ–∫–∞–ª—å–Ω—ñ safe-—Ö–µ–ª–ø–µ—Ä–∏ ---
    def safe_int(v, default=0):
        if v is None:
            return default
        s = str(v).strip()
        if s == "":
            return default
        try:
            return int(s)
        except ValueError:
            try:
                return int(float(s))
            except Exception:
                return default

    def safe_bool(v, default=0):
        if v is None:
            return default
        s = str(v).strip().lower()
        if s in ("1", "true", "yes", "y", "on"):
            return 1
        if s in ("0", "false", "no", "n", "off"):
            return 0
        return default

    imported = 0

    try:
        with open(csv_path, newline="", encoding="utf-8") as f:
            reader = csv.DictReader(f, delimiter=";")

            for row in reader:
                # –ø—Ä–∏–±–∏—Ä–∞—î–º–æ BOM
                row = {k.lstrip("\ufeff").strip(): (v if v is not None else "") for k, v in row.items()}

                category_id = safe_int(row.get("category_id"), None)
                if category_id is None:
                    oc_log_message("‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ —Ä—è–¥–æ–∫ –±–µ–∑ category_id")
                    continue

                parent_id = safe_int(row.get("parent_id"), 0)
                sort_order = safe_int(row.get("sort_order"), 0)

                image = row.get("image_name") or None
                top = safe_bool(row.get("top"), 0)
                column_value = safe_int(row.get("column"), 1)
                status = safe_bool(row.get("status"), 1)

                page_group_links = row.get("page_group_links") or ""
                date_added = row.get("date_added") or "2000-01-01 00:00:00"
                date_modified = row.get("date_modified") or date_added

                # --- oc_category ---
                cursor.execute("""
                    DELETE FROM oc_seo_url
                    WHERE query = %s
                    """, (f"category_id={category_id}",))
                cursor.execute(
                    """
                    INSERT INTO oc_category
                    (category_id, image, parent_id, top, `column`,
                     sort_order, status, page_group_links,
                     date_added, date_modified)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                    ON DUPLICATE KEY UPDATE
                        image = VALUES(image),
                        parent_id = VALUES(parent_id),
                        top = VALUES(top),
                        `column` = VALUES(`column`),
                        sort_order = VALUES(sort_order),
                        status = VALUES(status),
                        page_group_links = VALUES(page_group_links),
                        date_modified = VALUES(date_modified)
                    """,
                    (
                        category_id,
                        image,
                        parent_id,
                        top,
                        column_value,
                        sort_order,
                        status,
                        page_group_links,
                        date_added,
                        date_modified
                    )
                )

                # --- oc_category_description ---
                for code, language_id in languages.items():
                    cursor.execute(
                        """
                        INSERT INTO oc_category_description
                        (category_id, language_id, name, description, description2,
                         meta_title, meta_description, meta_keyword)
                        VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                        ON DUPLICATE KEY UPDATE
                            name = VALUES(name),
                            description = VALUES(description),
                            description2 = VALUES(description2),
                            meta_title = VALUES(meta_title),
                            meta_description = VALUES(meta_description),
                            meta_keyword = VALUES(meta_keyword)
                        """,
                        (
                            category_id,
                            language_id,
                            row.get(f"name({code})", "") or "",
                            row.get(f"description({code})", "") or "",
                            row.get(f"description2({code})", "") or "",
                            row.get(f"meta_title({code})", "") or "",
                            row.get(f"meta_description({code})", "") or "",
                            row.get(f"meta_keywords({code})", "") or ""
                        )
                    )

                # --- oc_seo_url ---
                seo_map = [
                    (2, "uk-ua"),
                    (3, "ru-ru"),
                ]
                for lang_id, suffix in seo_map:
                    seo_keyword = row.get(f"seo_keyword({suffix})")

                    if seo_keyword:
                        cursor.execute("""
                            INSERT INTO oc_seo_url
                            (store_id, language_id, query, keyword)
                            VALUES (0, %s, %s, %s)
                        """, (
                            lang_id,
                            f"category_id={category_id}",
                            seo_keyword.strip()
                        ))
                # --- oc_category_to_store ---
                cursor.execute(
                    "INSERT IGNORE INTO oc_category_to_store (category_id, store_id) VALUES (%s, %s)",
                    (category_id, 0)
                )

                # --- oc_category_path (CSV path_id) ---
                cursor.execute(
                    "DELETE FROM oc_category_path WHERE category_id = %s",
                    (category_id,)
                )

                path_raw = row.get("path_id", "").strip()
                if path_raw:
                    path_parts = [safe_int(x) for x in path_raw.split(">") if safe_int(x) > 0]
                else:
                    path_parts = [category_id]

                for level, path_id in enumerate(path_parts):
                    cursor.execute(
                        """
                        INSERT INTO oc_category_path (category_id, path_id, level)
                        VALUES (%s, %s, %s)
                        """,
                        (category_id, path_id, level)
                    )

                imported += 1

        conn.commit()
        oc_log_message(f"‚úÖ –Ü–º–ø–æ—Ä—Ç –∫–∞—Ç–µ–≥–æ—Ä—ñ–π –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –û–±—Ä–æ–±–ª–µ–Ω–æ: {imported}")

    except Exception as e:
        conn.rollback()
        oc_log_message(f"‚ùå –ü–æ–º–∏–ª–∫–∞ —ñ–º–ø–æ—Ä—Ç—É –∫–∞—Ç–µ–≥–æ—Ä—ñ–π: {e}")

    finally:
        cursor.close()
        conn.close()

def load_category_csv():
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –ø—Ä–∞–≤–∏–ª–∞ –∑–∞–º—ñ–Ω–∏ –∫–∞—Ç–µ–≥–æ—Ä—ñ–π –∑ category.csv.
    –ü–æ–≤–µ—Ä—Ç–∞—î:
    1. category_map: –°–ª–æ–≤–Ω–∏–∫ {supplier_id: {(name1, name2, name3): category_value}}
    2. raw_data: –°–ø–∏—Å–æ–∫ —Å–∏—Ä–∏—Ö —Ä—è–¥–∫—ñ–≤ –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ —Ñ–∞–π–ª—É.
    """
    category_path = "/var/www/scripts/update/config/category.csv"
    category_map = {}
    raw_data = []          
    
    default_header = ["postachalnyk", "name_1", "name_2", "name_3", "category"]
    current_supplier_id = None

    try:
        with open(category_path, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            
            try:
                header = next(reader)
                raw_data.append(header)
                max_row_len = len(header)
            except StopIteration:
                return {}, [default_header]

            for row in reader:
                row = row[:max_row_len] + [''] * (max_row_len - len(row))
                raw_data.append(row)
                
                # 1. –Ø–∫—â–æ —Ü–µ —Ä—è–¥–æ–∫-–∑–∞–≥–æ–ª–æ–≤–æ–∫ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, "1",,,,)
                if row and row[0].strip().isdigit():
                    try:
                        current_supplier_id = int(row[0].strip())
                        if current_supplier_id not in category_map:
                            category_map[current_supplier_id] = {}
                    except ValueError:
                        current_supplier_id = None
                        continue
                
                # 2. –Ø–∫—â–æ —Ü–µ —Ä—è–¥–æ–∫-–ø—Ä–∞–≤–∏–ª–æ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, ,"–õ—è–ª—å–∫–∏","–ö—É–∫–ª–∏","–ù–∞–¥—É–≤–Ω—ñ","–ù–∞–¥—É–≤–Ω—ñ –ª—è–ª—å–∫–∏")
                elif current_supplier_id is not None and len(row) >= 5:
                    
                    # –ö–ª—é—á—ñ –¥–ª—è –º–∞–ø–∏: (name_1, name_2, name_3) - –≤—Å—ñ –≤ –Ω–∏–∂–Ω—å–æ–º—É —Ä–µ–≥—ñ—Å—Ç—Ä—ñ
                    key_tuple = (
                        row[1].strip().lower(), 
                        row[2].strip().lower(), 
                        row[3].strip().lower()
                    )
                    
                    # –ó–Ω–∞—á–µ–Ω–Ω—è: category (–±–µ–∑ –∑–º—ñ–Ω–∏ —Ä–µ–≥—ñ—Å—Ç—Ä—É)
                    category_value = row[4].strip()
                    
                    category_map[current_supplier_id][key_tuple] = category_value

        return category_map, raw_data
    
    except FileNotFoundError:
        logging.warning(f"–§–∞–π–ª –∫–∞—Ç–µ–≥–æ—Ä—ñ–π 'category.csv' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ. –ë—É–¥–µ —Å—Ç–≤–æ—Ä–µ–Ω–æ –Ω–æ–≤–∏–π.")
        return {}, [default_header]
    except Exception as e:
        logging.error(f"–í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ category.csv: {e}")
        return {}, [default_header]

def save_category_csv(raw_data):
    """
    –ó–±–µ—Ä—ñ–≥–∞—î –æ–Ω–æ–≤–ª–µ–Ω—ñ —Å–∏—Ä—ñ –¥–∞–Ω—ñ —É category.csv.
    """
    category_path = "/var/www/scripts/update/config/category.csv"
    try:
        with open(category_path, 'w', encoding='utf-8', newline='') as f:
            writer = csv.writer(f)
            writer.writerows(raw_data)
        logging.info("–§–∞–π–ª –∫–∞—Ç–µ–≥–æ—Ä—ñ–π category.csv –æ–Ω–æ–≤–ª–µ–Ω–æ.")
    except Exception as e:
        logging.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—ñ —Ñ–∞–π–ª—É –∫–∞—Ç–µ–≥–æ—Ä—ñ–π category.csv: {e}")

def load_poznachky_csv():
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î —Å—Ç–∞—Ç–∏—á–Ω–∏–π —Å–ø–∏—Å–æ–∫ –ø–æ–∑–Ω–∞—á–æ–∫ –∑ poznachky.csv.
    –ü–æ–≤–µ—Ä—Ç–∞—î:
    1. poznachky_list: –°–ø–∏—Å–æ–∫ —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö –ø–æ–∑–Ω–∞—á–æ–∫ (—É –Ω–∏–∂–Ω—å–æ–º—É —Ä–µ–≥—ñ—Å—Ç—Ä—ñ).
    """
    poznachky_path = "/var/www/scripts/update/config/poznachky.csv"
    poznachky_list = []
    
    try:
        with open(poznachky_path, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            
            try:
                # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫ "Poznachky"
                next(reader) 
            except StopIteration:
                return []

            for row in reader:
                if row and row[0].strip():
                    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –ø–æ–∑–Ω–∞—á–∫–∏ —É –Ω–∏–∂–Ω—å–æ–º—É —Ä–µ–≥—ñ—Å—Ç—Ä—ñ –¥–ª—è —É–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–æ–≥–æ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è
                    poznachky_list.append(row[0].strip().lower())

        # –°–æ—Ä—Ç—É—î–º–æ –≤—ñ–¥ –Ω–∞–π–¥–æ–≤—à–∏—Ö –¥–æ –Ω–∞–π–∫–æ—Ä–æ—Ç—à–∏—Ö, —â–æ–± –∑–Ω–∞–π—Ç–∏ –Ω–∞–π–∫—Ä–∞—â–µ —Å–ø—ñ–≤–ø–∞–¥—ñ–Ω–Ω—è
        poznachky_list.sort(key=len, reverse=True)
        
        return poznachky_list
    
    except FileNotFoundError:
        logging.warning(f"–§–∞–π–ª –ø–æ–∑–Ω–∞—á–æ–∫ 'poznachky.csv' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return []
    except Exception as e:
        logging.error(f"–í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ poznachky.csv: {e}")
        return []

# --- –ü–ï–†–ï–í–Ü–†–ö–ê CSV ---
def check_csv_data(profile_id):
    """
    –ü–µ—Ä–µ–≤—ñ—Ä—è—î CSV-—Ñ–∞–π–ª –Ω–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω—ñ—Å—Ç—å –ø—Ä–∞–≤–∏–ª–∞–º, –≤–∏–∑–Ω–∞—á–µ–Ω–∏–º —É oc_settings.json.

    Args:
        profile_id (str): ID –ø—Ä–æ—Ñ—ñ–ª—é –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ –∑ 'validation_profiles' –≤ oc_settings.json.

    Returns:
        bool: True, —è–∫—â–æ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ –ø—Ä–æ–π—à–ª–∞ —É—Å–ø—ñ—à–Ω–æ, —ñ–Ω–∞–∫—à–µ False.
    """

    # 0. –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –ª–æ–≥—É–≤–∞–Ω–Ω—è
    oc_log_message(f"üîé –°—Ç–∞—Ä—Ç –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ CSV (–ø—Ä–æ—Ñ—ñ–ª—å: {profile_id})")

    # 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω—å
    settings = load_oc_settings()
    if not settings:
        oc_log_message("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ oc_settings.json")
        return False

    profiles = settings.get("validation_profiles", {})
    if profile_id not in profiles:
        oc_log_message(f"‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –ø—Ä–æ—Ñ—ñ–ª—å –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó –∑ ID '{profile_id}'")
        return False

    # 2. –î–∞–Ω—ñ –ø—Ä–æ—Ñ—ñ–ª—é
    profile = profiles[profile_id]
    csv_path_relative = profile.get("path")
    validation_rules = profile.get("rules")

    if not csv_path_relative or validation_rules is None:
        oc_log_message("‚ùå –ù–µ–ø–æ–≤–Ω—ñ –¥–∞–Ω—ñ –≤ –ø—Ä–æ—Ñ—ñ–ª—ñ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó")
        return False

    # 3. –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ñ–∞–π–ª—É
    base_dir = os.path.join(os.path.dirname(__file__), "..")
    full_csv_path = os.path.join(base_dir, csv_path_relative)

    if not os.path.exists(full_csv_path):
        oc_log_message(f"‚ùå CSV —Ñ–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {full_csv_path}")
        return False

    oc_log_message(f"üìÑ –ü–µ—Ä–µ–≤—ñ—Ä—è—î—Ç—å—Å—è —Ñ–∞–π–ª: {full_csv_path}")

    # 4. –ß–∏—Ç–∞–Ω–Ω—è —Ç–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—è CSV
    try:
        with open(full_csv_path, "r", encoding="utf-8") as f:
            reader = csv.reader(f)

            try:
                headers = next(reader)
            except StopIteration:
                oc_log_message("‚ùå CSV —Ñ–∞–π–ª –ø–æ—Ä–æ–∂–Ω—ñ–π (–≤—ñ–¥—Å—É—Ç–Ω—ñ –∑–∞–≥–æ–ª–æ–≤–∫–∏)")
                return False

            # 5. –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫—ñ–≤
            expected_columns = list(validation_rules.keys())
            headers_set = set(headers)

            for col_name in expected_columns:
                if col_name not in headers_set:
                    oc_log_message(f"‚ùå –í—ñ–¥—Å—É—Ç–Ω—è –æ–±–æ–≤ º—è–∑–∫–æ–≤–∞ –∫–æ–ª–æ–Ω–∫–∞: '{col_name}'")
                    return False

            header_map = {name: idx for idx, name in enumerate(headers)}

            # 6. –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ä—è–¥–∫—ñ–≤
            for i, row in enumerate(reader):
                row_number = i + 2

                if not row or all(not col.strip() for col in row):
                    oc_log_message(f"‚ÑπÔ∏è –†—è–¥–æ–∫ {row_number} –ø–æ—Ä–æ–∂–Ω—ñ–π ‚Äî –ø—Ä–æ–ø—É—â–µ–Ω–æ")
                    continue

                for col_name, rule_type in validation_rules.items():
                    col_index = header_map.get(col_name)

                    if col_index is None or col_index >= len(row):
                        oc_log_message(f"‚ùå –†—è–¥–æ–∫ {row_number}: –Ω–µ–∫–æ—Ä–µ–∫—Ç–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ CSV")
                        return False

                    value = row[col_index].strip()

                    # 6.1 not_empty
                    if rule_type == "not_empty":
                        if not value:
                            oc_log_message(f"‚ùå –†—è–¥–æ–∫ {row_number}, '{col_name}': –ø–æ–ª–µ –Ω–µ –ø–æ–≤–∏–Ω–Ω–æ –±—É—Ç–∏ –ø–æ—Ä–æ–∂–Ω—ñ–º")
                            return False
                        continue

                    # 6.2 integer
                    if rule_type == "integer":
                        if not value or not value.lstrip("-").isdigit():
                            oc_log_message(
                                f"‚ùå –†—è–¥–æ–∫ {row_number}, '{col_name}': –æ—á—ñ–∫—É—î—Ç—å—Å—è —Ü—ñ–ª–µ —á–∏—Å–ª–æ, –æ—Ç—Ä–∏–º–∞–Ω–æ '{value}'"
                            )
                            return False

                    # 6.3 integer_or_empty
                    elif rule_type == "integer_or_empty":
                        if value and not value.lstrip("-").isdigit():
                            oc_log_message(
                                f"‚ùå –†—è–¥–æ–∫ {row_number}, '{col_name}': –æ—á—ñ–∫—É—î—Ç—å—Å—è —Ü—ñ–ª–µ —á–∏—Å–ª–æ –∞–±–æ –ø–æ—Ä–æ–∂–Ω—î –ø–æ–ª–µ"
                            )
                            return False

                    # 6.4 float_or_empty
                    elif rule_type == "float_or_empty":
                        if value:
                            try:
                                float(value.replace(",", "."))
                            except ValueError:
                                oc_log_message(
                                    f"‚ùå –†—è–¥–æ–∫ {row_number}, '{col_name}': –æ—á—ñ–∫—É—î—Ç—å—Å—è float –∞–±–æ –ø–æ—Ä–æ–∂–Ω—î –ø–æ–ª–µ"
                                )
                                return False

                    # 6.5 datetime
                    elif rule_type == "datetime":
                        if value:
                            try:
                                datetime.strptime(value, "%Y-%m-%dT%H:%M:%S")
                            except ValueError:
                                oc_log_message(
                                    f"‚ùå –†—è–¥–æ–∫ {row_number}, '{col_name}': –Ω–µ–≤—ñ—Ä–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç datetime"
                                )
                                return False

                    # 6.6 —Å–ø–∏—Å–æ–∫ –¥–æ–ø—É—Å—Ç–∏–º–∏—Ö –∑–Ω–∞—á–µ–Ω—å
                    elif isinstance(rule_type, list):
                        if value not in rule_type:
                            oc_log_message(
                                f"‚ùå –†—è–¥–æ–∫ {row_number}, '{col_name}': –∑–Ω–∞—á–µ–Ω–Ω—è '{value}' –Ω–µ –≤—Ö–æ–¥–∏—Ç—å —É {rule_type}"
                            )
                            return False

    except Exception as e:
        oc_log_message(f"‚ùå –ù–µ–≤—ñ–¥–æ–º–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ CSV: {e}")
        return False

    oc_log_message("‚úÖ –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ CSV —É—Å–ø—ñ—à–Ω–∞")
    return True
