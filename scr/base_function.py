from woocommerce import API
import json
import os, csv, shutil, logging, requests, mimetypes, glob
import logging
import html
import re
import mysql.connector
from datetime import datetime
from typing import Dict, Tuple, List, Optional, Any
from PIL import Image
from bs4 import BeautifulSoup
import time


# --- –ó–ê–ì–ê–õ–¨–ù–Ü –§–£–ù–ö–¶–Ü–á ---
def load_settings():
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó –∑ settings.json
    """
    config_path = os.path.join(os.path.dirname(__file__), "..", "config", "settings.json")
    try:
        with open(config_path, "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: —Ñ–∞–π–ª –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∑–∞ —à–ª—è—Ö–æ–º: {config_path}")
        return None
    except json.JSONDecodeError:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: —Ñ–∞–π–ª –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó –ø–æ—à–∫–æ–¥–∂–µ–Ω–∏–π: {config_path}")
        return None

# --- –ü–Ü–î–ö–õ–Æ–ß–ï–ù–ù–Ø –î–û WOOCOMMERCE API ---
def get_wc_api(settings):
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó –∑ settings.json
    """
    config_path = os.path.join(os.path.dirname(__file__), "..", "config", "settings.json")
    with open(config_path, "r", encoding="utf-8") as f:
        settings = json.load(f)

    wcapi = API(
        url=settings["url"],
        consumer_key=settings["consumer_key"],
        consumer_secret=settings["consumer_secret"],
        version="wc/v3",
        timeout=120,
        query_string_auth=False  # –ó–º—ñ–Ω–∏–≤ –∑ True üëà –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î Basic Auth (—Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ) 
    )
    return wcapi

# --- –ü–ï–†–ï–í–Ü–†–ö–ê –í–ï–†–°–Ü–á WOOCOMMERCE ---
def check_version():
    wcapi = get_wc_api()
    response = wcapi.get("system_status")
    if response.status_code == 200:
        data = response.json()
        print("WooCommerce version:", data.get("environment", {}).get("version"))
    else:
        print("Error:", response.status_code, response.text)

# --- –õ–û–ì–£–í–ê–ù–ù–Ø (–°—Ç–≤–æ—Ä–µ–Ω–Ω—è –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª—É)---
def setup_new_log_file():
    """
    –ü–µ—Ä–µ–π–º–µ–Ω–æ–≤—É—î —ñ—Å–Ω—É—é—á–∏–π –ª–æ–≥-—Ñ–∞–π–ª —Ç–∞ –Ω–∞–ª–∞—à—Ç–æ–≤—É—î –Ω–æ–≤–∏–π,
    –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—á–∏ —à–ª—è—Ö –∑ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω—å.
    """
    settings = load_settings()
    if not settings or "paths" not in settings or "main_log_file" not in settings["paths"]:
        print("‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ —à–ª—è—Ö –¥–æ –ª–æ–≥-—Ñ–∞–π–ª—É –≤ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è—Ö.")
        return

    current_log_path = os.path.join(os.path.dirname(__file__), "..", settings["paths"]["main_log_file"])
    log_dir = os.path.dirname(current_log_path)
    
    os.makedirs(log_dir, exist_ok=True)
    
    if os.path.exists(current_log_path):
        timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        file_name, file_extension = os.path.splitext(os.path.basename(current_log_path))
        new_log_path = os.path.join(log_dir, f"{file_name}_{timestamp}{file_extension}")
        try:
            os.rename(current_log_path, new_log_path)
            print(f"‚úÖ –°—Ç–∞—Ä–∏–π –ª–æ–≥-—Ñ–∞–π–ª –ø–µ—Ä–µ–π–º–µ–Ω–æ–≤–∞–Ω–æ –Ω–∞ {os.path.basename(new_log_path)}")
        except OSError as e:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–π–º–µ–Ω—É–≤–∞–Ω–Ω—ñ –ª–æ–≥-—Ñ–∞–π–ª—É: {e}")

    logging.basicConfig(
        filename=current_log_path,
        level=logging.INFO,
        format='%(asctime)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S',
        filemode='a'
    )
    logging.info("--- –ù–æ–≤–∏–π —Å–µ–∞–Ω—Å –ª–æ–≥—É–≤–∞–Ω–Ω—è —Ä–æ–∑–ø–æ—á–∞—Ç–æ ---")

# --- –õ–û–ì–£–í–ê–ù–ù–Ø (–ó–∞–ø–∏—Å –≤ —ñ—Å–Ω—É—é—á–∏–π —Ñ–∞–π–ª)---
def log_message_to_existing_file():
    """
    –ù–∞–ª–∞—à—Ç–æ–≤—É—î –ª–æ–≥—É–≤–∞–Ω–Ω—è –¥–ª—è –¥–æ–ø–∏—Å—É–≤–∞–Ω–Ω—è –≤ —ñ—Å–Ω—É—é—á–∏–π —Ñ–∞–π–ª,
    –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—á–∏ —à–ª—è—Ö –∑ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω—å.
    """
    settings = load_settings()
    if not settings or "paths" not in settings or "main_log_file" not in settings["paths"]:
        print("‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ —à–ª—è—Ö –¥–æ –ª–æ–≥-—Ñ–∞–π–ª—É –≤ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è—Ö.")
        return

    current_log_path = os.path.join(os.path.dirname(__file__), "..", settings["paths"]["main_log_file"])
    log_dir = os.path.dirname(current_log_path)
    
    os.makedirs(log_dir, exist_ok=True)

    if not logging.getLogger().hasHandlers():
        logging.basicConfig(
            filename=current_log_path,
            #level=logging.INFO,
            level=logging.DEBUG,
            format='%(asctime)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S',
            filemode='a'
        )
    logging.info("--- –ü–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –¥–æ–¥–∞–Ω–æ –¥–æ —ñ—Å–Ω—É—é—á–æ–≥–æ –ª–æ–≥—É ---")

# --- –ü–ï–†–ï–í–Ü–†–ö–ê CSV ---
def check_csv_data(profile_id):
    """
    –ü–µ—Ä–µ–≤—ñ—Ä—è—î CSV-—Ñ–∞–π–ª –Ω–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω—ñ—Å—Ç—å –ø—Ä–∞–≤–∏–ª–∞–º, –≤–∏–∑–Ω–∞—á–µ–Ω–∏–º —É settings.json.
    
    Args:
        profile_id (str): ID –ø—Ä–æ—Ñ—ñ–ª—é –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ –∑ 'validation_profiles' –≤ settings.json.
    
    Returns:
        bool: True, —è–∫—â–æ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ –ø—Ä–æ–π—à–ª–∞ —É—Å–ø—ñ—à–Ω–æ, —ñ–Ω–∞–∫—à–µ False.
    """
    # 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω—å
    # –¶–µ–π –±–ª–æ–∫ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î –∑–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó –∑ —Ñ–∞–π–ª—É settings.json
    # —Ç–∞ –ø–µ—Ä–µ–≤—ñ—Ä—è—î, —á–∏ —ñ—Å–Ω—É—î –≤–∫–∞–∑–∞–Ω–∏–π –ø—Ä–æ—Ñ—ñ–ª—å –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó.
    # –Ø–∫—â–æ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –∞–±–æ –ø—Ä–æ—Ñ—ñ–ª—å –≤—ñ–¥—Å—É—Ç–Ω—ñ–π, —Ñ—É–Ω–∫—Ü—ñ—è –∑–∞–≤–µ—Ä—à—É—î —Ä–æ–±–æ—Ç—É.
    
    log_message_to_existing_file()
    
    try:
        with open(os.path.join(os.path.dirname(__file__), "..", "config", "settings.json"), "r", encoding="utf-8") as f:
            settings = json.load(f)
    except (FileNotFoundError, json.JSONDecodeError) as e:
        logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó: {e}")
        return False
        
    profiles = settings.get("validation_profiles", {})
    if profile_id not in profiles:
        logging.error(f"‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –ø—Ä–æ—Ñ—ñ–ª—å –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó –∑ ID '{profile_id}' –≤ settings.json.")
        return False
    
    # 2. –û—Ç—Ä–∏–º–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö –ø—Ä–æ—Ñ—ñ–ª—é
    # –û—Ç—Ä–∏–º—É—î–º–æ —à–ª—è—Ö –¥–æ —Ñ–∞–π–ª—É —Ç–∞ –ø—Ä–∞–≤–∏–ª–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó –¥–ª—è –æ–±—Ä–∞–Ω–æ–≥–æ –ø—Ä–æ—Ñ—ñ–ª—é.
    profile = profiles[profile_id]
    csv_path_relative = profile.get("path")
    validation_rules = profile.get("rules")
    
    if not csv_path_relative or validation_rules is None:
        logging.error("‚ùå –ù–µ–ø–æ–≤–Ω—ñ –¥–∞–Ω—ñ –≤ –ø—Ä–æ—Ñ—ñ–ª—ñ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó.")
        return False
        
    # 3. –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ —Ñ–∞–π–ª—É
    # –§–æ—Ä–º—É—î–º–æ –ø–æ–≤–Ω–∏–π —à–ª—è—Ö –¥–æ —Ñ–∞–π–ª—É —Ç–∞ –ø–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –π–æ–≥–æ —ñ—Å–Ω—É–≤–∞–Ω–Ω—è –Ω–∞ –¥–∏—Å–∫—É.
    base_dir = os.path.join(os.path.dirname(__file__), "..")
    full_csv_path = os.path.join(base_dir, csv_path_relative)
    
    if not os.path.exists(full_csv_path):
        logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞: —Ñ–∞–π–ª –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return False
        
    logging.info(f"üîé –ü–æ—á–∞—Ç–æ–∫ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ —Ñ–∞–π–ª—É")
    
    # 4. –ß–∏—Ç–∞–Ω–Ω—è —Ç–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—è –¥–∞–Ω–∏—Ö
    # –í—ñ–¥–∫—Ä–∏–≤–∞—î–º–æ —Ñ–∞–π–ª —Ç–∞ –ø–æ—á–∏–Ω–∞—î–º–æ —ñ—Ç–µ—Ä–∞—Ü—ñ—é –ø–æ –π–æ–≥–æ –≤–º—ñ—Å—Ç—É.
    try:
        with open(full_csv_path, "r", encoding="utf-8") as f:
            reader = csv.reader(f)
            try:
                headers = next(reader)
            except StopIteration:
                logging.error("‚ùå –§–∞–π–ª –ø–æ—Ä–æ–∂–Ω—ñ–π. –í—ñ–¥—Å—É—Ç–Ω—ñ –∑–∞–≥–æ–ª–æ–≤–∫–∏.")
                return False
            
            # 5. –û–Ω–æ–≤–ª–µ–Ω–∞ –ª–æ–≥—ñ–∫–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ –∑–∞–≥–æ–ª–æ–≤–∫—ñ–≤
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ –≤—Å—ñ –æ—á—ñ–∫—É–≤–∞–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏ –ø—Ä–∏—Å—É—Ç–Ω—ñ —É –∑–∞–≥–æ–ª–æ–≤–∫–∞—Ö —Ñ–∞–π–ª—É
            rule_columns = list(validation_rules.keys())
            headers_set = set(headers)
            for col_name in rule_columns:
                if col_name not in headers_set:
                    logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞: –æ—á—ñ–∫—É–≤–∞–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ '{col_name}' –≤—ñ–¥—Å—É—Ç–Ω—è —É —Ñ–∞–π–ª—ñ.")
                    return False
            
            # –°—Ç–≤–æ—Ä—é—î–º–æ —Å–ª–æ–≤–Ω–∏–∫ –¥–ª—è —à–≤–∏–¥–∫–æ–≥–æ –¥–æ—Å—Ç—É–ø—É –¥–æ —ñ–Ω–¥–µ–∫—Å—ñ–≤ –∫–æ–ª–æ–Ω–æ–∫
            header_map = {name: index for index, name in enumerate(headers)}
            
            # 6. –í–∞–ª—ñ–¥–∞—Ü—ñ—è –∫–æ–∂–Ω–æ–≥–æ —Ä—è–¥–∫–∞
            for i, row in enumerate(reader):
                row_number = i + 2
                if not row or all(not col.strip() for col in row):
                    logging.info(f"‚úÖ –†—è–¥–æ–∫ {row_number} –ø–æ—Ä–æ–∂–Ω—ñ–π –∞–±–æ –º—ñ—Å—Ç–∏—Ç—å –ª–∏—à–µ –ø—Ä–æ–±—ñ–ª–∏. –ü—Ä–æ–ø—É—Å–∫–∞—é.")
                    continue
                
                # 7. –í–∞–ª—ñ–¥–∞—Ü—ñ—è –∫–æ–∂–Ω–æ–≥–æ –ø–æ–ª—è, —è–∫–µ —î –≤ –ø—Ä–∞–≤–∏–ª–∞—Ö
                for col_name, rule_type in validation_rules.items():
                    try:
                        col_index = header_map.get(col_name)
                        if col_index is None:
                            # –¶–µ –º–∞–ª–æ –±—É—Ç–∏ —Å–ø—ñ–π–º–∞–Ω–æ –Ω–∞ –µ—Ç–∞–ø—ñ 5, –∞–ª–µ —Ü–µ –¥–æ–¥–∞—Ç–∫–æ–≤–∞ –ø–µ—Ä–µ—Å—Ç—Ä–∞—Ö–æ–≤–∫–∞
                            continue
                        
                        if col_index >= len(row):
                            logging.error(f"‚ùå –†—è–¥–æ–∫ {row_number}: –†—è–¥–æ–∫ –∫–æ—Ä–æ—Ç—à–∏–π –∑–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –æ—á—ñ–∫—É–≤–∞–Ω–∏—Ö –∫–æ–ª–æ–Ω–æ–∫.")
                            return False
                        
                        value = row[col_index].strip()

                        # 7.0. –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ –æ–±–æ–≤‚Äô—è–∑–∫–æ–≤—ñ—Å—Ç—å –∑–∞–ø–æ–≤–Ω–µ–Ω–Ω—è
                        if rule_type == "not_empty":
                            if not value:
                                logging.error(f"‚ùå –†—è–¥–æ–∫ {row_number}, –∫–æ–ª–æ–Ω–∫–∞ '{col_name}': –ø–æ–ª–µ –Ω–µ –ø–æ–≤–∏–Ω–Ω–æ –±—É—Ç–∏ –ø–æ—Ä–æ–∂–Ω—ñ–º.")
                                return False
                            continue  # –Ω–µ –ø–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –¥–∞–ª—ñ
                        
                        # 7.1. –í–∞–ª—ñ–¥–∞—Ü—ñ—è —Ü—ñ–ª–∏—Ö —á–∏—Å–µ–ª
                        if rule_type == "integer":
                            if not value:
                                logging.error(f"‚ùå –†—è–¥–æ–∫ {row_number}, –∫–æ–ª–æ–Ω–∫–∞ '{col_name}': –æ—á—ñ–∫—É—î—Ç—å—Å—è —Ü—ñ–ª–µ —á–∏—Å–ª–æ, –∞–ª–µ –ø–æ–ª–µ –ø–æ—Ä–æ–∂–Ω—î.")
                                return False
                            if not value.lstrip('-').isdigit():
                                logging.error(f"‚ùå –†—è–¥–æ–∫ {row_number}, –∫–æ–ª–æ–Ω–∫–∞ '{col_name}': –æ—á—ñ–∫—É—î—Ç—å—Å—è —Ü—ñ–ª–µ —á–∏—Å–ª–æ, –∞–ª–µ –æ—Ç—Ä–∏–º–∞–Ω–æ '{value}'.")
                                return False

                        # 7.2. –í–∞–ª—ñ–¥–∞—Ü—ñ—è –∑–Ω–∞—á–µ–Ω—å –∑—ñ —Å–ø–∏—Å–∫—É
                        elif isinstance(rule_type, list):
                            if not value:
                                logging.error(f"‚ùå –†—è–¥–æ–∫ {row_number}, –∫–æ–ª–æ–Ω–∫–∞ '{col_name}': –æ—á—ñ–∫—É—î—Ç—å—Å—è –æ–¥–Ω–µ –∑—ñ –∑–Ω–∞—á–µ–Ω—å {rule_type}, –∞–ª–µ –ø–æ–ª–µ –ø–æ—Ä–æ–∂–Ω—î.")
                                return False
                            if value not in rule_type:
                                logging.error(f"‚ùå –†—è–¥–æ–∫ {row_number}, –∫–æ–ª–æ–Ω–∫–∞ '{col_name}': –æ—á—ñ–∫—É—î—Ç—å—Å—è –æ–¥–Ω–µ –∑—ñ –∑–Ω–∞—á–µ–Ω—å {rule_type}, –∞–ª–µ –æ—Ç—Ä–∏–º–∞–Ω–æ '{value}'.")
                                return False
                        
                        # 7.3. –í–∞–ª—ñ–¥–∞—Ü—ñ—è —Ñ–æ—Ä–º–∞—Ç—É –¥–∞—Ç–∏-—á–∞—Å—É
                        elif rule_type == "datetime":
                            if value:
                                try:
                                    datetime.strptime(value, "%Y-%m-%dT%H:%M:%S")
                                except ValueError:
                                    logging.error(f"‚ùå –†—è–¥–æ–∫ {row_number}, –∫–æ–ª–æ–Ω–∫–∞ '{col_name}': –Ω–µ–≤—ñ—Ä–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç–∏-—á–∞—Å—É. –û—á—ñ–∫—É—î—Ç—å—Å—è 'YYYY-MM-DDTHH:MM:SS', –∞–ª–µ –æ—Ç—Ä–∏–º–∞–Ω–æ '{value}'.")
                                    return False

                        # 7.4. –í–∞–ª—ñ–¥–∞—Ü—ñ—è —Ü—ñ–ª–∏—Ö —á–∏—Å–µ–ª (–¥–æ–ø—É—Å–∫–∞—î –ø–æ—Ä–æ–∂–Ω—î –ø–æ–ª–µ)
                        if rule_type == "integer_or_empty":
                            if value == "":
                                continue  # –ü–æ—Ä–æ–∂–Ω—î –∑–Ω–∞—á–µ–Ω–Ω—è ‚Äî –¥–æ–∑–≤–æ–ª–µ–Ω–µ
                            if not value.lstrip('-').isdigit():
                                logging.error(f"‚ùå –†—è–¥–æ–∫ {row_number}, –∫–æ–ª–æ–Ω–∫–∞ '{col_name}': –æ—á—ñ–∫—É—î—Ç—å—Å—è —Ü—ñ–ª–µ —á–∏—Å–ª–æ –∞–±–æ –ø–æ—Ä–æ–∂–Ω—î –ø–æ–ª–µ, –∞–ª–µ –æ—Ç—Ä–∏–º–∞–Ω–æ '{value}'.")
                                return False

                        # 7.5. –í–∞–ª—ñ–¥–∞—Ü—ñ—è —á–∏—Å–µ–ª –∑ –ø–ª–∞–≤–∞—é—á–æ—é –∫–æ–º–æ—é (float) (–¥–æ–ø—É—Å–∫–∞—î –ø–æ—Ä–æ–∂–Ω—î –ø–æ–ª–µ)
                        elif rule_type == "float_or_empty":
                            if value == "":
                                continue  # –¥–æ–∑–≤–æ–ª—è—î–º–æ –ø—É—Å—Ç–µ –ø–æ–ª–µ

                            # –î–æ–∑–≤–æ–ª—è—î–º–æ —î–≤—Ä–æ–ø–µ–π—Å—å–∫–∏–π —Ñ–æ—Ä–º–∞—Ç –∑ –∫–æ–º–æ—é ‚Äî –∑–∞–º—ñ–Ω—é—î–º–æ –Ω–∞ –∫—Ä–∞–ø–∫—É
                            normalized_value = value.replace(",", ".")
                            try:
                                float(normalized_value)
                            except ValueError:
                                logging.error(
                                    f"‚ùå –†—è–¥–æ–∫ {row_number}, –∫–æ–ª–æ–Ω–∫–∞ '{col_name}': –æ—á—ñ–∫—É—î—Ç—å—Å—è —á–∏—Å–ª–æ (float) –∞–±–æ –ø–æ—Ä–æ–∂–Ω—î –ø–æ–ª–µ, "
                                    f"–∞–ª–µ –æ—Ç—Ä–∏–º–∞–Ω–æ '{value}'."
                                )
                                return False
                                    
                    except (ValueError, IndexError):
                        logging.error(f"‚ùå –ù–µ–ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –≤ —Ä—è–¥–∫—É {row_number}. –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∑—É–ø–∏–Ω–µ–Ω–∞.")
                        return False

    except Exception as e:
        logging.error(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –Ω–µ–≤—ñ–¥–æ–º–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å —á–∏—Ç–∞–Ω–Ω—è CSV: {e}", exc_info=True)
        return False
        
    logging.info(f"‚úÖ –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ñ–∞–π–ª—É –ø—Ä–æ–π—à–ª–∞ —É—Å–ø—ñ—à–Ω–æ.")
    return True

# --- –†–û–ë–û–¢–ê –ó –§–ê–ô–õ–ê–ú–ò –ö–û–ù–§–Ü–ì–£–†–ê–¶–Ü–á (attribute.csv, category.csv, poznachky.csv) ---
def get_config_path(filename):
    """–ü–æ–≤–µ—Ä—Ç–∞—î –ø–æ–≤–Ω–∏–π —à–ª—è—Ö –¥–æ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó."""
    # –ü—Ä–∏–ø—É—Å–∫–∞—î–º–æ, —â–æ config –∑–Ω–∞—Ö–æ–¥–∏—Ç—å—Å—è –Ω–∞ –æ–¥–∏–Ω —Ä—ñ–≤–µ–Ω—å –≤–∏—â–µ –≤—ñ–¥ scr
    current_dir = os.path.dirname(os.path.abspath(__file__))
    config_dir = os.path.abspath(os.path.join(current_dir, '..', 'config'))
    return os.path.join(config_dir, filename)

def load_attributes_csv():
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –ø—Ä–∞–≤–∏–ª–∞ –∑–∞–º—ñ–Ω–∏ –∞—Ç—Ä–∏–±—É—Ç—ñ–≤ –∑ attribute.csv (–≥—ñ–±—Ä–∏–¥–Ω–∞ –±–ª–æ—á–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞).
    –ü–æ–≤–µ—Ä—Ç–∞—î:
    1. replacements_map: –°–ª–æ–≤–Ω–∏–∫ {col_index: {original_value: new_value}} –¥–ª—è —à–≤–∏–¥–∫–æ–≥–æ –ø–æ—à—É–∫—É.
    2. raw_data: –°–ø–∏—Å–æ–∫ —Å–∏—Ä–∏—Ö —Ä—è–¥–∫—ñ–≤ –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ —Ñ–∞–π–ª—É.
    """
    attribute_path = get_config_path('attribute.csv')
    replacements_map = {}
    raw_data = []          
    
    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
    default_header = ["column_number", "attr_site_name", "atr_a", "atr_b", "atr_c", "atr_d", "atr_e", "atr_f", "atr_g", "atr_h", "atr_i"]
    current_col_index = None # –í—ñ–¥—Å—Ç–µ–∂—É—î–º–æ –ø–æ—Ç–æ—á–Ω–∏–π –±–ª–æ–∫

    try:
        with open(attribute_path, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            
            try:
                header = next(reader)
                raw_data.append(header)
                max_row_len = len(header)
            except StopIteration:
                return {}, [default_header]

            for row in reader:
                # –ù–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ –¥–æ–≤–∂–∏–Ω—É —Ä—è–¥–∫–∞
                row = row[:max_row_len] + [''] * (max_row_len - len(row))
                raw_data.append(row)
                
                # 1. –Ø–∫—â–æ —Ü–µ —Ä—è–¥–æ–∫-–∑–∞–≥–æ–ª–æ–≤–æ–∫ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, "27",,,,,)
                if row and row[0].strip().isdigit():
                    try:
                        current_col_index = int(row[0].strip())
                        if current_col_index not in replacements_map:
                            replacements_map[current_col_index] = {}
                    except ValueError:
                        current_col_index = None
                        continue
                
                # 2. –Ø–∫—â–æ —Ü–µ —Ä—è–¥–æ–∫-–ø—Ä–∞–≤–∏–ª–æ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, ,,,—á–æ—Ä–Ω–∏–π,,)
                elif current_col_index is not None and len(row) >= 3:
                    
                    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–æ–≤–∞–Ω–µ –∑–Ω–∞—á–µ–Ω–Ω—è –∑–Ω–∞—Ö–æ–¥–∏—Ç—å—Å—è –≤ –∫–æ–ª–æ–Ω—Ü—ñ 1 (attr_site_name)
                    new_value = row[1].strip() 
                    
                    # –ü–µ—Ä–µ–≥–ª—è–¥–∞—î–º–æ –≤—Å—ñ –∑–Ω–∞—á–µ–Ω–Ω—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫—ñ–≤ (–ø–æ—á–∏–Ω–∞—é—á–∏ –∑ —ñ–Ω–¥–µ–∫—Å—É 2)
                    for original in row[2:]:
                        original = original.strip().lower()
                        if original:
                            # –ö–ª—é—á - –æ—Ä–∏–≥—ñ–Ω–∞–ª (lower), –ó–Ω–∞—á–µ–Ω–Ω—è - –∑–∞–º—ñ–Ω–∞ (–∑ attr_site_name)
                            replacements_map[current_col_index][original] = new_value

        return replacements_map, raw_data
    
    except FileNotFoundError:
        logging.warning(f"–§–∞–π–ª –∞—Ç—Ä–∏–±—É—Ç—ñ–≤ 'attribute.csv' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ. –ë—É–¥–µ —Å—Ç–≤–æ—Ä–µ–Ω–æ –Ω–æ–≤–∏–π.")
        return {}, [default_header]
    except Exception as e:
        logging.error(f"–í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ attribute.csv: {e}")
        return {}, [default_header]

def save_attributes_csv(raw_data):
    """
    –ó–±–µ—Ä—ñ–≥–∞—î –æ–Ω–æ–≤–ª–µ–Ω—ñ —Å–∏—Ä—ñ –¥–∞–Ω—ñ —É attribute.csv.
    """
    attribute_path = get_config_path('attribute.csv')
    try:
        # 'newline=''' –≤–∞–∂–ª–∏–≤–∏–π –¥–ª—è –∫–æ—Ä–µ–∫—Ç–Ω–æ–≥–æ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è CSV –Ω–∞ —Ä—ñ–∑–Ω–∏—Ö –û–°
        with open(attribute_path, 'w', encoding='utf-8', newline='') as f:
            writer = csv.writer(f)
            writer.writerows(raw_data)
        logging.info("–§–∞–π–ª –∞—Ç—Ä–∏–±—É—Ç—ñ–≤ attribute.csv –æ–Ω–æ–≤–ª–µ–Ω–æ.")
    except Exception as e:
        logging.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—ñ —Ñ–∞–π–ª—É –∞—Ç—Ä–∏–±—É—Ç—ñ–≤ attribute.csv: {e}")

def load_category_csv():
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –ø—Ä–∞–≤–∏–ª–∞ –∑–∞–º—ñ–Ω–∏ –∫–∞—Ç–µ–≥–æ—Ä—ñ–π –∑ category.csv.
    –ü–æ–≤–µ—Ä—Ç–∞—î:
    1. category_map: –°–ª–æ–≤–Ω–∏–∫ {supplier_id: {(name1, name2, name3): category_value}}
    2. raw_data: –°–ø–∏—Å–æ–∫ —Å–∏—Ä–∏—Ö —Ä—è–¥–∫—ñ–≤ –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ —Ñ–∞–π–ª—É.
    """
    category_path = get_config_path('category.csv')
    category_map = {}
    raw_data = []          
    
    default_header = ["postachalnyk", "name_1", "name_2", "name_3", "category"]
    current_supplier_id = None

    try:
        with open(category_path, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            
            try:
                header = next(reader)
                raw_data.append(header)
                max_row_len = len(header)
            except StopIteration:
                return {}, [default_header]

            for row in reader:
                row = row[:max_row_len] + [''] * (max_row_len - len(row))
                raw_data.append(row)
                
                # 1. –Ø–∫—â–æ —Ü–µ —Ä—è–¥–æ–∫-–∑–∞–≥–æ–ª–æ–≤–æ–∫ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, "1",,,,)
                if row and row[0].strip().isdigit():
                    try:
                        current_supplier_id = int(row[0].strip())
                        if current_supplier_id not in category_map:
                            category_map[current_supplier_id] = {}
                    except ValueError:
                        current_supplier_id = None
                        continue
                
                # 2. –Ø–∫—â–æ —Ü–µ —Ä—è–¥–æ–∫-–ø—Ä–∞–≤–∏–ª–æ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, ,"–õ—è–ª—å–∫–∏","–ö—É–∫–ª–∏","–ù–∞–¥—É–≤–Ω—ñ","–ù–∞–¥—É–≤–Ω—ñ –ª—è–ª—å–∫–∏")
                elif current_supplier_id is not None and len(row) >= 5:
                    
                    # –ö–ª—é—á—ñ –¥–ª—è –º–∞–ø–∏: (name_1, name_2, name_3) - –≤—Å—ñ –≤ –Ω–∏–∂–Ω—å–æ–º—É —Ä–µ–≥—ñ—Å—Ç—Ä—ñ
                    key_tuple = (
                        row[1].strip().lower(), 
                        row[2].strip().lower(), 
                        row[3].strip().lower()
                    )
                    
                    # –ó–Ω–∞—á–µ–Ω–Ω—è: category (–±–µ–∑ –∑–º—ñ–Ω–∏ —Ä–µ–≥—ñ—Å—Ç—Ä—É)
                    category_value = row[4].strip()
                    
                    category_map[current_supplier_id][key_tuple] = category_value

        return category_map, raw_data
    
    except FileNotFoundError:
        logging.warning(f"–§–∞–π–ª –∫–∞—Ç–µ–≥–æ—Ä—ñ–π 'category.csv' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ. –ë—É–¥–µ —Å—Ç–≤–æ—Ä–µ–Ω–æ –Ω–æ–≤–∏–π.")
        return {}, [default_header]
    except Exception as e:
        logging.error(f"–í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ category.csv: {e}")
        return {}, [default_header]

def save_category_csv(raw_data):
    """
    –ó–±–µ—Ä—ñ–≥–∞—î –æ–Ω–æ–≤–ª–µ–Ω—ñ —Å–∏—Ä—ñ –¥–∞–Ω—ñ —É category.csv.
    """
    category_path = get_config_path('category.csv')
    try:
        with open(category_path, 'w', encoding='utf-8', newline='') as f:
            writer = csv.writer(f)
            writer.writerows(raw_data)
        logging.info("–§–∞–π–ª –∫–∞—Ç–µ–≥–æ—Ä—ñ–π category.csv –æ–Ω–æ–≤–ª–µ–Ω–æ.")
    except Exception as e:
        logging.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—ñ —Ñ–∞–π–ª—É –∫–∞—Ç–µ–≥–æ—Ä—ñ–π category.csv: {e}")

def load_poznachky_csv():
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î —Å—Ç–∞—Ç–∏—á–Ω–∏–π —Å–ø–∏—Å–æ–∫ –ø–æ–∑–Ω–∞—á–æ–∫ –∑ poznachky.csv.
    –ü–æ–≤–µ—Ä—Ç–∞—î:
    1. poznachky_list: –°–ø–∏—Å–æ–∫ —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö –ø–æ–∑–Ω–∞—á–æ–∫ (—É –Ω–∏–∂–Ω—å–æ–º—É —Ä–µ–≥—ñ—Å—Ç—Ä—ñ).
    """
    poznachky_path = get_config_path('poznachky.csv')
    poznachky_list = []
    
    try:
        with open(poznachky_path, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            
            try:
                # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫ "Poznachky"
                next(reader) 
            except StopIteration:
                return []

            for row in reader:
                if row and row[0].strip():
                    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –ø–æ–∑–Ω–∞—á–∫–∏ —É –Ω–∏–∂–Ω—å–æ–º—É —Ä–µ–≥—ñ—Å—Ç—Ä—ñ –¥–ª—è —É–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–æ–≥–æ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è
                    poznachky_list.append(row[0].strip().lower())

        # –°–æ—Ä—Ç—É—î–º–æ –≤—ñ–¥ –Ω–∞–π–¥–æ–≤—à–∏—Ö –¥–æ –Ω–∞–π–∫–æ—Ä–æ—Ç—à–∏—Ö, —â–æ–± –∑–Ω–∞–π—Ç–∏ –Ω–∞–π–∫—Ä–∞—â–µ —Å–ø—ñ–≤–ø–∞–¥—ñ–Ω–Ω—è
        poznachky_list.sort(key=len, reverse=True)
        
        return poznachky_list
    
    except FileNotFoundError:
        logging.warning(f"–§–∞–π–ª –ø–æ–∑–Ω–∞—á–æ–∫ 'poznachky.csv' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return []
    except Exception as e:
        logging.error(f"–í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ poznachky.csv: {e}")
        return []

# --- –û–ë–†–û–ë–ö–ê –ó–û–ë–†–ê–ñ–ï–ù–¨ ---   
def clear_directory(folder_path: str):
    """–û—á–∏—â–∞—î –∞–±–æ —Å—Ç–≤–æ—Ä—é—î –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—é."""
    if not os.path.exists(folder_path):
        os.makedirs(folder_path, exist_ok=True)
        return
    for item in os.listdir(folder_path):
        path = os.path.join(folder_path, item)
        try:
            if os.path.isfile(path) or os.path.islink(path):
                os.unlink(path)
            elif os.path.isdir(path):
                shutil.rmtree(path)
        except Exception as e:
            logging.error(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –≤–∏–¥–∞–ª–∏—Ç–∏ {path}: {e}")

def move_gifs(src: str, dest: str) -> int:
    """–ü–µ—Ä–µ–º—ñ—â—É—î –≤—Å—ñ GIF —ñ–∑ src —É dest."""
    moved = 0
    os.makedirs(dest, exist_ok=True)
    for root, _, files in os.walk(src):
        for f in files:
            if f.lower().endswith('.gif'):
                src_path = os.path.join(root, f)
                rel = os.path.relpath(src_path, src)
                dest_path = os.path.join(dest, rel)
                os.makedirs(os.path.dirname(dest_path), exist_ok=True)
                shutil.move(src_path, dest_path)
                moved += 1
    logging.info(f"üü£ –ü–µ—Ä–µ–º—ñ—â–µ–Ω–æ {moved} GIF-—Ñ–∞–π–ª—ñ–≤.")
    return moved

def convert_to_webp_square(src: str, dest: str) -> int:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç—É—î JPG/PNG ‚Üí WEBP, –≤–∏—Ä—ñ–≤–Ω—é—î –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –¥–æ –∫–≤–∞–¥—Ä–∞—Ç—É
    —Ç–∞ –∫–æ—Ä–µ–∫—Ç–Ω–æ –æ–±—Ä–æ–±–ª—è—î –ø—Ä–æ–∑–æ—Ä—ñ—Å—Ç—å (RGBA / –ø–∞–ª—ñ—Ç—Ä–æ–≤—ñ P-–∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è).
    """
    import os
    import logging
    from PIL import Image

    converted = 0

    for root, _, files in os.walk(src):
        rel = os.path.relpath(root, src)
        out_dir = os.path.join(dest, rel)
        os.makedirs(out_dir, exist_ok=True)

        for f in files:
            if not f.lower().endswith(('.jpg', '.jpeg', '.png', '.webp')):
                continue

            try:
                img_path = os.path.join(root, f)
                img = Image.open(img_path)

                # üîπ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –∫–æ–ª—å–æ—Ä–æ–≤–æ–≥–æ —Ä–µ–∂–∏–º—É (–¥–ª—è —É–Ω–∏–∫–Ω–µ–Ω–Ω—è warning)
                if img.mode == "P":
                    img = img.convert("RGBA")
                elif img.mode not in ("RGB", "RGBA"):
                    img = img.convert("RGB")

                w, h = img.size
                max_side = max(w, h)

                # üîπ –Ø–∫—â–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –º–∞—î –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª ‚Äî —Å—Ç–≤–æ—Ä—é—î–º–æ –ø—Ä–æ–∑–æ—Ä–µ –ø–æ–ª–æ—Ç–Ω–æ
                if img.mode == "RGBA":
                    canvas = Image.new("RGBA", (max_side, max_side), (255, 255, 255, 0))
                else:
                    canvas = Image.new("RGB", (max_side, max_side), (255, 255, 255))

                # –¶–µ–Ω—Ç—Ä—É–≤–∞–Ω–Ω—è
                canvas.paste(img, ((max_side - w) // 2, (max_side - h) // 2))

                # üîπ –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —É —Ñ–æ—Ä–º–∞—Ç—ñ WEBP
                new_name = os.path.splitext(f)[0] + '.webp'
                out_path = os.path.join(out_dir, new_name)
                canvas.save(out_path, 'webp', quality=90)

                converted += 1

            except Exception as e:
                logging.error(f"‚ùå WEBP-–∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è '{f}' –Ω–µ –≤–¥–∞–ª–∞—Å—è: {e}")

    logging.info(f"üü¢ WEBP-–∫–æ–Ω–≤–µ—Ä—Ç–æ–≤–∞–Ω–æ {converted} –∑–æ–±—Ä–∞–∂–µ–Ω—å.")
    return converted

# --- –ó–ê–í–ê–ù–¢–ê–ñ–ï–ù–ù–Ø –ó–û–ë–†–ê–ñ–ï–ù–¨ –¢–û–í–ê–†–£ ---
def download_product_images(url: str, sku: str, category: str, base_path: str, cat_map: Dict[str, str]) -> List[str]:
    """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –≤—Å—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Ç–æ–≤–∞—Ä—É –∑ URL."""
    cat_slug = cat_map.get(category.strip()) or category.strip().lower().replace(' ', '_').replace(',', '')
    dest = os.path.join(base_path, cat_slug)
    os.makedirs(dest, exist_ok=True)

    try:
        page = requests.get(url, timeout=10)
        page.raise_for_status()
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Å—Ç–æ—Ä—ñ–Ω–∫—É {url}: {e}")
        return []

    soup = BeautifulSoup(page.content, 'html.parser')
    links = {a.get('href') for a in soup.find_all('a', class_='thumb_image_container') if a.get('href')}
    files = []

    for i, img_url in enumerate(links, 1):
        try:
            r = requests.get(img_url, timeout=10)
            r.raise_for_status()
            mime = r.headers.get('Content-Type')
            ext = mimetypes.guess_extension(mime) or '.jpg'
            fname = f"{sku}-{i}{ext}"
            with open(os.path.join(dest, fname), 'wb') as f:
                f.write(r.content)
            files.append(fname)
        except Exception:
            continue

    # üü¢ –õ–æ–≥—É–≤–∞–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É
    logging.info(f"üì∏ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(files)} –∑–æ–±—Ä–∞–∂–µ–Ω—å –¥–ª—è SKU {sku}: {', '.join(files)}")

    return files

# --- –°–ò–ù–•–†–û–ù–Ü–ó–ê–¶–Ü–Ø –ö–û–õ–û–ù–ö–ò WEBP –£ CSV ---
def sync_webp_column(sl_path: str, webp_path: str, col_index: int, sku_index: int) -> int:
    """–û–Ω–æ–≤–ª—é—î –∫–æ–ª–æ–Ω–∫—É WEBP/GIF-—Å–ø–∏—Å–∫—ñ–≤ —É CSV."""
    with open(sl_path, 'r', encoding='utf-8') as f:
        reader = list(csv.reader(f))
    if not reader:
        return 0

    header, *rows = reader
    sku_map = {}
    for root, _, files in os.walk(webp_path):
        for f in files:
            if '-' in f and f.lower().endswith(('.webp', '.gif')):
                sku = f.split('-')[0]
                sku_map.setdefault(sku, []).append(f)

    updated = 0
    for row in rows:
        if len(row) <= max(col_index, sku_index):
            row.extend([''] * (max(col_index, sku_index) + 1 - len(row)))
        sku = row[sku_index].strip()
        if sku in sku_map:
            row[col_index] = ', '.join(sorted(sku_map[sku]))
            updated += 1
    with open(sl_path, 'w', encoding='utf-8', newline='') as f:
        csv.writer(f).writerows([header] + rows)
    logging.info(f"üîÅ –û–Ω–æ–≤–ª–µ–Ω–æ {updated} SKU —É –∫–æ–ª–æ–Ω—Ü—ñ WEBP.")
    return updated

# --- –ö–û–ü–Ü–Æ–í–ê–ù–ù–Ø –§–ê–ô–õ–Ü–í –£ –§–Ü–ù–ê–õ–¨–ù–£ –î–ò–†–ï–ö–¢–û–†–Ü–Æ ---
def copy_to_site(src: str, dest: str):
    """–ö–æ–ø—ñ—é—î WEBP/GIF –¥–æ —Ñ—ñ–Ω–∞–ª—å–Ω–æ—ó –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó –∑ –ø—Ä–∞–≤–∞–º–∏."""
    uid, gid = 33, 33
    fperm, dperm = 0o644, 0o755
    copied = 0

    for root, _, files in os.walk(src):
        rel = os.path.relpath(root, src)
        out_dir = os.path.join(dest, rel)
        os.makedirs(out_dir, mode=dperm, exist_ok=True)
        for f in files:
            if not f.lower().endswith(('.webp', '.gif')):
                continue
            src_f = os.path.join(root, f)
            dst_f = os.path.join(out_dir, f)
            shutil.copy2(src_f, dst_f)
            try:
                os.chown(dst_f, uid, gid)
                os.chmod(dst_f, fperm)
                copied += 1
            except PermissionError:
                logging.warning(f"‚ö†Ô∏è –ù–µ–º–∞—î –ø—Ä–∞–≤ –¥–ª—è –∑–º—ñ–Ω–∏ –≤–ª–∞—Å–Ω–∏–∫–∞ {dst_f}")
    logging.info(f"üì¶ –°–∫–æ–ø—ñ–π–æ–≤–∞–Ω–æ {copied} —Ñ–∞–π–ª—ñ–≤ —É {dest}.")
    return copied

# --- –î–û–ü–û–ú–Ü–ñ–ù–ê –§–£–ù–ö–¶–Ü–Ø –î–õ–Ø –ü–ê–ö–ï–¢–ù–û–ì–û –ó–ê–ü–ò–°–£ (–û–Ω–æ–≤–ª–µ–Ω–Ω—è) ---
def _process_batch_update(wcapi: Any, batch_data: List[Dict[str, Any]], errors_list: List[str]) -> int:
    """–í–∏–∫–æ–Ω—É—î –ø–∞–∫–µ—Ç–Ω–∏–π –∑–∞–ø–∏—Ç 'update' –¥–æ WooCommerce API."""
    
    payload = {"update": batch_data}
    
    try:
        logging.info(f"–ù–∞–¥—Å–∏–ª–∞—é –ø–∞–∫–µ—Ç –Ω–∞ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è ({len(batch_data)} —Ç–æ–≤–∞—Ä—ñ–≤)...")
        
        response = wcapi.post("products/batch", data=payload) 
        
        if response.status_code == 200:
            result = response.json()
            updated_count = len(result.get('update', []))
            
            # –î–µ—Ç–∞–ª—å–Ω–µ –ª–æ–≥—É–≤–∞–Ω–Ω—è –ø–æ–º–∏–ª–æ–∫, —è–∫—ñ –ø–æ–≤–µ—Ä–Ω—É–≤ API
            api_errors = result.get('errors', [])
            if api_errors:
                for err in api_errors:
                    err_msg = f"API-–ü–æ–º–∏–ª–∫–∞ (ID: {err.get('id', 'N/A')}): {err.get('message', '–ù–µ–≤—ñ–¥–æ–º–∞ –ø–æ–º–∏–ª–∫–∞')}"
                    errors_list.append(err_msg)
                    logging.error(err_msg)
                
            logging.info(f"‚úÖ –ü–∞–∫–µ—Ç –æ–Ω–æ–≤–ª–µ–Ω–æ. –£—Å–ø—ñ—à–Ω–æ –æ–±—Ä–æ–±–ª–µ–Ω–æ API: {updated_count} —Ç–æ–≤–∞—Ä—ñ–≤. –ü–æ–º–∏–ª–æ–∫ —É –ø–∞–∫–µ—Ç—ñ: {len(api_errors)}")
            return updated_count
        else:
            err_msg = f"‚ùå –ö—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞ API ({response.status_code}) –ø—Ä–∏ –ø–∞–∫–µ—Ç–Ω–æ–º—É –æ–Ω–æ–≤–ª–µ–Ω–Ω—ñ. –ü–æ–º–∏–ª–∫–∞: {response.text[:200]}..."
            errors_list.append(err_msg)
            logging.critical(err_msg)
            return 0
            
    except Exception as e:
        err_msg = f"‚ùå –ù–µ–ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –≤—ñ–¥–ø—Ä–∞–≤–∫–∏ –ø–∞–∫–µ—Ç—É: {e}"
        errors_list.append(err_msg)
        logging.critical(err_msg, exc_info=True)
        return 0

# --- –î–û–ü–û–ú–Ü–ñ–ù–ê –§–£–ù–ö–¶–Ü–Ø –î–õ–Ø –ü–æ—à—É–∫—É Media IDs ---
def find_media_ids_for_sku(wcapi, sku: str, uploads_path: str) -> List[Dict[str, Any]]:
    """
    –ó–Ω–∞—Ö–æ–¥–∏—Ç—å —É—Å—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –¥–ª—è SKU —É uploads_path —Ç–∞ –ø–æ–≤–µ—Ä—Ç–∞—î —Å–ø–∏—Å–æ–∫ ID –¥–ª—è WooCommerce.
    –ü—ñ–¥—Ç—Ä–∏–º—É—î —Ä—ñ–∑–Ω—ñ —Ä–æ–∑—à–∏—Ä–µ–Ω–Ω—è —Ç–∞ –ø—ñ–¥–ø–∞–ø–∫–∏.
    """
    def _get_media_id_by_filename(filename: str) -> int | None:
        """–í–Ω—É—Ç—Ä—ñ—à–Ω—è —Ñ—É–Ω–∫—Ü—ñ—è: —à—É–∫–∞—î ID –º–µ–¥—ñ–∞ –∑–∞ slug –∞–±–æ title"""
        import requests

        file_slug = os.path.splitext(filename)[0]

        # –ü–æ—à—É–∫ –∑–∞ slug
        try:
            response = wcapi.get("media", params={'search': file_slug, 'per_page': 1, 'orderby': 'slug'})
            if response.status_code == 200:
                items = response.json()
                if items:
                    item = items[0]
                    if item.get('slug') == file_slug or item.get('title', {}).get('rendered') == filename:
                        return item['id']
        except Exception as e:
            logging.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –ø–æ—à—É–∫—É –º–µ–¥—ñ–∞ ID –¥–ª—è {filename} (slug): {e}")

        # –ü–æ—à—É–∫ –∑–∞ —Ç–æ—á–Ω–∏–º title
        try:
            response = wcapi.get("media", params={'search': filename, 'per_page': 1, 'orderby': 'title'})
            if response.status_code == 200:
                items = response.json()
                if items:
                    item = items[0]
                    if item.get('title', {}).get('rendered') == filename:
                        return item['id']
        except Exception as e:
            logging.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –ø–æ—à—É–∫—É –º–µ–¥—ñ–∞ ID –¥–ª—è {filename} (title): {e}")

        logging.warning(f"‚ö†Ô∏è –ú–µ–¥—ñ–∞ ID –¥–ª—è —Ñ–∞–π–ª—É '{filename}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return None

    media_ids = []
    pattern = os.path.join(uploads_path, '**', f'{sku}*.*')
    files = glob.glob(pattern, recursive=True)
    for file_path in files:
        filename = os.path.basename(file_path)
        media_id = _get_media_id_by_filename(filename)
        if media_id:
            media_ids.append({"id": media_id})

    if not media_ids:
        logging.warning(f"‚ö†Ô∏è SKU {sku}: –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∑–æ–±—Ä–∞–∂–µ–Ω—å —É '{uploads_path}'")
    return media_ids

# --- –î–û–ü–û–ú–Ü–ñ–ù–ê –§–£–ù–ö–¶–Ü–Ø –î–õ–Ø –ü–ê–ö–ï–¢–ù–û–ì–û –ó–ê–ü–ò–°–£ (–°—Ç–≤–æ—Ä–µ–Ω–Ω—è) ---
def _process_batch_create(wcapi: Any, batch_data: List[Dict[str, Any]], errors_list: List[str]) -> int:
    """–í–∏–∫–æ–Ω—É—î –ø–∞–∫–µ—Ç–Ω–∏–π –∑–∞–ø–∏—Ç 'create' –¥–æ WooCommerce API."""
    
    payload = {"create": batch_data}
    
    try:
        logging.info(f"–ù–∞–¥—Å–∏–ª–∞—é –ø–∞–∫–µ—Ç –Ω–∞ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è ({len(batch_data)} —Ç–æ–≤–∞—Ä—ñ–≤)...")
        response = wcapi.post("products/batch", data=payload) 
        
        if response.status_code == 200:
            result = response.json()
            created_count = len(result.get('create', []))
            
            api_errors = result.get('errors', [])
            if api_errors:
                for err in api_errors:
                    err_msg = f"API-–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—ñ: SKU '{err.get('data', {}).get('resource_id', 'N/A')}', Code: {err.get('code', 'N/A')}: {err.get('message', '–ù–µ–≤—ñ–¥–æ–º–∞ –ø–æ–º–∏–ª–∫–∞')}"
                    errors_list.append(err_msg)
                    logging.error(err_msg)
                
            logging.info(f"‚úÖ –ü–∞–∫–µ—Ç —Å—Ç–≤–æ—Ä–µ–Ω–æ. –£—Å–ø—ñ—à–Ω–æ –æ–±—Ä–æ–±–ª–µ–Ω–æ API: {created_count} —Ç–æ–≤–∞—Ä—ñ–≤. –ü–æ–º–∏–ª–æ–∫ —É –ø–∞–∫–µ—Ç—ñ: {len(api_errors)}")
            return created_count
        else:
            err_msg = f"‚ùå –ö—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞ API ({response.status_code}) –ø—Ä–∏ –ø–∞–∫–µ—Ç–Ω–æ–º—É —Å—Ç–≤–æ—Ä–µ–Ω–Ω—ñ. –ü–æ–º–∏–ª–∫–∞: {response.text[:200]}..."
            errors_list.append(err_msg)
            logging.critical(err_msg)
            return 0
            
    except Exception as e:
        err_msg = f"‚ùå –ù–µ–ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –≤—ñ–¥–ø—Ä–∞–≤–∫–∏ –ø–∞–∫–µ—Ç—É: {e}"
        errors_list.append(err_msg)
        logging.critical(err_msg, exc_info=True)
        return 0

def _clean_text(value: str) -> str:
    """–û—á–∏—â—É—î HTML-—Ç–µ–≥–∏, –∫–æ–¥—É–≤–∞–Ω–Ω—è —ñ –∑–∞–π–≤—ñ –ø—Ä–æ–±—ñ–ª–∏."""
    if not value:
        return ""
    value = html.unescape(str(value))  # —Ä–æ–∑–∫–æ–¥–æ–≤—É—î &#8211; ‚Üí ‚Äì
    value = re.sub(r"<.*?>", "", value)  # –≤–∏–¥–∞–ª—è—î HTML-—Ç–µ–≥–∏
    return value.strip()

# --- –ï–ö–°–ü–û–†–¢ –¢–û–í–ê–†–£ –ó–ê ID ---
def export_product_by_id():
    """
    –ï–∫—Å–ø–æ—Ä—Ç—É—î –≤—Å—ñ –¥–∞–Ω—ñ —Ç–æ–≤–∞—Ä—É –∑–∞ –≤–≤–µ–¥–µ–Ω–∏–º ID —É /csv/input/ID_tovar.csv.
    –í–∏–ø—Ä–∞–≤–ª–µ–Ω–æ HTML-–∫–æ–¥—É–≤–∞–Ω–Ω—è, –µ–∫—Ä–∞–Ω—É–≤–∞–Ω–Ω—è CSV —ñ –¥–æ–¥–∞–Ω–æ –ø–µ—Ä–µ–∫–ª–∞–¥–∏ WPML.
    """
    log_message_to_existing_file()
    settings = load_settings()
    if not settings:
        logging.error("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è.")
        return

    wcapi = get_wc_api(settings)
    if not wcapi:
        logging.error("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è —Å—Ç–≤–æ—Ä–∏—Ç–∏ –æ–±'—î–∫—Ç WooCommerce API.")
        return

    product_id = input("–í–≤–µ–¥—ñ—Ç—å ID —Ç–æ–≤–∞—Ä—É –¥–ª—è –µ–∫—Å–ø–æ—Ä—Ç—É: ").strip()
    if not product_id.isdigit():
        logging.error("‚ùå –ù–µ–∫–æ—Ä–µ–∫—Ç–Ω–∏–π ID —Ç–æ–≤–∞—Ä—É.")
        return
    product_id = int(product_id)

    output_dir = "/var/www/scripts/update/csv/input"
    os.makedirs(output_dir, exist_ok=True)
    csv_path = os.path.join(output_dir, "ID_tovar.csv")

    start_time = time.time()
    try:
        # === –û—Å–Ω–æ–≤–Ω—ñ –¥–∞–Ω—ñ —Ç–æ–≤–∞—Ä—É ===
        response = wcapi.get(f"products/{product_id}", params={"context": "edit"})
        if response.status_code != 200:
            logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ {response.status_code}: {response.text}")
            return
        product = response.json()
        if not isinstance(product, dict):
            logging.error(f"‚ùå –ù–µ–∫–æ—Ä–µ–∫—Ç–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ API –¥–ª—è —Ç–æ–≤–∞—Ä—É ID {product_id}")
            return

        row = {"id": product_id}

        # === –û—Å–Ω–æ–≤–Ω—ñ –ø–æ–ª—è ===
        for key, value in product.items():
            if isinstance(value, dict):
                for subkey, subval in value.items():
                    row[f"{key}.{subkey}"] = _clean_text(subval)
            elif isinstance(value, list):
                if key == "meta_data":
                    for meta in value:
                        k = meta.get("key")
                        v = meta.get("value")
                        if k:
                            row[f"–ú–µ—Ç–∞: {k}"] = _clean_text(v)
                elif key == "categories":
                    row["categories"] = ", ".join([_clean_text(v.get("name", "")) for v in value])
                elif key == "tags":
                    row["tags"] = ", ".join([_clean_text(v.get("name", "")) for v in value])
                elif key == "images":
                    for idx, img in enumerate(value, start=1):
                        row[f"image_{idx}_id"] = img.get("id", "")
                        row[f"image_{idx}_src"] = img.get("src", "")
                        row[f"image_{idx}_name"] = _clean_text(img.get("name", ""))
                        row[f"image_{idx}_alt"] = _clean_text(img.get("alt", ""))
                        row[f"image_{idx}_title"] = _clean_text(img.get("title", ""))
                        row[f"image_{idx}_caption"] = _clean_text(img.get("caption", ""))
                        row[f"image_{idx}_description"] = _clean_text(img.get("description", ""))
                else:
                    row[key] = ", ".join(map(_clean_text, map(str, value)))
            else:
                row[key] = _clean_text(value)

        # === –ü–µ—Ä–µ–∫–ª–∞–¥–∏ WPML ===
        try:
            wpml_resp = wcapi.get(f"products/{product_id}/translations")
            if wpml_resp.status_code == 200:
                translations = wpml_resp.json()
                for lang, tr in translations.items():
                    if isinstance(tr, dict):
                        row[f"wpml_{lang}_id"] = tr.get("id", "")
                        row[f"wpml_{lang}_name"] = _clean_text(tr.get("name", ""))
                        row[f"wpml_{lang}_slug"] = tr.get("slug", "")
                        row[f"wpml_{lang}_status"] = tr.get("status", "")
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è –ù–µ–º–æ–∂–ª–∏–≤–æ –æ—Ç—Ä–∏–º–∞—Ç–∏ WPML –ø–µ—Ä–µ–∫–ª–∞–¥–∏: {e}")

        # === –ó–∞–ø–∏—Å —É CSV ===
        file_exists = os.path.exists(csv_path)
        file_is_empty = not file_exists or os.path.getsize(csv_path) == 0

        with open(csv_path, "a", newline="", encoding="utf-8") as f:
            writer = csv.DictWriter(f, fieldnames=row.keys(), quoting=csv.QUOTE_ALL)
            if file_is_empty:
                writer.writeheader()
            writer.writerow(row)

        elapsed = int(time.time() - start_time)
        logging.info(f"‚úÖ –ï–∫—Å–ø–æ—Ä—Ç–æ–≤–∞–Ω–æ —Ç–æ–≤–∞—Ä ID {product_id} ({len(row)} –ø–æ–ª—ñ–≤) ‚Üí {csv_path} –∑–∞ {elapsed} —Å–µ–∫.")

    except Exception as e:
        logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –µ–∫—Å–ø–æ—Ä—Ç—É: {e}", exc_info=True)

# --- –û–ù–û–í–õ–ï–ù–ù–Ø SEO-–ê–¢–†–ò–ë–£–¢–Ü–í –ó–û–ë–†–ê–ñ–ï–ù–¨ ---
def update_image_seo_by_sku():
    """
    –û–Ω–æ–≤–ª—é—î SEO-–∞—Ç—Ä–∏–±—É—Ç–∏ –∑–æ–±—Ä–∞–∂–µ–Ω—å —Ç–æ–≤–∞—Ä—É –∑–∞ SKU.
    - –û–Ω–æ–≤–ª—é—î alt/title —á–µ—Ä–µ–∑ WooCommerce (wc/v3 products PUT).
    - –û–Ω–æ–≤–ª—é—î caption/description —á–µ—Ä–µ–∑ WP REST API (wp/v2/media/{id}) –∑ Basic Auth,
      –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—á–∏ credentials –∑ settings.json: 'login' —ñ 'pass'.
    """
    logging.basicConfig(level=logging.INFO)
    print("üñºÔ∏è –ó–∞–ø—É—Å–∫–∞—é –æ–Ω–æ–≤–ª–µ–Ω–Ω—è SEO-–∞—Ç—Ä–∏–±—É—Ç—ñ–≤ –∑–æ–±—Ä–∞–∂–µ–Ω—å...")

    settings = load_settings()
    if not settings:
        logging.critical("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è.")
        return

    # --- –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –¥–ª—è WooCommerce API (wc/v3) ---
    try:
        wcapi = get_wc_api(settings)
    except Exception as e:
        logging.critical(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è —Å—Ç–≤–æ—Ä–∏—Ç–∏ –æ–±'—î–∫—Ç WooCommerce API: {e}")
        return

    base_url = settings.get("url", "").rstrip("/")
    api_key = settings.get("consumer_key")
    api_secret = settings.get("consumer_secret")

    wp_login = settings.get("login")   # username –∞–±–æ –ª–æ–≥—ñ–Ω
    wp_pass = settings.get("pass")     # application password –∞–±–æ –ø–∞—Ä–æ–ª—å

    if not base_url or not api_key or not api_secret:
        logging.critical("‚ùå –ù–µ–ø–æ–≤–Ω—ñ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è API (url, consumer_key –∞–±–æ consumer_secret).")
        return

    # 1) –í–≤–µ–¥–µ–Ω–Ω—è SKU
    sku = input("üîç –í–≤–µ–¥—ñ—Ç—å SKU —Ç–æ–≤–∞—Ä—É: ").strip()
    if not sku:
        print("‚ùå SKU –Ω–µ –≤–≤–µ–¥–µ–Ω–æ.")
        return

    # 2) –û—Ç—Ä–∏–º—É—î–º–æ —Ç–æ–≤–∞—Ä –ø–æ SKU
    try:
        resp = wcapi.get("products", params={"sku": sku})
        if resp.status_code != 200:
            logging.error(f"‚ùå WooCommerce products GET returned {resp.status_code}: {resp.text[:200]}")
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –ø–æ—à—É–∫—É —Ç–æ–≤–∞—Ä—É (—Å—Ç–∞—Ç—É—Å {resp.status_code}). –ü–µ—Ä–µ–≤—ñ—Ä –ª–æ–≥–∏.")
            return
        products = resp.json()
        if not products:
            print(f"‚ùå –¢–æ–≤–∞—Ä –∑—ñ SKU {sku} –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
            return
        product = products[0]
    except Exception as e:
        logging.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Ç—ñ –¥–æ WooCommerce: {e}", exc_info=True)
        print("‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑'—î–¥–Ω–∞–Ω–Ω—ñ –∑ WooCommerce.")
        return

    product_name = product.get("name", "").strip()
    product_id = product.get("id")
    image_list: List[Dict[str, Any]] = product.get("images", [])  # —Å–ø–∏—Å–æ–∫ dict –∑ keys: id, src, name, alt

    if not product_name:
        print("‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –Ω–∞–∑–≤–∏ —Ç–æ–≤–∞—Ä—É.")
        return

    if not image_list:
        print(f"‚ùå –¢–æ–≤–∞—Ä {product_name} –Ω–µ –º–∞—î –ø—Ä–∏–≤'—è–∑–∞–Ω–∏—Ö –∑–æ–±—Ä–∞–∂–µ–Ω—å —É –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ WC API.")
        return

    print(f"‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ —Ç–æ–≤–∞—Ä: {product_name}")
    print(f"üñºÔ∏è –ó–Ω–∞–π–¥–µ–Ω–æ {len(image_list)} –ø—Ä–∏–≤'—è–∑–∞–Ω–∏—Ö –∑–æ–±—Ä–∞–∂–µ–Ω—å. –ü–æ—á–∏–Ω–∞—é –æ–Ω–æ–≤–ª–µ–Ω–Ω—è...")

    seo_data = {
        "title": product_name,
        "alt": f"–ö—É–ø–∏—Ç–∏ —Ç–æ–≤–∞—Ä {product_name} –≤ —Å–µ–∫—Å-—à–æ–ø—ñ Eros.in.ua",
        "caption": f"{product_name} ‚Äì —ñ–Ω–Ω–æ–≤–∞—Ü—ñ–π–Ω–∞ —Å–µ–∫—Å-—ñ–≥—Ä–∞—à–∫–∞ –¥–ª—è –≤–∞—à–æ–≥–æ –∑–∞–¥–æ–≤–æ–ª–µ–Ω–Ω—è",
        "description": f"{product_name} –∫—É–ø–∏—Ç–∏ –≤ —ñ–Ω—Ç–µ—Ä–Ω–µ—Ç-–º–∞–≥–∞–∑–∏–Ω—ñ Eros.in.ua. –í–µ–ª–∏–∫–∏–π –≤–∏–±—ñ—Ä —Å–µ–∫—Å-—ñ–≥—Ä–∞—à–æ–∫, –Ω–∏–∑—å–∫–∞ —Ü—ñ–Ω–∞, —à–≤–∏–¥–∫–∞ –±–µ–∑–∫–æ—à—Ç–æ–≤–Ω–∞ –¥–æ—Å—Ç–∞–≤–∫–∞."
    }

    # --- –î–æ–ø–æ–º—ñ–∂–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è: –∑–Ω–∞–π—Ç–∏ media id –ø–æ filename —á–µ—Ä–µ–∑ WP REST API (search) ---
    def find_media_id_by_filename(filename: str) -> int:
        """
        –ü–æ–≤–µ—Ä—Ç–∞—î media id –∞–±–æ None. –ü—Ä–∞—Ü—é—î —á–µ—Ä–µ–∑ /wp-json/wp/v2/media?search=<filename>
        –ü–æ—Ç—Ä—ñ–±–Ω–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ü—ñ—è, —è–∫—â–æ WP –∑–∞–∫—Ä–∏—Ç–∏–π. –ú–∏ —Å–ø—Ä–æ–±—É—î–º–æ –±–µ–∑ auth –ø–µ—Ä—à–∏–º, –ø–æ—Ç—ñ–º –∑ auth.
        """
        search_url = f"{base_url}/wp-json/wp/v2/media"
        params = {"search": filename, "per_page": 10}
        headers = {"Accept": "application/json"}

        # –°–ø—Ä–æ–±–∞ –±–µ–∑ auth
        try:
            r = requests.get(search_url, params=params, headers=headers, timeout=15, verify=True)
            if r.status_code == 200:
                items = r.json()
                for it in items:
                    src = it.get("source_url", "") or it.get("guid", {}).get("rendered", "")
                    if filename.lower() in (os.path.basename(src).lower()):
                        return it.get("id")
            # —è–∫—â–æ –Ω–µ –≤–¥–∞–ª–æ—Å—å –∞–±–æ –ø–æ—Ä–æ–∂–Ω—å–æ ‚Äî —Å–ø—Ä–æ–±—É—î–º–æ –∑ auth —è–∫—â–æ —î
        except Exception as e:
            logging.debug(f"find_media_id_by_filename (no auth) error: {e}")

        if wp_login and wp_pass:
            try:
                r = requests.get(search_url, params=params, headers=headers, auth=(wp_login, wp_pass), timeout=15, verify=True)
                if r.status_code == 200:
                    items = r.json()
                    for it in items:
                        src = it.get("source_url", "") or it.get("guid", {}).get("rendered", "")
                        if filename.lower() in (os.path.basename(src).lower()):
                            return it.get("id")
                else:
                    logging.debug(f"find_media_id_by_filename (auth) status {r.status_code}: {r.text[:200]}")
            except Exception as e:
                logging.debug(f"find_media_id_by_filename (auth) exception: {e}")

        return None

    # --- –û—Å–Ω–æ–≤–Ω–∏–π —Ü–∏–∫–ª –æ–Ω–æ–≤–ª–µ–Ω–Ω—è ---
    updated = 0
    failed = 0

    # We'll batch update product images alt/title via product PUT if possible
    # Prepare a copy of current images with alt changes to minimize number of product PUTs.
    wc_images_update = []
    for img in image_list:
        media_id = img.get("id")
        src = img.get("src") or ""
        filename = os.path.basename(src) if src else None

        # Prefer media_id; if missing, try to find by filename
        if not media_id and filename:
            found_id = find_media_id_by_filename(filename)
            if found_id:
                media_id = found_id
                logging.info(f"–ó–Ω–∞–π–¥–µ–Ω–æ media_id {media_id} –ø–æ —Ñ–∞–π–ª—É {filename}")
            else:
                logging.warning(f"–ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ media record –¥–ª—è {filename}. –ü—Ä–æ–ø—É—Å–∫–∞—é.")
                continue

        if media_id:
            # For WooCommerce product update we will set alt and name (title)
            wc_images_update.append({"id": media_id, "alt": seo_data["alt"], "name": seo_data["title"]})

    # If we have any image updates for WooCommerce ‚Äî send one PUT to products/{id}
    if wc_images_update and product_id:
        try:
            resp_put = wcapi.put(f"products/{product_id}", {"images": wc_images_update})
            if resp_put.status_code == 200:
                logging.info("‚úÖ WooCommerce: alt/title –æ–Ω–æ–≤–ª–µ–Ω–æ —á–µ—Ä–µ–∑ products PUT")
                updated += len(wc_images_update)
            else:
                logging.error(f"‚ùå WooCommerce products PUT returned {resp_put.status_code}: {resp_put.text[:300]}")
                # don't return ‚Äî try per-media WP updates below
        except Exception as e:
            logging.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ WooCommerce products PUT: {e}")

    # Now, attempt to update caption/description via wp/v2/media for each image
    for img in image_list:
        media_id = img.get("id")
        src = img.get("src") or ""
        filename = os.path.basename(src) if src else None

        if not media_id:
            if filename:
                media_id = find_media_id_by_filename(filename)
                if media_id:
                    logging.info(f"–ó–Ω–∞–π–¥–µ–Ω–æ media_id {media_id} –¥–ª—è {filename} —á–µ—Ä–µ–∑ –ø–æ—à—É–∫.")
                else:
                    logging.warning(f"–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–Ω–∞–π—Ç–∏ media_id –¥–ª—è {filename}. –ü—Ä–æ–ø—É—Å–∫–∞—é WP media update.")
                    failed += 1
                    continue
            else:
                logging.warning("–ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è –Ω–µ –º–∞—î src —Ç–∞ id ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞—é.")
                failed += 1
                continue

        media_endpoint = f"{base_url}/wp-json/wp/v2/media/{media_id}"
        update_data = {
            "title": seo_data["title"],
            "alt_text": seo_data["alt"],
            "caption": seo_data["caption"],
            "description": seo_data["description"]
        }

        # –¢—Ä–µ–±–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü—ñ—è –¥–ª—è wp/v2/media (Application Password –∞–±–æ user/pass)
        if not wp_login or not wp_pass:
            logging.warning("‚ö†Ô∏è –í settings.json –Ω–µ –∑–Ω–∞–π–¥–µ–Ω—ñ 'login' —Ç–∞ 'pass' ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞—é –æ–Ω–æ–≤–ª–µ–Ω–Ω—è caption/description —á–µ—Ä–µ–∑ wp/v2/media.")
            failed += 1
            continue

        try:
            r = requests.put(media_endpoint, auth=(wp_login, wp_pass), json=update_data, timeout=20, verify=True)
            if r.status_code == 200:
                print(f"‚úÖ –û–Ω–æ–≤–ª–µ–Ω–æ –º–µ–¥—ñ–∞ ID {media_id} ({filename if filename else ''})")
                updated += 1
            else:
                logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è ID {media_id}. –°—Ç–∞—Ç—É—Å: {r.status_code}. –ü–æ–º–∏–ª–∫–∞: {r.text[:300]}")
                failed += 1
        except requests.exceptions.RequestException as e:
            logging.error(f"–ö—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –∑–∞–ø–∏—Ç—É –¥–ª—è {media_id}: {e}")
            failed += 1

    print(f"üéØ –ó–∞–≤–µ—Ä—à–µ–Ω–æ. –£—Å–ø—ñ—à–Ω–æ –æ–Ω–æ–≤–ª–µ–Ω–æ: {updated}, –Ω–µ –≤–¥–∞–ª–æ—Å—è: {failed}.")

# --- –ó–ê–ü–û–í–ù–ï–ù–ù–Ø –ö–û–õ–û–ù–ö–ò _wpml_import_translation_group ---
def fill_wpml_translation_group():
    """
    –®—É–∫–∞—î trid (_wpml_import_translation_group) —É –±–∞–∑—ñ WordPress
    –∑–∞ SKU —ñ –æ–Ω–æ–≤–ª—é—î —Ü–µ–π —Å–∞–º–∏–π CSV-—Ñ–∞–π–ª (–±–µ–∑ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –∫–æ–ø—ñ—ó).
    """
    log_message_to_existing_file()
    logging.info("üöÄ –ü–æ—á–∞—Ç–æ–∫ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è –∫–æ–ª–æ–Ω–∫–∏ _wpml_import_translation_group")

    settings = load_settings()
    csv_path = settings["paths"].get("csv_path_sl_new_prod_ru")
    db_conf = settings.get("db")

    # üîπ –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó
    if not db_conf:
        logging.error("‚ùå –£ settings.json –≤—ñ–¥—Å—É—Ç–Ω—ñ–π —Ä–æ–∑–¥—ñ–ª 'db' –∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –±–∞–∑–∏ –¥–∞–Ω–∏—Ö")
        return

    # üîπ –ü—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ MySQL
    conn = mysql.connector.connect(
        host=db_conf["host"],
        user=db_conf["user"],
        password=db_conf["password"],
        database=db_conf["database"],
        charset="utf8mb4"
    )
    cursor = conn.cursor(dictionary=True)

    # üîπ –ó—á–∏—Ç—É—î–º–æ —É—Å—ñ —Ä—è–¥–∫–∏ –∑ —Ñ–∞–π–ª—É
    with open(csv_path, "r", encoding="utf-8") as infile:
        reader = csv.DictReader(infile)
        rows = list(reader)
        fieldnames = reader.fieldnames
        if "_wpml_import_translation_group" not in fieldnames:
            fieldnames.append("_wpml_import_translation_group")

    logging.info("üöÄ –ü–æ—á–∞—Ç–æ–∫ –ø–æ—à—É–∫—É trid –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ SKU...")

    # üîπ –û–±—Ä–æ–±–∫–∞ –∫–æ–∂–Ω–æ–≥–æ SKU
    for idx, row in enumerate(rows, start=2):
        sku = row.get("Sku")
        if not sku:
            logging.warning(f"–†—è–¥–æ–∫ {idx}: –ø—Ä–æ–ø—É—â–µ–Ω–æ —á–µ—Ä–µ–∑ –≤—ñ–¥—Å—É—Ç–Ω—ñ–π SKU")
            continue

        # –ó–Ω–∞–π—Ç–∏ product_id –∑–∞ SKU
        cursor.execute("""
            SELECT pm.post_id
            FROM wp_postmeta pm
            JOIN wp_posts p ON p.ID = pm.post_id
            WHERE pm.meta_key = '_sku' AND pm.meta_value = %s AND p.post_type = 'product'
            LIMIT 1;
        """, (sku,))
        res = cursor.fetchone()

        if not res:
            logging.warning(f"‚ö†Ô∏è SKU {sku}: —Ç–æ–≤–∞—Ä –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ —É –±–∞–∑—ñ")
            continue

        product_id = res["post_id"]

        # –ó–Ω–∞–π—Ç–∏ trid
        cursor.execute("""
            SELECT trid
            FROM wp_icl_translations
            WHERE element_type = 'post_product' AND element_id = %s
            LIMIT 1;
        """, (product_id,))
        trid_res = cursor.fetchone()

        if trid_res:
            trid = trid_res["trid"]
            row["_wpml_import_translation_group"] = trid
            logging.info(f"‚úÖ SKU {sku}: –∑–Ω–∞–π–¥–µ–Ω–æ trid = {trid}")
        else:
            logging.warning(f"‚ö†Ô∏è SKU {sku}: –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ trid —É wp_icl_translations")

    # üîπ –ó–∞–ø–∏—Å—É—î–º–æ –Ω–∞–∑–∞–¥ —É —Ç–æ–π —Å–∞–º–∏–π —Ñ–∞–π–ª
    with open(csv_path, "w", encoding="utf-8", newline="") as outfile:
        writer = csv.DictWriter(outfile, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(rows)

    cursor.close()
    conn.close()

    logging.info(f"üèÅ –û–Ω–æ–≤–ª–µ–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –î–∞–Ω—ñ –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É {csv_path}")

# --- –ü–ï–†–ï–ö–õ–ê–î CSV –£–ö–† ‚Üí –†–£–° ---
def clean_text(text):
    """
    –í–∏–¥–∞–ª—è—î HTML —Ç–µ–≥–∏ —Ç–∞ –∑–∞–π–≤—ñ –ø—Ä–æ–±—ñ–ª–∏.
    """
    if not text:
        return ""
    text = re.sub(r'<[^>]+>', '', text)  # –≤–∏–¥–∞–ª–∏—Ç–∏ HTML —Ç–µ–≥–∏
    text = re.sub(r'\s+', ' ', text).strip()  # –∑–∞–π–≤—ñ –ø—Ä–æ–±—ñ–ª–∏ —Ç–∞ –ø–µ—Ä–µ–≤–æ–¥–∏ —Ä—è–¥–∫—ñ–≤
    return text

def get_deepl_usage(api_key, api_url="https://api-free.deepl.com/v2/usage"):
    """
    –ü–µ—Ä–µ–≤—ñ—Ä—è—î –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è —Å–∏–º–≤–æ–ª—ñ–≤ DeepL API (Free –∞–±–æ Pro).
    –ü–æ–≤–µ—Ä—Ç–∞—î —Å–ª–æ–≤–Ω–∏–∫ –∑ used_characters, limit, remaining.
    """
    try:
        response = requests.get(api_url, headers={"Authorization": f"DeepL-Auth-Key {api_key}"}, timeout=15)
        response.raise_for_status()
        data = response.json()
        used = data.get("character_count", 0)
        limit = data.get("character_limit", 0)
        remaining = limit - used if limit else None
        logging.info(f"üîπ –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–æ {used:,} —ñ–∑ {limit:,} —Å–∏–º–≤–æ–ª—ñ–≤ DeepL (–∑–∞–ª–∏—à–∏–ª–æ—Å—å {remaining:,})")
        return {"used": used, "limit": limit, "remaining": remaining}
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –ª—ñ–º—ñ—Ç DeepL: {e}")
        return None

def translate_text_deepl(text, target_lang="RU", api_key=None, api_url=None):
    """
    –ü–µ—Ä–µ–∫–ª–∞–¥ —Ç–µ–∫—Å—Ç—É —á–µ—Ä–µ–∑ DeepL API –∑ —ñ–≥–Ω–æ—Ä—É–≤–∞–Ω–Ω—è–º –∞–Ω–≥–ª—ñ–π—Å—å–∫–∏—Ö —Å–ª—ñ–≤ —Ç–∞ –∫–æ–¥—ñ–≤.
    –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –∫–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–≥ <i> –¥–ª—è –µ–∫–æ–Ω–æ–º—ñ—ó —Å–∏–º–≤–æ–ª—ñ–≤.
    """
    if not text.strip():
        return text
    if not api_key:
        logging.error("API –∫–ª—é—á DeepL –Ω–µ –≤–∫–∞–∑–∞–Ω–æ!")
        return text
    if not api_url:
        api_url = "https://api-free.deepl.com/v2/translate"

    # –†–æ–∑–±–∏–≤–∞—î–º–æ —Ç–µ–∫—Å—Ç –Ω–∞ —à–º–∞—Ç–∫–∏, —â–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ –æ–±–º–µ–∂–µ–Ω—å API
    chunks = []
    current = ""
    for paragraph in text.split(". "):
        if len(current) + len(paragraph) + 2 <= 500:
            current += (". " if current else "") + paragraph
        else:
            if current:
                chunks.append(current)
            current = paragraph
    if current:
        chunks.append(current)

    translated_chunks = []
    for chunk in chunks:
        pattern = r'\b[a-zA-Z0-9][a-zA-Z0-9\-\.]*[a-zA-Z0-Z0-9]\b|\b[a-zA-Z0-9]+\b'
        
        # --- –ó–ú–Ü–ù–ê 1: –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –∫–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–≥ <i> ---
        chunk_with_tags = re.sub(pattern, r'<i>\g<0></i>', chunk)

        try:
            response = requests.post(
                api_url,
                data={
                    "auth_key": api_key,
                    "text": chunk_with_tags,
                    "target_lang": target_lang,
                    "tag_handling": "xml",
                    # --- –ó–ú–Ü–ù–ê 2: –í–∫–∞–∑—É—î–º–æ –Ω–æ–≤–∏–π —Ç–µ–≥ –¥–ª—è —ñ–≥–Ω–æ—Ä—É–≤–∞–Ω–Ω—è ---
                    "ignore_tags": "i" 
                },
                timeout=30
            )
            response.raise_for_status()
            
            translated_text = response.json()["translations"][0]["text"]
            
            # –ù–∞–¥—ñ–π–Ω–µ –æ—á–∏—â–µ–Ω–Ω—è —Ç–µ–≥—ñ–≤, —è–∫—â–æ API —ó—Ö –≤–∏–ø–∞–¥–∫–æ–≤–æ –ø–æ–≤–µ—Ä–Ω—É–≤
            translated_text = translated_text.replace("<i>", "").replace("</i>", "")
            
            translated_chunks.append(translated_text)
            time.sleep(0.5)
        except Exception as e:
            logging.error(f"–ü–æ–º–∏–ª–∫–∞ –ø–µ—Ä–µ–∫–ª–∞–¥—É: {e}")
            translated_chunks.append(chunk)

    return " ".join(translated_chunks)

def translate_csv_to_ru():
    """
    –ü–µ—Ä–µ–∫–ª–∞–¥–∞—î content —Ç–∞ excerpt –∑ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—ó –Ω–∞ —Ä–æ—Å—ñ–π—Å—å–∫—É
    —Ç–∞ –∑–±–µ—Ä—ñ–≥–∞—î —É SL_new_prod_ru.csv
    """
    log_message_to_existing_file()
    logging.info("üöÄ –ü–æ—á–∞—Ç–æ–∫ –ø–µ—Ä–µ–∫–ª–∞–¥—É CSV –Ω–∞ —Ä–æ—Å—ñ–π—Å—å–∫—É...")

    settings = load_settings()
    if not settings:
        logging.error("‚ùå –ù–µ–º–æ–∂–ª–∏–≤–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ settings.json")
        return

    input_path = settings["paths"].get("csv_path_sl_new_prod")
    output_path = settings["paths"].get("csv_path_sl_new_prod_ru")
    api_key = settings.get("deepl_api_key")
    api_url = settings.get("DEEPL_API_URL", "https://api-free.deepl.com/v2/translate")

    if not all([input_path, output_path, api_key]):
        logging.error("‚ùå –ù–µ –≤–∫–∞–∑–∞–Ω—ñ –≤—Å—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ —É settings.json")
        return

    try:
        with open(input_path, 'r', encoding='utf-8') as f_in, \
             open(output_path, 'w', encoding='utf-8', newline='') as f_out:

            reader = csv.DictReader(f_in)
            output_headers = ["sku", "name", "content", "short_description", "rank_math_focus_keyword", "lang", "translation_of"]
            writer = csv.DictWriter(f_out, fieldnames=output_headers)
            writer.writeheader()

            for idx, row in enumerate(reader, start=2):
                new_row = {}

                # 1. SKU
                new_row["sku"] = row.get("sku", "")

                # 2. Name –±–µ–∑ –ø–µ—Ä–µ–∫–ª–∞–¥—É
                new_row["name"] = row.get("name", "")

                # 3. –ü–µ—Ä–µ–∫–ª–∞–¥ content
                content_text = clean_text(row.get("content", ""))
                new_row["content"] = translate_text_deepl(content_text, target_lang="RU", api_key=api_key, api_url=api_url)

                # 4. –ü–µ—Ä–µ–∫–ª–∞–¥ excerpt ‚Üí short_description
                excerpt_text = clean_text(row.get("excerpt", ""))
                new_row["short_description"] = translate_text_deepl(excerpt_text, target_lang="RU", api_key=api_key, api_url=api_url)

                # 5. Rank Math
                new_row["rank_math_focus_keyword"] = row.get("rank_math_focus_keyword", "")

                # 6. WPML
                new_row["lang"] = "ru"
                new_row["translation_of"] = ""  # –º–æ–∂–Ω–∞ –ø—ñ–¥—Å—Ç–∞–≤–∏—Ç–∏ ID –æ—Ä–∏–≥—ñ–Ω–∞–ª—É

                writer.writerow(new_row)
                logging.info(f"–†—è–¥–æ–∫ {idx}: –ø–µ—Ä–µ–∫–ª–∞–¥ content —Ç–∞ short_description –∑–∞–≤–µ—Ä—à–µ–Ω–æ")

        logging.info(f"‚úÖ –ü–µ—Ä–µ–∫–ª–∞–¥ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –§–∞–π–ª –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {output_path}")

    except FileNotFoundError:
        logging.error(f"‚ùå –í—Ö—ñ–¥–Ω–∏–π —Ñ–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {input_path}")
    except Exception as e:
        logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–∫–ª–∞–¥—ñ CSV: {e}")

# --- –õ–û–ì–£–í–ê–ù–ù–Ø –ì–õ–û–ë–ê–õ–¨–ù–ò–• –ê–¢–†–ò–ë–£–¢–Ü–í WOO ---
def log_global_attributes():
    """
    –û—Ç—Ä–∏–º—É—î —Å–ø–∏—Å–æ–∫ –≥–ª–æ–±–∞–ª—å–Ω–∏—Ö –∞—Ç—Ä–∏–±—É—Ç—ñ–≤ WooCommerce (pa_*)
    —ñ –≤–∏–≤–æ–¥–∏—Ç—å —ó—Ö —É –ª–æ–≥ —ñ–∑ ID, slug —Ç–∞ –Ω–∞–∑–≤–æ—é.
    """
    log_message_to_existing_file()
    logging.info("üîç –ü–æ—á–∏–Ω–∞—é –æ—Ç—Ä–∏–º–∞–Ω–Ω—è —Å–ø–∏—Å–∫—É –≥–ª–æ–±–∞–ª—å–Ω–∏—Ö –∞—Ç—Ä–∏–±—É—Ç—ñ–≤ WooCommerce...")

    settings = load_settings()
    if not settings:
        logging.error("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ settings.json")
        return

    wcapi = get_wc_api(settings)
    if not wcapi:
        logging.error("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è —Å—Ç–≤–æ—Ä–∏—Ç–∏ –æ–±'—î–∫—Ç WooCommerce API.")
        return

    try:
        page = 1
        all_attributes = []
        MAX_PAGES = 5  # üîí –±–µ–∑–ø–µ—á–Ω–∞ –º–µ–∂–∞, –±–æ –≥–ª–æ–±–∞–ª—å–Ω–∏—Ö –∞—Ç—Ä–∏–±—É—Ç—ñ–≤ –º–∞–∫—Å–∏–º—É–º –∫—ñ–ª—å–∫–∞ –¥–µ—Å—è—Ç–∫—ñ–≤

        while page <= MAX_PAGES:
            response = wcapi.get("products/attributes", params={"per_page": 100, "page": page})
            logging.info(f"‚û°Ô∏è –û—Ç—Ä–∏–º–∞–Ω–æ —Å—Ç–æ—Ä—ñ–Ω–∫—É {page} (—Å—Ç–∞—Ç—É—Å {response.status_code})")

            if response.status_code != 200:
                logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Ç—ñ –¥–æ WooCommerce API: {response.status_code} - {response.text}")
                break

            data = response.json()
            if not data:
                logging.info("üì≠ –ë—ñ–ª—å—à–µ —Å—Ç–æ—Ä—ñ–Ω–æ–∫ –Ω–µ–º–∞—î ‚Äî –∑–∞–≤–µ—Ä—à—É—é –∑–∞–ø–∏—Ç.")
                break

            all_attributes.extend(data)
            if len(data) < 100:
                break  # –º–µ–Ω—à–µ 100 ‚Äî –∑–Ω–∞—á–∏—Ç—å, –æ—Å—Ç–∞–Ω–Ω—è —Å—Ç–æ—Ä—ñ–Ω–∫–∞
            page += 1

        if not all_attributes:
            logging.warning("‚ö†Ô∏è –ì–ª–æ–±–∞–ª—å–Ω—ñ –∞—Ç—Ä–∏–±—É—Ç–∏ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
            return

        logging.info("üß© --- –ì–ª–æ–±–∞–ª—å–Ω—ñ –∞—Ç—Ä–∏–±—É—Ç–∏ WooCommerce ---")
        for attr in all_attributes:
            attr_id = attr.get("id")
            name = attr.get("name")
            slug = attr.get("slug")
            type_ = attr.get("type")
            orderby = attr.get("order_by")
            logging.info(f"ID={attr_id:>3} | slug={slug:<20} | name={name:<25} | type={type_} | orderby={orderby}")

        logging.info(f"‚úÖ –í—Å—å–æ–≥–æ –∑–Ω–∞–π–¥–µ–Ω–æ {len(all_attributes)} –≥–ª–æ–±–∞–ª—å–Ω–∏—Ö –∞—Ç—Ä–∏–±—É—Ç—ñ–≤.")

    except Exception as e:
        logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ—Ç—Ä–∏–º–∞–Ω–Ω—ñ —Å–ø–∏—Å–∫—É –∞—Ç—Ä–∏–±—É—Ç—ñ–≤: {e}", exc_info=True)


# --- –ö–û–ù–í–ï–†–¢–ê–¶–Ü–Ø –õ–û–ö–ê–õ–¨–ù–ò–• –ê–¢–†–ò–ë–£–¢–Ü–í –£ –ì–õ–û–ë–ê–õ–¨–ù–Ü ---
def convert_local_attributes_to_global():
    """
    –ü–∞–∫–µ—Ç–Ω–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –ª–æ–∫–∞–ª—å–Ω–∏—Ö –∞—Ç—Ä–∏–±—É—Ç—ñ–≤ —É –≥–ª–æ–±–∞–ª—å–Ω—ñ
    –¥–ª—è —Ç–æ–≤–∞—Ä—ñ–≤, —Å—Ç–≤–æ—Ä–µ–Ω–∏—Ö –ø—ñ—Å–ª—è 1 –≤–µ—Ä–µ—Å–Ω—è 2025 —Ä–æ–∫—É.
    """
    from datetime import datetime
    import re

    log_message_to_existing_file()
    logging.info("üöÄ –ü–æ—á–∞—Ç–æ–∫ –ø–∞–∫–µ—Ç–Ω–æ—ó –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—ó –ª–æ–∫–∞–ª—å–Ω–∏—Ö –∞—Ç—Ä–∏–±—É—Ç—ñ–≤ —É –≥–ª–æ–±–∞–ª—å–Ω—ñ –¥–ª—è –æ—Å—Ç–∞–Ω–Ω—ñ—Ö —Ç–æ–≤–∞—Ä—ñ–≤...")

    settings = load_settings()
    if not settings:
        logging.critical("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è.")
        return

    wcapi = get_wc_api(settings)
    if not wcapi:
        logging.critical("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –ø—ñ–¥–∫–ª—é—á–∏—Ç–∏—Å—è –¥–æ WooCommerce API.")
        return

    global_attr_map = settings.get("global_attr_map", {})
    numeric_attrs = ["pa_diameter", "pa_length", "pa_height"]
    cutoff_date = datetime(2025, 9, 1)

    def _smart_split_attr(attr_name, val):
        if not val:
            return []
        if attr_name in numeric_attrs:
            parts = [p.strip() for p in re.split(r'[|;,]', val) if p.strip()]
            return [",".join(parts)]
        else:
            parts = [p.strip() for p in re.split(r'[|;,]', val) if p.strip()]
            return parts

    try:
        # –û—Ç—Ä–∏–º—É—î–º–æ –≤—Å—ñ —Ç–æ–≤–∞—Ä–∏ –ø—ñ—Å–ª—è cutoff_date (–ø–æ—Å—Ç–∞—î–º–æ —É —Å—Ç–æ—Ä—ñ–Ω–∫–∞—Ö –ø–æ 100)
        page = 1
        per_page = 10
        total_checked = 0
        total_updated = 0

        while True:
            response = wcapi.get("products", params={
                "per_page": per_page,
                "page": page,
                "after": cutoff_date.isoformat(),
                "orderby": "date",
                "order": "asc"
            })
            if response.status_code != 200:
                logging.error(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ —Ç–æ–≤–∞—Ä–∏: {response.text}")
                break

            products = response.json()
            if not products:
                break  # –∫—ñ–Ω–µ—Ü—å —Å–ø–∏—Å–∫—É

            for product in products:
                product_id = product["id"]
                product_name = product.get("name", "")
                attributes = product.get("attributes", [])
                local_attrs = []
                global_attrs = []

                for attr in attributes:
                    attr_name = attr.get("name")
                    attr_id = attr.get("id")
                    if attr_id and attr_id in global_attr_map.values():
                        global_attrs.append(attr)
                    else:
                        local_attrs.append(attr)

                logging.info(f"–¢–æ–≤–∞—Ä ID={product_id}, Name='{product_name}': {len(global_attrs)} –≥–ª–æ–±–∞–ª—å–Ω–∏—Ö, {len(local_attrs)} –ª–æ–∫–∞–ª—å–Ω–∏—Ö –∞—Ç—Ä–∏–±—É—Ç—ñ–≤")

                if not local_attrs:
                    total_checked += 1
                    continue

                # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –ª–æ–∫–∞–ª—å–Ω–∏—Ö —É –≥–ª–æ–±–∞–ª—å–Ω—ñ
                changes = 0
                for attr in local_attrs:
                    name = attr.get("name")
                    value = "|".join(attr.get("options", []))
                    attr["options"] = _smart_split_attr(name, value)
                    if name in global_attr_map:
                        attr["id"] = global_attr_map[name]
                        changes += 1

                if changes:
                    product_data = {"id": product_id, "attributes": attributes}
                    resp_update = wcapi.put(f"products/{product_id}", product_data)
                    if resp_update.status_code == 200:
                        logging.info(f"‚úÖ –û–Ω–æ–≤–ª–µ–Ω–æ {changes} –∞—Ç—Ä–∏–±—É—Ç—ñ–≤ –¥–ª—è SKU={product.get('sku','')} / ID={product_id}")
                        total_updated += changes
                    else:
                        logging.error(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –æ–Ω–æ–≤–∏—Ç–∏ —Ç–æ–≤–∞—Ä ID={product_id}: {resp_update.text}")

                total_checked += 1

            page += 1

        logging.info(f"--- üèÅ –ü—ñ–¥—Å—É–º–æ–∫ ---")
        logging.info(f"–í—Å—å–æ–≥–æ –ø–µ—Ä–µ–≤—ñ—Ä–µ–Ω–æ —Ç–æ–≤–∞—Ä—ñ–≤: {total_checked}")
        logging.info(f"–í—Å—å–æ–≥–æ –æ–Ω–æ–≤–ª–µ–Ω–æ –∞—Ç—Ä–∏–±—É—Ç—ñ–≤: {total_updated}")

    except Exception as e:
        logging.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞: {e}", exc_info=True)
