from woocommerce import API
import json
import os, csv, shutil, logging, requests, mimetypes, glob
import logging
import html
import re
from datetime import datetime
from typing import Dict, Tuple, List, Optional, Any
from PIL import Image
from bs4 import BeautifulSoup
import time


def load_settings():
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó –∑ settings.json
    """
    config_path = os.path.join(os.path.dirname(__file__), "..", "config", "settings.json")
    try:
        with open(config_path, "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: —Ñ–∞–π–ª –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∑–∞ —à–ª—è—Ö–æ–º: {config_path}")
        return None
    except json.JSONDecodeError:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: —Ñ–∞–π–ª –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó –ø–æ—à–∫–æ–¥–∂–µ–Ω–∏–π: {config_path}")
        return None



def get_wc_api(settings):
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó –∑ settings.json
    """
    config_path = os.path.join(os.path.dirname(__file__), "..", "config", "settings.json")
    with open(config_path, "r", encoding="utf-8") as f:
        settings = json.load(f)

    wcapi = API(
        url=settings["url"],
        consumer_key=settings["consumer_key"],
        consumer_secret=settings["consumer_secret"],
        version="wc/v3",
        timeout=120,
        query_string_auth=True
    )
    return wcapi

def check_version():
    wcapi = get_wc_api()
    response = wcapi.get("system_status")
    if response.status_code == 200:
        data = response.json()
        print("WooCommerce version:", data.get("environment", {}).get("version"))
    else:
        print("Error:", response.status_code, response.text)



def setup_new_log_file():
    """
    –ü–µ—Ä–µ–π–º–µ–Ω–æ–≤—É—î —ñ—Å–Ω—É—é—á–∏–π –ª–æ–≥-—Ñ–∞–π–ª —Ç–∞ –Ω–∞–ª–∞—à—Ç–æ–≤—É—î –Ω–æ–≤–∏–π,
    –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—á–∏ —à–ª—è—Ö –∑ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω—å.
    """
    settings = load_settings()
    if not settings or "paths" not in settings or "main_log_file" not in settings["paths"]:
        print("‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ —à–ª—è—Ö –¥–æ –ª–æ–≥-—Ñ–∞–π–ª—É –≤ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è—Ö.")
        return

    current_log_path = os.path.join(os.path.dirname(__file__), "..", settings["paths"]["main_log_file"])
    log_dir = os.path.dirname(current_log_path)
    
    os.makedirs(log_dir, exist_ok=True)
    
    if os.path.exists(current_log_path):
        timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        file_name, file_extension = os.path.splitext(os.path.basename(current_log_path))
        new_log_path = os.path.join(log_dir, f"{file_name}_{timestamp}{file_extension}")
        try:
            os.rename(current_log_path, new_log_path)
            print(f"‚úÖ –°—Ç–∞—Ä–∏–π –ª–æ–≥-—Ñ–∞–π–ª –ø–µ—Ä–µ–π–º–µ–Ω–æ–≤–∞–Ω–æ –Ω–∞ {os.path.basename(new_log_path)}")
        except OSError as e:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–π–º–µ–Ω—É–≤–∞–Ω–Ω—ñ –ª–æ–≥-—Ñ–∞–π–ª—É: {e}")

    logging.basicConfig(
        filename=current_log_path,
        level=logging.INFO,
        format='%(asctime)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S',
        filemode='a'
    )
    logging.info("--- –ù–æ–≤–∏–π —Å–µ–∞–Ω—Å –ª–æ–≥—É–≤–∞–Ω–Ω—è —Ä–æ–∑–ø–æ—á–∞—Ç–æ ---")

def log_message_to_existing_file():
    """
    –ù–∞–ª–∞—à—Ç–æ–≤—É—î –ª–æ–≥—É–≤–∞–Ω–Ω—è –¥–ª—è –¥–æ–ø–∏—Å—É–≤–∞–Ω–Ω—è –≤ —ñ—Å–Ω—É—é—á–∏–π —Ñ–∞–π–ª,
    –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—á–∏ —à–ª—è—Ö –∑ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω—å.
    """
    settings = load_settings()
    if not settings or "paths" not in settings or "main_log_file" not in settings["paths"]:
        print("‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ —à–ª—è—Ö –¥–æ –ª–æ–≥-—Ñ–∞–π–ª—É –≤ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è—Ö.")
        return

    current_log_path = os.path.join(os.path.dirname(__file__), "..", settings["paths"]["main_log_file"])
    log_dir = os.path.dirname(current_log_path)
    
    os.makedirs(log_dir, exist_ok=True)

    if not logging.getLogger().hasHandlers():
        logging.basicConfig(
            filename=current_log_path,
            level=logging.INFO,
            format='%(asctime)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S',
            filemode='a'
        )
    logging.info("--- –ü–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –¥–æ–¥–∞–Ω–æ –¥–æ —ñ—Å–Ω—É—é—á–æ–≥–æ –ª–æ–≥—É ---")



def check_csv_data(profile_id):
    """
    –ü–µ—Ä–µ–≤—ñ—Ä—è—î CSV-—Ñ–∞–π–ª –Ω–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω—ñ—Å—Ç—å –ø—Ä–∞–≤–∏–ª–∞–º, –≤–∏–∑–Ω–∞—á–µ–Ω–∏–º —É settings.json.
    
    Args:
        profile_id (str): ID –ø—Ä–æ—Ñ—ñ–ª—é –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ –∑ 'validation_profiles' –≤ settings.json.
    
    Returns:
        bool: True, —è–∫—â–æ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ –ø—Ä–æ–π—à–ª–∞ —É—Å–ø—ñ—à–Ω–æ, —ñ–Ω–∞–∫—à–µ False.
    """
    # 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω—å
    # –¶–µ–π –±–ª–æ–∫ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î –∑–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó –∑ —Ñ–∞–π–ª—É settings.json
    # —Ç–∞ –ø–µ—Ä–µ–≤—ñ—Ä—è—î, —á–∏ —ñ—Å–Ω—É—î –≤–∫–∞–∑–∞–Ω–∏–π –ø—Ä–æ—Ñ—ñ–ª—å –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó.
    # –Ø–∫—â–æ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –∞–±–æ –ø—Ä–æ—Ñ—ñ–ª—å –≤—ñ–¥—Å—É—Ç–Ω—ñ–π, —Ñ—É–Ω–∫—Ü—ñ—è –∑–∞–≤–µ—Ä—à—É—î —Ä–æ–±–æ—Ç—É.
    
    log_message_to_existing_file()
    
    try:
        with open(os.path.join(os.path.dirname(__file__), "..", "config", "settings.json"), "r", encoding="utf-8") as f:
            settings = json.load(f)
    except (FileNotFoundError, json.JSONDecodeError) as e:
        logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó: {e}")
        return False
        
    profiles = settings.get("validation_profiles", {})
    if profile_id not in profiles:
        logging.error(f"‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –ø—Ä–æ—Ñ—ñ–ª—å –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó –∑ ID '{profile_id}' –≤ settings.json.")
        return False
    
    # 2. –û—Ç—Ä–∏–º–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö –ø—Ä–æ—Ñ—ñ–ª—é
    # –û—Ç—Ä–∏–º—É—î–º–æ —à–ª—è—Ö –¥–æ —Ñ–∞–π–ª—É —Ç–∞ –ø—Ä–∞–≤–∏–ª–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó –¥–ª—è –æ–±—Ä–∞–Ω–æ–≥–æ –ø—Ä–æ—Ñ—ñ–ª—é.
    profile = profiles[profile_id]
    csv_path_relative = profile.get("path")
    validation_rules = profile.get("rules")
    
    if not csv_path_relative or validation_rules is None:
        logging.error("‚ùå –ù–µ–ø–æ–≤–Ω—ñ –¥–∞–Ω—ñ –≤ –ø—Ä–æ—Ñ—ñ–ª—ñ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó.")
        return False
        
    # 3. –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ —Ñ–∞–π–ª—É
    # –§–æ—Ä–º—É—î–º–æ –ø–æ–≤–Ω–∏–π —à–ª—è—Ö –¥–æ —Ñ–∞–π–ª—É —Ç–∞ –ø–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –π–æ–≥–æ —ñ—Å–Ω—É–≤–∞–Ω–Ω—è –Ω–∞ –¥–∏—Å–∫—É.
    base_dir = os.path.join(os.path.dirname(__file__), "..")
    full_csv_path = os.path.join(base_dir, csv_path_relative)
    
    if not os.path.exists(full_csv_path):
        logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞: —Ñ–∞–π–ª –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return False
        
    logging.info(f"üîé –ü–æ—á–∞—Ç–æ–∫ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ —Ñ–∞–π–ª—É")
    
    # 4. –ß–∏—Ç–∞–Ω–Ω—è —Ç–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—è –¥–∞–Ω–∏—Ö
    # –í—ñ–¥–∫—Ä–∏–≤–∞—î–º–æ —Ñ–∞–π–ª —Ç–∞ –ø–æ—á–∏–Ω–∞—î–º–æ —ñ—Ç–µ—Ä–∞—Ü—ñ—é –ø–æ –π–æ–≥–æ –≤–º—ñ—Å—Ç—É.
    try:
        with open(full_csv_path, "r", encoding="utf-8") as f:
            reader = csv.reader(f)
            try:
                headers = next(reader)
            except StopIteration:
                logging.error("‚ùå –§–∞–π–ª –ø–æ—Ä–æ–∂–Ω—ñ–π. –í—ñ–¥—Å—É—Ç–Ω—ñ –∑–∞–≥–æ–ª–æ–≤–∫–∏.")
                return False
            
            # 5. –û–Ω–æ–≤–ª–µ–Ω–∞ –ª–æ–≥—ñ–∫–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ –∑–∞–≥–æ–ª–æ–≤–∫—ñ–≤
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ –≤—Å—ñ –æ—á—ñ–∫—É–≤–∞–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏ –ø—Ä–∏—Å—É—Ç–Ω—ñ —É –∑–∞–≥–æ–ª–æ–≤–∫–∞—Ö —Ñ–∞–π–ª—É
            rule_columns = list(validation_rules.keys())
            headers_set = set(headers)
            for col_name in rule_columns:
                if col_name not in headers_set:
                    logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞: –æ—á—ñ–∫—É–≤–∞–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ '{col_name}' –≤—ñ–¥—Å—É—Ç–Ω—è —É —Ñ–∞–π–ª—ñ.")
                    return False
            
            # –°—Ç–≤–æ—Ä—é—î–º–æ —Å–ª–æ–≤–Ω–∏–∫ –¥–ª—è —à–≤–∏–¥–∫–æ–≥–æ –¥–æ—Å—Ç—É–ø—É –¥–æ —ñ–Ω–¥–µ–∫—Å—ñ–≤ –∫–æ–ª–æ–Ω–æ–∫
            header_map = {name: index for index, name in enumerate(headers)}
            
            # 6. –í–∞–ª—ñ–¥–∞—Ü—ñ—è –∫–æ–∂–Ω–æ–≥–æ —Ä—è–¥–∫–∞
            for i, row in enumerate(reader):
                row_number = i + 2
                if not row or all(not col.strip() for col in row):
                    logging.info(f"‚úÖ –†—è–¥–æ–∫ {row_number} –ø–æ—Ä–æ–∂–Ω—ñ–π –∞–±–æ –º—ñ—Å—Ç–∏—Ç—å –ª–∏—à–µ –ø—Ä–æ–±—ñ–ª–∏. –ü—Ä–æ–ø—É—Å–∫–∞—é.")
                    continue
                
                # 7. –í–∞–ª—ñ–¥–∞—Ü—ñ—è –∫–æ–∂–Ω–æ–≥–æ –ø–æ–ª—è, —è–∫–µ —î –≤ –ø—Ä–∞–≤–∏–ª–∞—Ö
                for col_name, rule_type in validation_rules.items():
                    try:
                        col_index = header_map.get(col_name)
                        if col_index is None:
                            # –¶–µ –º–∞–ª–æ –±—É—Ç–∏ —Å–ø—ñ–π–º–∞–Ω–æ –Ω–∞ –µ—Ç–∞–ø—ñ 5, –∞–ª–µ —Ü–µ –¥–æ–¥–∞—Ç–∫–æ–≤–∞ –ø–µ—Ä–µ—Å—Ç—Ä–∞—Ö–æ–≤–∫–∞
                            continue
                        
                        if col_index >= len(row):
                            logging.error(f"‚ùå –†—è–¥–æ–∫ {row_number}: –†—è–¥–æ–∫ –∫–æ—Ä–æ—Ç—à–∏–π –∑–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –æ—á—ñ–∫—É–≤–∞–Ω–∏—Ö –∫–æ–ª–æ–Ω–æ–∫.")
                            return False
                        
                        value = row[col_index].strip()

                        # 7.0. –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ –æ–±–æ–≤‚Äô—è–∑–∫–æ–≤—ñ—Å—Ç—å –∑–∞–ø–æ–≤–Ω–µ–Ω–Ω—è
                        if rule_type == "not_empty":
                            if not value:
                                logging.error(f"‚ùå –†—è–¥–æ–∫ {row_number}, –∫–æ–ª–æ–Ω–∫–∞ '{col_name}': –ø–æ–ª–µ –Ω–µ –ø–æ–≤–∏–Ω–Ω–æ –±—É—Ç–∏ –ø–æ—Ä–æ–∂–Ω—ñ–º.")
                                return False
                            continue  # –Ω–µ –ø–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –¥–∞–ª—ñ
                        
                        # 7.1. –í–∞–ª—ñ–¥–∞—Ü—ñ—è —Ü—ñ–ª–∏—Ö —á–∏—Å–µ–ª
                        if rule_type == "integer":
                            if not value:
                                logging.error(f"‚ùå –†—è–¥–æ–∫ {row_number}, –∫–æ–ª–æ–Ω–∫–∞ '{col_name}': –æ—á—ñ–∫—É—î—Ç—å—Å—è —Ü—ñ–ª–µ —á–∏—Å–ª–æ, –∞–ª–µ –ø–æ–ª–µ –ø–æ—Ä–æ–∂–Ω—î.")
                                return False
                            if not value.lstrip('-').isdigit():
                                logging.error(f"‚ùå –†—è–¥–æ–∫ {row_number}, –∫–æ–ª–æ–Ω–∫–∞ '{col_name}': –æ—á—ñ–∫—É—î—Ç—å—Å—è —Ü—ñ–ª–µ —á–∏—Å–ª–æ, –∞–ª–µ –æ—Ç—Ä–∏–º–∞–Ω–æ '{value}'.")
                                return False

                        # 7.2. –í–∞–ª—ñ–¥–∞—Ü—ñ—è –∑–Ω–∞—á–µ–Ω—å –∑—ñ —Å–ø–∏—Å–∫—É
                        elif isinstance(rule_type, list):
                            if not value:
                                logging.error(f"‚ùå –†—è–¥–æ–∫ {row_number}, –∫–æ–ª–æ–Ω–∫–∞ '{col_name}': –æ—á—ñ–∫—É—î—Ç—å—Å—è –æ–¥–Ω–µ –∑—ñ –∑–Ω–∞—á–µ–Ω—å {rule_type}, –∞–ª–µ –ø–æ–ª–µ –ø–æ—Ä–æ–∂–Ω—î.")
                                return False
                            if value not in rule_type:
                                logging.error(f"‚ùå –†—è–¥–æ–∫ {row_number}, –∫–æ–ª–æ–Ω–∫–∞ '{col_name}': –æ—á—ñ–∫—É—î—Ç—å—Å—è –æ–¥–Ω–µ –∑—ñ –∑–Ω–∞—á–µ–Ω—å {rule_type}, –∞–ª–µ –æ—Ç—Ä–∏–º–∞–Ω–æ '{value}'.")
                                return False
                        
                        # 7.3. –í–∞–ª—ñ–¥–∞—Ü—ñ—è —Ñ–æ—Ä–º–∞—Ç—É –¥–∞—Ç–∏-—á–∞—Å—É
                        elif rule_type == "datetime":
                            if value:
                                try:
                                    datetime.strptime(value, "%Y-%m-%dT%H:%M:%S")
                                except ValueError:
                                    logging.error(f"‚ùå –†—è–¥–æ–∫ {row_number}, –∫–æ–ª–æ–Ω–∫–∞ '{col_name}': –Ω–µ–≤—ñ—Ä–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç–∏-—á–∞—Å—É. –û—á—ñ–∫—É—î—Ç—å—Å—è 'YYYY-MM-DDTHH:MM:SS', –∞–ª–µ –æ—Ç—Ä–∏–º–∞–Ω–æ '{value}'.")
                                    return False

                        # 7.4. –í–∞–ª—ñ–¥–∞—Ü—ñ—è —Ü—ñ–ª–∏—Ö —á–∏—Å–µ–ª (–¥–æ–ø—É—Å–∫–∞—î –ø–æ—Ä–æ–∂–Ω—î –ø–æ–ª–µ)
                        if rule_type == "integer_or_empty":
                            if value == "":
                                continue  # –ü–æ—Ä–æ–∂–Ω—î –∑–Ω–∞—á–µ–Ω–Ω—è ‚Äî –¥–æ–∑–≤–æ–ª–µ–Ω–µ
                            if not value.lstrip('-').isdigit():
                                logging.error(f"‚ùå –†—è–¥–æ–∫ {row_number}, –∫–æ–ª–æ–Ω–∫–∞ '{col_name}': –æ—á—ñ–∫—É—î—Ç—å—Å—è —Ü—ñ–ª–µ —á–∏—Å–ª–æ –∞–±–æ –ø–æ—Ä–æ–∂–Ω—î –ø–æ–ª–µ, –∞–ª–µ –æ—Ç—Ä–∏–º–∞–Ω–æ '{value}'.")
                                return False

                        # 7.5. –í–∞–ª—ñ–¥–∞—Ü—ñ—è —á–∏—Å–µ–ª –∑ –ø–ª–∞–≤–∞—é—á–æ—é –∫–æ–º–æ—é (float) (–¥–æ–ø—É—Å–∫–∞—î –ø–æ—Ä–æ–∂–Ω—î –ø–æ–ª–µ)
                        elif rule_type == "float_or_empty":
                            if value == "":
                                continue  # –¥–æ–∑–≤–æ–ª—è—î–º–æ –ø—É—Å—Ç–µ –ø–æ–ª–µ

                            # –î–æ–∑–≤–æ–ª—è—î–º–æ —î–≤—Ä–æ–ø–µ–π—Å—å–∫–∏–π —Ñ–æ—Ä–º–∞—Ç –∑ –∫–æ–º–æ—é ‚Äî –∑–∞–º—ñ–Ω—é—î–º–æ –Ω–∞ –∫—Ä–∞–ø–∫—É
                            normalized_value = value.replace(",", ".")
                            try:
                                float(normalized_value)
                            except ValueError:
                                logging.error(
                                    f"‚ùå –†—è–¥–æ–∫ {row_number}, –∫–æ–ª–æ–Ω–∫–∞ '{col_name}': –æ—á—ñ–∫—É—î—Ç—å—Å—è —á–∏—Å–ª–æ (float) –∞–±–æ –ø–æ—Ä–æ–∂–Ω—î –ø–æ–ª–µ, "
                                    f"–∞–ª–µ –æ—Ç—Ä–∏–º–∞–Ω–æ '{value}'."
                                )
                                return False
                                    
                    except (ValueError, IndexError):
                        logging.error(f"‚ùå –ù–µ–ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –≤ —Ä—è–¥–∫—É {row_number}. –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∑—É–ø–∏–Ω–µ–Ω–∞.")
                        return False

    except Exception as e:
        logging.error(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –Ω–µ–≤—ñ–¥–æ–º–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å —á–∏—Ç–∞–Ω–Ω—è CSV: {e}", exc_info=True)
        return False
        
    logging.info(f"‚úÖ –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ñ–∞–π–ª—É –ø—Ä–æ–π—à–ª–∞ —É—Å–ø—ñ—à–Ω–æ.")
    return True

def get_config_path(filename):
    """–ü–æ–≤–µ—Ä—Ç–∞—î –ø–æ–≤–Ω–∏–π —à–ª—è—Ö –¥–æ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó."""
    # –ü—Ä–∏–ø—É—Å–∫–∞—î–º–æ, —â–æ config –∑–Ω–∞—Ö–æ–¥–∏—Ç—å—Å—è –Ω–∞ –æ–¥–∏–Ω —Ä—ñ–≤–µ–Ω—å –≤–∏—â–µ –≤—ñ–¥ scr
    current_dir = os.path.dirname(os.path.abspath(__file__))
    config_dir = os.path.abspath(os.path.join(current_dir, '..', 'config'))
    return os.path.join(config_dir, filename)



def load_attributes_csv():
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –ø—Ä–∞–≤–∏–ª–∞ –∑–∞–º—ñ–Ω–∏ –∞—Ç—Ä–∏–±—É—Ç—ñ–≤ –∑ attribute.csv (–≥—ñ–±—Ä–∏–¥–Ω–∞ –±–ª–æ—á–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞).
    –ü–æ–≤–µ—Ä—Ç–∞—î:
    1. replacements_map: –°–ª–æ–≤–Ω–∏–∫ {col_index: {original_value: new_value}} –¥–ª—è —à–≤–∏–¥–∫–æ–≥–æ –ø–æ—à—É–∫—É.
    2. raw_data: –°–ø–∏—Å–æ–∫ —Å–∏—Ä–∏—Ö —Ä—è–¥–∫—ñ–≤ –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ —Ñ–∞–π–ª—É.
    """
    attribute_path = get_config_path('attribute.csv')
    replacements_map = {}
    raw_data = []          
    
    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
    default_header = ["column_number", "attr_site_name", "atr_a", "atr_b", "atr_c", "atr_d", "atr_e", "atr_f", "atr_g", "atr_h", "atr_i"]
    current_col_index = None # –í—ñ–¥—Å—Ç–µ–∂—É—î–º–æ –ø–æ—Ç–æ—á–Ω–∏–π –±–ª–æ–∫

    try:
        with open(attribute_path, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            
            try:
                header = next(reader)
                raw_data.append(header)
                max_row_len = len(header)
            except StopIteration:
                return {}, [default_header]

            for row in reader:
                # –ù–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ –¥–æ–≤–∂–∏–Ω—É —Ä—è–¥–∫–∞
                row = row[:max_row_len] + [''] * (max_row_len - len(row))
                raw_data.append(row)
                
                # 1. –Ø–∫—â–æ —Ü–µ —Ä—è–¥–æ–∫-–∑–∞–≥–æ–ª–æ–≤–æ–∫ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, "27",,,,,)
                if row and row[0].strip().isdigit():
                    try:
                        current_col_index = int(row[0].strip())
                        if current_col_index not in replacements_map:
                            replacements_map[current_col_index] = {}
                    except ValueError:
                        current_col_index = None
                        continue
                
                # 2. –Ø–∫—â–æ —Ü–µ —Ä—è–¥–æ–∫-–ø—Ä–∞–≤–∏–ª–æ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, ,,,—á–æ—Ä–Ω–∏–π,,)
                elif current_col_index is not None and len(row) >= 3:
                    
                    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–æ–≤–∞–Ω–µ –∑–Ω–∞—á–µ–Ω–Ω—è –∑–Ω–∞—Ö–æ–¥–∏—Ç—å—Å—è –≤ –∫–æ–ª–æ–Ω—Ü—ñ 1 (attr_site_name)
                    new_value = row[1].strip() 
                    
                    # –ü–µ—Ä–µ–≥–ª—è–¥–∞—î–º–æ –≤—Å—ñ –∑–Ω–∞—á–µ–Ω–Ω—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫—ñ–≤ (–ø–æ—á–∏–Ω–∞—é—á–∏ –∑ —ñ–Ω–¥–µ–∫—Å—É 2)
                    for original in row[2:]:
                        original = original.strip().lower()
                        if original:
                            # –ö–ª—é—á - –æ—Ä–∏–≥—ñ–Ω–∞–ª (lower), –ó–Ω–∞—á–µ–Ω–Ω—è - –∑–∞–º—ñ–Ω–∞ (–∑ attr_site_name)
                            replacements_map[current_col_index][original] = new_value

        return replacements_map, raw_data
    
    except FileNotFoundError:
        logging.warning(f"–§–∞–π–ª –∞—Ç—Ä–∏–±—É—Ç—ñ–≤ 'attribute.csv' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ. –ë—É–¥–µ —Å—Ç–≤–æ—Ä–µ–Ω–æ –Ω–æ–≤–∏–π.")
        return {}, [default_header]
    except Exception as e:
        logging.error(f"–í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ attribute.csv: {e}")
        return {}, [default_header]

def save_attributes_csv(raw_data):
    """
    –ó–±–µ—Ä—ñ–≥–∞—î –æ–Ω–æ–≤–ª–µ–Ω—ñ —Å–∏—Ä—ñ –¥–∞–Ω—ñ —É attribute.csv.
    """
    attribute_path = get_config_path('attribute.csv')
    try:
        # 'newline=''' –≤–∞–∂–ª–∏–≤–∏–π –¥–ª—è –∫–æ—Ä–µ–∫—Ç–Ω–æ–≥–æ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è CSV –Ω–∞ —Ä—ñ–∑–Ω–∏—Ö –û–°
        with open(attribute_path, 'w', encoding='utf-8', newline='') as f:
            writer = csv.writer(f)
            writer.writerows(raw_data)
        logging.info("–§–∞–π–ª –∞—Ç—Ä–∏–±—É—Ç—ñ–≤ attribute.csv –æ–Ω–æ–≤–ª–µ–Ω–æ.")
    except Exception as e:
        logging.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—ñ —Ñ–∞–π–ª—É –∞—Ç—Ä–∏–±—É—Ç—ñ–≤ attribute.csv: {e}")



def load_category_csv():
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –ø—Ä–∞–≤–∏–ª–∞ –∑–∞–º—ñ–Ω–∏ –∫–∞—Ç–µ–≥–æ—Ä—ñ–π –∑ category.csv.
    –ü–æ–≤–µ—Ä—Ç–∞—î:
    1. category_map: –°–ª–æ–≤–Ω–∏–∫ {supplier_id: {(name1, name2, name3): category_value}}
    2. raw_data: –°–ø–∏—Å–æ–∫ —Å–∏—Ä–∏—Ö —Ä—è–¥–∫—ñ–≤ –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ —Ñ–∞–π–ª—É.
    """
    category_path = get_config_path('category.csv')
    category_map = {}
    raw_data = []          
    
    default_header = ["postachalnyk", "name_1", "name_2", "name_3", "category"]
    current_supplier_id = None

    try:
        with open(category_path, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            
            try:
                header = next(reader)
                raw_data.append(header)
                max_row_len = len(header)
            except StopIteration:
                return {}, [default_header]

            for row in reader:
                row = row[:max_row_len] + [''] * (max_row_len - len(row))
                raw_data.append(row)
                
                # 1. –Ø–∫—â–æ —Ü–µ —Ä—è–¥–æ–∫-–∑–∞–≥–æ–ª–æ–≤–æ–∫ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, "1",,,,)
                if row and row[0].strip().isdigit():
                    try:
                        current_supplier_id = int(row[0].strip())
                        if current_supplier_id not in category_map:
                            category_map[current_supplier_id] = {}
                    except ValueError:
                        current_supplier_id = None
                        continue
                
                # 2. –Ø–∫—â–æ —Ü–µ —Ä—è–¥–æ–∫-–ø—Ä–∞–≤–∏–ª–æ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, ,"–õ—è–ª—å–∫–∏","–ö—É–∫–ª–∏","–ù–∞–¥—É–≤–Ω—ñ","–ù–∞–¥—É–≤–Ω—ñ –ª—è–ª—å–∫–∏")
                elif current_supplier_id is not None and len(row) >= 5:
                    
                    # –ö–ª—é—á—ñ –¥–ª—è –º–∞–ø–∏: (name_1, name_2, name_3) - –≤—Å—ñ –≤ –Ω–∏–∂–Ω—å–æ–º—É —Ä–µ–≥—ñ—Å—Ç—Ä—ñ
                    key_tuple = (
                        row[1].strip().lower(), 
                        row[2].strip().lower(), 
                        row[3].strip().lower()
                    )
                    
                    # –ó–Ω–∞—á–µ–Ω–Ω—è: category (–±–µ–∑ –∑–º—ñ–Ω–∏ —Ä–µ–≥—ñ—Å—Ç—Ä—É)
                    category_value = row[4].strip()
                    
                    category_map[current_supplier_id][key_tuple] = category_value

        return category_map, raw_data
    
    except FileNotFoundError:
        logging.warning(f"–§–∞–π–ª –∫–∞—Ç–µ–≥–æ—Ä—ñ–π 'category.csv' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ. –ë—É–¥–µ —Å—Ç–≤–æ—Ä–µ–Ω–æ –Ω–æ–≤–∏–π.")
        return {}, [default_header]
    except Exception as e:
        logging.error(f"–í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ category.csv: {e}")
        return {}, [default_header]

def save_category_csv(raw_data):
    """
    –ó–±–µ—Ä—ñ–≥–∞—î –æ–Ω–æ–≤–ª–µ–Ω—ñ —Å–∏—Ä—ñ –¥–∞–Ω—ñ —É category.csv.
    """
    category_path = get_config_path('category.csv')
    try:
        with open(category_path, 'w', encoding='utf-8', newline='') as f:
            writer = csv.writer(f)
            writer.writerows(raw_data)
        logging.info("–§–∞–π–ª –∫–∞—Ç–µ–≥–æ—Ä—ñ–π category.csv –æ–Ω–æ–≤–ª–µ–Ω–æ.")
    except Exception as e:
        logging.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—ñ —Ñ–∞–π–ª—É –∫–∞—Ç–µ–≥–æ—Ä—ñ–π category.csv: {e}")

def load_poznachky_csv():
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î —Å—Ç–∞—Ç–∏—á–Ω–∏–π —Å–ø–∏—Å–æ–∫ –ø–æ–∑–Ω–∞—á–æ–∫ –∑ poznachky.csv.
    –ü–æ–≤–µ—Ä—Ç–∞—î:
    1. poznachky_list: –°–ø–∏—Å–æ–∫ —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö –ø–æ–∑–Ω–∞—á–æ–∫ (—É –Ω–∏–∂–Ω—å–æ–º—É —Ä–µ–≥—ñ—Å—Ç—Ä—ñ).
    """
    poznachky_path = get_config_path('poznachky.csv')
    poznachky_list = []
    
    try:
        with open(poznachky_path, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            
            try:
                # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫ "Poznachky"
                next(reader) 
            except StopIteration:
                return []

            for row in reader:
                if row and row[0].strip():
                    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –ø–æ–∑–Ω–∞—á–∫–∏ —É –Ω–∏–∂–Ω—å–æ–º—É —Ä–µ–≥—ñ—Å—Ç—Ä—ñ –¥–ª—è —É–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–æ–≥–æ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è
                    poznachky_list.append(row[0].strip().lower())

        # –°–æ—Ä—Ç—É—î–º–æ –≤—ñ–¥ –Ω–∞–π–¥–æ–≤—à–∏—Ö –¥–æ –Ω–∞–π–∫–æ—Ä–æ—Ç—à–∏—Ö, —â–æ–± –∑–Ω–∞–π—Ç–∏ –Ω–∞–π–∫—Ä–∞—â–µ —Å–ø—ñ–≤–ø–∞–¥—ñ–Ω–Ω—è
        poznachky_list.sort(key=len, reverse=True)
        
        return poznachky_list
    
    except FileNotFoundError:
        logging.warning(f"–§–∞–π–ª –ø–æ–∑–Ω–∞—á–æ–∫ 'poznachky.csv' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return []
    except Exception as e:
        logging.error(f"–í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ poznachky.csv: {e}")
        return []



def clear_directory(folder_path: str):
    """–û—á–∏—â–∞—î –∞–±–æ —Å—Ç–≤–æ—Ä—é—î –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—é."""
    if not os.path.exists(folder_path):
        os.makedirs(folder_path, exist_ok=True)
        return
    for item in os.listdir(folder_path):
        path = os.path.join(folder_path, item)
        try:
            if os.path.isfile(path) or os.path.islink(path):
                os.unlink(path)
            elif os.path.isdir(path):
                shutil.rmtree(path)
        except Exception as e:
            logging.error(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –≤–∏–¥–∞–ª–∏—Ç–∏ {path}: {e}")

def move_gifs(src: str, dest: str) -> int:
    """–ü–µ—Ä–µ–º—ñ—â—É—î –≤—Å—ñ GIF —ñ–∑ src —É dest."""
    moved = 0
    os.makedirs(dest, exist_ok=True)
    for root, _, files in os.walk(src):
        for f in files:
            if f.lower().endswith('.gif'):
                src_path = os.path.join(root, f)
                rel = os.path.relpath(src_path, src)
                dest_path = os.path.join(dest, rel)
                os.makedirs(os.path.dirname(dest_path), exist_ok=True)
                shutil.move(src_path, dest_path)
                moved += 1
    logging.info(f"üü£ –ü–µ—Ä–µ–º—ñ—â–µ–Ω–æ {moved} GIF-—Ñ–∞–π–ª—ñ–≤.")
    return moved

def convert_to_webp_square(src: str, dest: str) -> int:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç—É—î JPG/PNG ‚Üí WEBP, –≤–∏—Ä—ñ–≤–Ω—é—î –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –¥–æ –∫–≤–∞–¥—Ä–∞—Ç—É
    —Ç–∞ –∫–æ—Ä–µ–∫—Ç–Ω–æ –æ–±—Ä–æ–±–ª—è—î –ø—Ä–æ–∑–æ—Ä—ñ—Å—Ç—å (RGBA / –ø–∞–ª—ñ—Ç—Ä–æ–≤—ñ P-–∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è).
    """
    import os
    import logging
    from PIL import Image

    converted = 0

    for root, _, files in os.walk(src):
        rel = os.path.relpath(root, src)
        out_dir = os.path.join(dest, rel)
        os.makedirs(out_dir, exist_ok=True)

        for f in files:
            if not f.lower().endswith(('.jpg', '.jpeg', '.png', '.webp')):
                continue

            try:
                img_path = os.path.join(root, f)
                img = Image.open(img_path)

                # üîπ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –∫–æ–ª—å–æ—Ä–æ–≤–æ–≥–æ —Ä–µ–∂–∏–º—É (–¥–ª—è —É–Ω–∏–∫–Ω–µ–Ω–Ω—è warning)
                if img.mode == "P":
                    img = img.convert("RGBA")
                elif img.mode not in ("RGB", "RGBA"):
                    img = img.convert("RGB")

                w, h = img.size
                max_side = max(w, h)

                # üîπ –Ø–∫—â–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –º–∞—î –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª ‚Äî —Å—Ç–≤–æ—Ä—é—î–º–æ –ø—Ä–æ–∑–æ—Ä–µ –ø–æ–ª–æ—Ç–Ω–æ
                if img.mode == "RGBA":
                    canvas = Image.new("RGBA", (max_side, max_side), (255, 255, 255, 0))
                else:
                    canvas = Image.new("RGB", (max_side, max_side), (255, 255, 255))

                # –¶–µ–Ω—Ç—Ä—É–≤–∞–Ω–Ω—è
                canvas.paste(img, ((max_side - w) // 2, (max_side - h) // 2))

                # üîπ –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —É —Ñ–æ—Ä–º–∞—Ç—ñ WEBP
                new_name = os.path.splitext(f)[0] + '.webp'
                out_path = os.path.join(out_dir, new_name)
                canvas.save(out_path, 'webp', quality=90)

                converted += 1

            except Exception as e:
                logging.error(f"‚ùå WEBP-–∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è '{f}' –Ω–µ –≤–¥–∞–ª–∞—Å—è: {e}")

    logging.info(f"üü¢ WEBP-–∫–æ–Ω–≤–µ—Ä—Ç–æ–≤–∞–Ω–æ {converted} –∑–æ–±—Ä–∞–∂–µ–Ω—å.")
    return converted

def download_product_images(url: str, sku: str, category: str, base_path: str, cat_map: Dict[str, str]) -> List[str]:
    """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –≤—Å—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Ç–æ–≤–∞—Ä—É –∑ URL."""
    cat_slug = cat_map.get(category.strip()) or category.strip().lower().replace(' ', '_').replace(',', '')
    dest = os.path.join(base_path, cat_slug)
    os.makedirs(dest, exist_ok=True)

    try:
        page = requests.get(url, timeout=10)
        page.raise_for_status()
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Å—Ç–æ—Ä—ñ–Ω–∫—É {url}: {e}")
        return []

    soup = BeautifulSoup(page.content, 'html.parser')
    links = {a.get('href') for a in soup.find_all('a', class_='thumb_image_container') if a.get('href')}
    files = []

    for i, img_url in enumerate(links, 1):
        try:
            r = requests.get(img_url, timeout=10)
            r.raise_for_status()
            mime = r.headers.get('Content-Type')
            ext = mimetypes.guess_extension(mime) or '.jpg'
            fname = f"{sku}-{i}{ext}"
            with open(os.path.join(dest, fname), 'wb') as f:
                f.write(r.content)
            files.append(fname)
        except Exception:
            continue

    # üü¢ –õ–æ–≥—É–≤–∞–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É
    logging.info(f"üì∏ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(files)} –∑–æ–±—Ä–∞–∂–µ–Ω—å –¥–ª—è SKU {sku}: {', '.join(files)}")

    return files

def sync_webp_column(sl_path: str, webp_path: str, col_index: int, sku_index: int) -> int:
    """–û–Ω–æ–≤–ª—é—î –∫–æ–ª–æ–Ω–∫—É WEBP/GIF-—Å–ø–∏—Å–∫—ñ–≤ —É CSV."""
    with open(sl_path, 'r', encoding='utf-8') as f:
        reader = list(csv.reader(f))
    if not reader:
        return 0

    header, *rows = reader
    sku_map = {}
    for root, _, files in os.walk(webp_path):
        for f in files:
            if '-' in f and f.lower().endswith(('.webp', '.gif')):
                sku = f.split('-')[0]
                sku_map.setdefault(sku, []).append(f)

    updated = 0
    for row in rows:
        if len(row) <= max(col_index, sku_index):
            row.extend([''] * (max(col_index, sku_index) + 1 - len(row)))
        sku = row[sku_index].strip()
        if sku in sku_map:
            row[col_index] = ', '.join(sorted(sku_map[sku]))
            updated += 1
    with open(sl_path, 'w', encoding='utf-8', newline='') as f:
        csv.writer(f).writerows([header] + rows)
    logging.info(f"üîÅ –û–Ω–æ–≤–ª–µ–Ω–æ {updated} SKU —É –∫–æ–ª–æ–Ω—Ü—ñ WEBP.")
    return updated

def copy_to_site(src: str, dest: str):
    """–ö–æ–ø—ñ—é—î WEBP/GIF –¥–æ —Ñ—ñ–Ω–∞–ª—å–Ω–æ—ó –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó –∑ –ø—Ä–∞–≤–∞–º–∏."""
    uid, gid = 33, 33
    fperm, dperm = 0o644, 0o755
    copied = 0

    for root, _, files in os.walk(src):
        rel = os.path.relpath(root, src)
        out_dir = os.path.join(dest, rel)
        os.makedirs(out_dir, mode=dperm, exist_ok=True)
        for f in files:
            if not f.lower().endswith(('.webp', '.gif')):
                continue
            src_f = os.path.join(root, f)
            dst_f = os.path.join(out_dir, f)
            shutil.copy2(src_f, dst_f)
            try:
                os.chown(dst_f, uid, gid)
                os.chmod(dst_f, fperm)
                copied += 1
            except PermissionError:
                logging.warning(f"‚ö†Ô∏è –ù–µ–º–∞—î –ø—Ä–∞–≤ –¥–ª—è –∑–º—ñ–Ω–∏ –≤–ª–∞—Å–Ω–∏–∫–∞ {dst_f}")
    logging.info(f"üì¶ –°–∫–æ–ø—ñ–π–æ–≤–∞–Ω–æ {copied} —Ñ–∞–π–ª—ñ–≤ —É {dest}.")
    return copied








def _process_batch_update(wcapi: Any, batch_data: List[Dict[str, Any]], errors_list: List[str]) -> int:
    """–í–∏–∫–æ–Ω—É—î –ø–∞–∫–µ—Ç–Ω–∏–π –∑–∞–ø–∏—Ç 'update' –¥–æ WooCommerce API."""
    
    payload = {"update": batch_data}
    
    try:
        logging.info(f"–ù–∞–¥—Å–∏–ª–∞—é –ø–∞–∫–µ—Ç –Ω–∞ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è ({len(batch_data)} —Ç–æ–≤–∞—Ä—ñ–≤)...")
        
        response = wcapi.post("products/batch", data=payload) 
        
        if response.status_code == 200:
            result = response.json()
            updated_count = len(result.get('update', []))
            
            # –î–µ—Ç–∞–ª—å–Ω–µ –ª–æ–≥—É–≤–∞–Ω–Ω—è –ø–æ–º–∏–ª–æ–∫, —è–∫—ñ –ø–æ–≤–µ—Ä–Ω—É–≤ API
            api_errors = result.get('errors', [])
            if api_errors:
                for err in api_errors:
                    err_msg = f"API-–ü–æ–º–∏–ª–∫–∞ (ID: {err.get('id', 'N/A')}): {err.get('message', '–ù–µ–≤—ñ–¥–æ–º–∞ –ø–æ–º–∏–ª–∫–∞')}"
                    errors_list.append(err_msg)
                    logging.error(err_msg)
                
            logging.info(f"‚úÖ –ü–∞–∫–µ—Ç –æ–Ω–æ–≤–ª–µ–Ω–æ. –£—Å–ø—ñ—à–Ω–æ –æ–±—Ä–æ–±–ª–µ–Ω–æ API: {updated_count} —Ç–æ–≤–∞—Ä—ñ–≤. –ü–æ–º–∏–ª–æ–∫ —É –ø–∞–∫–µ—Ç—ñ: {len(api_errors)}")
            return updated_count
        else:
            err_msg = f"‚ùå –ö—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞ API ({response.status_code}) –ø—Ä–∏ –ø–∞–∫–µ—Ç–Ω–æ–º—É –æ–Ω–æ–≤–ª–µ–Ω–Ω—ñ. –ü–æ–º–∏–ª–∫–∞: {response.text[:200]}..."
            errors_list.append(err_msg)
            logging.critical(err_msg)
            return 0
            
    except Exception as e:
        err_msg = f"‚ùå –ù–µ–ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –≤—ñ–¥–ø—Ä–∞–≤–∫–∏ –ø–∞–∫–µ—Ç—É: {e}"
        errors_list.append(err_msg)
        logging.critical(err_msg, exc_info=True)
        return 0
    

def find_media_ids_for_sku(wcapi, sku: str, uploads_path: str) -> List[Dict[str, Any]]:
    """
    –ó–Ω–∞—Ö–æ–¥–∏—Ç—å —É—Å—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –¥–ª—è SKU —É uploads_path —Ç–∞ –ø–æ–≤–µ—Ä—Ç–∞—î —Å–ø–∏—Å–æ–∫ ID –¥–ª—è WooCommerce.
    –ü—ñ–¥—Ç—Ä–∏–º—É—î —Ä—ñ–∑–Ω—ñ —Ä–æ–∑—à–∏—Ä–µ–Ω–Ω—è —Ç–∞ –ø—ñ–¥–ø–∞–ø–∫–∏.
    """
    def _get_media_id_by_filename(filename: str) -> int | None:
        """–í–Ω—É—Ç—Ä—ñ—à–Ω—è —Ñ—É–Ω–∫—Ü—ñ—è: —à—É–∫–∞—î ID –º–µ–¥—ñ–∞ –∑–∞ slug –∞–±–æ title"""
        import requests

        file_slug = os.path.splitext(filename)[0]

        # –ü–æ—à—É–∫ –∑–∞ slug
        try:
            response = wcapi.get("media", params={'search': file_slug, 'per_page': 1, 'orderby': 'slug'})
            if response.status_code == 200:
                items = response.json()
                if items:
                    item = items[0]
                    if item.get('slug') == file_slug or item.get('title', {}).get('rendered') == filename:
                        return item['id']
        except Exception as e:
            logging.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –ø–æ—à—É–∫—É –º–µ–¥—ñ–∞ ID –¥–ª—è {filename} (slug): {e}")

        # –ü–æ—à—É–∫ –∑–∞ —Ç–æ—á–Ω–∏–º title
        try:
            response = wcapi.get("media", params={'search': filename, 'per_page': 1, 'orderby': 'title'})
            if response.status_code == 200:
                items = response.json()
                if items:
                    item = items[0]
                    if item.get('title', {}).get('rendered') == filename:
                        return item['id']
        except Exception as e:
            logging.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –ø–æ—à—É–∫—É –º–µ–¥—ñ–∞ ID –¥–ª—è {filename} (title): {e}")

        logging.warning(f"‚ö†Ô∏è –ú–µ–¥—ñ–∞ ID –¥–ª—è —Ñ–∞–π–ª—É '{filename}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return None

    media_ids = []
    pattern = os.path.join(uploads_path, '**', f'{sku}*.*')
    files = glob.glob(pattern, recursive=True)
    for file_path in files:
        filename = os.path.basename(file_path)
        media_id = _get_media_id_by_filename(filename)
        if media_id:
            media_ids.append({"id": media_id})

    if not media_ids:
        logging.warning(f"‚ö†Ô∏è SKU {sku}: –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∑–æ–±—Ä–∞–∂–µ–Ω—å —É '{uploads_path}'")
    return media_ids



# --- –î–û–ü–û–ú–Ü–ñ–ù–ê –§–£–ù–ö–¶–Ü–Ø –î–õ–Ø –ü–ê–ö–ï–¢–ù–û–ì–û –ó–ê–ü–ò–°–£ (–°—Ç–≤–æ—Ä–µ–Ω–Ω—è) (–±–µ–∑ –∑–º—ñ–Ω) ---
def _process_batch_create(wcapi: Any, batch_data: List[Dict[str, Any]], errors_list: List[str]) -> int:
    """–í–∏–∫–æ–Ω—É—î –ø–∞–∫–µ—Ç–Ω–∏–π –∑–∞–ø–∏—Ç 'create' –¥–æ WooCommerce API."""
    
    payload = {"create": batch_data}
    
    try:
        logging.info(f"–ù–∞–¥—Å–∏–ª–∞—é –ø–∞–∫–µ—Ç –Ω–∞ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è ({len(batch_data)} —Ç–æ–≤–∞—Ä—ñ–≤)...")
        response = wcapi.post("products/batch", data=payload) 
        
        if response.status_code == 200:
            result = response.json()
            created_count = len(result.get('create', []))
            
            api_errors = result.get('errors', [])
            if api_errors:
                for err in api_errors:
                    err_msg = f"API-–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—ñ: SKU '{err.get('data', {}).get('resource_id', 'N/A')}', Code: {err.get('code', 'N/A')}: {err.get('message', '–ù–µ–≤—ñ–¥–æ–º–∞ –ø–æ–º–∏–ª–∫–∞')}"
                    errors_list.append(err_msg)
                    logging.error(err_msg)
                
            logging.info(f"‚úÖ –ü–∞–∫–µ—Ç —Å—Ç–≤–æ—Ä–µ–Ω–æ. –£—Å–ø—ñ—à–Ω–æ –æ–±—Ä–æ–±–ª–µ–Ω–æ API: {created_count} —Ç–æ–≤–∞—Ä—ñ–≤. –ü–æ–º–∏–ª–æ–∫ —É –ø–∞–∫–µ—Ç—ñ: {len(api_errors)}")
            return created_count
        else:
            err_msg = f"‚ùå –ö—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞ API ({response.status_code}) –ø—Ä–∏ –ø–∞–∫–µ—Ç–Ω–æ–º—É —Å—Ç–≤–æ—Ä–µ–Ω–Ω—ñ. –ü–æ–º–∏–ª–∫–∞: {response.text[:200]}..."
            errors_list.append(err_msg)
            logging.critical(err_msg)
            return 0
            
    except Exception as e:
        err_msg = f"‚ùå –ù–µ–ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –≤—ñ–¥–ø—Ä–∞–≤–∫–∏ –ø–∞–∫–µ—Ç—É: {e}"
        errors_list.append(err_msg)
        logging.critical(err_msg, exc_info=True)
        return 0
    

def _clean_text(value: str) -> str:
    """–û—á–∏—â—É—î HTML-—Ç–µ–≥–∏, –∫–æ–¥—É–≤–∞–Ω–Ω—è —ñ –∑–∞–π–≤—ñ –ø—Ä–æ–±—ñ–ª–∏."""
    if not value:
        return ""
    value = html.unescape(str(value))  # —Ä–æ–∑–∫–æ–¥–æ–≤—É—î &#8211; ‚Üí ‚Äì
    value = re.sub(r"<.*?>", "", value)  # –≤–∏–¥–∞–ª—è—î HTML-—Ç–µ–≥–∏
    return value.strip()

def export_product_by_id():
    """
    –ï–∫—Å–ø–æ—Ä—Ç—É—î –≤—Å—ñ –¥–∞–Ω—ñ —Ç–æ–≤–∞—Ä—É –∑–∞ –≤–≤–µ–¥–µ–Ω–∏–º ID —É /csv/input/ID_tovar.csv.
    –í–∏–ø—Ä–∞–≤–ª–µ–Ω–æ HTML-–∫–æ–¥—É–≤–∞–Ω–Ω—è, –µ–∫—Ä–∞–Ω—É–≤–∞–Ω–Ω—è CSV —ñ –¥–æ–¥–∞–Ω–æ –ø–µ—Ä–µ–∫–ª–∞–¥–∏ WPML.
    """
    log_message_to_existing_file()
    settings = load_settings()
    if not settings:
        logging.error("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è.")
        return

    wcapi = get_wc_api(settings)
    if not wcapi:
        logging.error("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è —Å—Ç–≤–æ—Ä–∏—Ç–∏ –æ–±'—î–∫—Ç WooCommerce API.")
        return

    product_id = input("–í–≤–µ–¥—ñ—Ç—å ID —Ç–æ–≤–∞—Ä—É –¥–ª—è –µ–∫—Å–ø–æ—Ä—Ç—É: ").strip()
    if not product_id.isdigit():
        logging.error("‚ùå –ù–µ–∫–æ—Ä–µ–∫—Ç–Ω–∏–π ID —Ç–æ–≤–∞—Ä—É.")
        return
    product_id = int(product_id)

    output_dir = "/var/www/scripts/update/csv/input"
    os.makedirs(output_dir, exist_ok=True)
    csv_path = os.path.join(output_dir, "ID_tovar.csv")

    start_time = time.time()
    try:
        # === –û—Å–Ω–æ–≤–Ω—ñ –¥–∞–Ω—ñ —Ç–æ–≤–∞—Ä—É ===
        response = wcapi.get(f"products/{product_id}", params={"context": "edit"})
        if response.status_code != 200:
            logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ {response.status_code}: {response.text}")
            return
        product = response.json()
        if not isinstance(product, dict):
            logging.error(f"‚ùå –ù–µ–∫–æ—Ä–µ–∫—Ç–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ API –¥–ª—è —Ç–æ–≤–∞—Ä—É ID {product_id}")
            return

        row = {"id": product_id}

        # === –û—Å–Ω–æ–≤–Ω—ñ –ø–æ–ª—è ===
        for key, value in product.items():
            if isinstance(value, dict):
                for subkey, subval in value.items():
                    row[f"{key}.{subkey}"] = _clean_text(subval)
            elif isinstance(value, list):
                if key == "meta_data":
                    for meta in value:
                        k = meta.get("key")
                        v = meta.get("value")
                        if k:
                            row[f"–ú–µ—Ç–∞: {k}"] = _clean_text(v)
                elif key == "categories":
                    row["categories"] = ", ".join([_clean_text(v.get("name", "")) for v in value])
                elif key == "tags":
                    row["tags"] = ", ".join([_clean_text(v.get("name", "")) for v in value])
                elif key == "images":
                    for idx, img in enumerate(value, start=1):
                        row[f"image_{idx}_id"] = img.get("id", "")
                        row[f"image_{idx}_src"] = img.get("src", "")
                        row[f"image_{idx}_name"] = _clean_text(img.get("name", ""))
                        row[f"image_{idx}_alt"] = _clean_text(img.get("alt", ""))
                        row[f"image_{idx}_title"] = _clean_text(img.get("title", ""))
                        row[f"image_{idx}_caption"] = _clean_text(img.get("caption", ""))
                        row[f"image_{idx}_description"] = _clean_text(img.get("description", ""))
                else:
                    row[key] = ", ".join(map(_clean_text, map(str, value)))
            else:
                row[key] = _clean_text(value)

        # === –ü–µ—Ä–µ–∫–ª–∞–¥–∏ WPML ===
        try:
            wpml_resp = wcapi.get(f"products/{product_id}/translations")
            if wpml_resp.status_code == 200:
                translations = wpml_resp.json()
                for lang, tr in translations.items():
                    if isinstance(tr, dict):
                        row[f"wpml_{lang}_id"] = tr.get("id", "")
                        row[f"wpml_{lang}_name"] = _clean_text(tr.get("name", ""))
                        row[f"wpml_{lang}_slug"] = tr.get("slug", "")
                        row[f"wpml_{lang}_status"] = tr.get("status", "")
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è –ù–µ–º–æ–∂–ª–∏–≤–æ –æ—Ç—Ä–∏–º–∞—Ç–∏ WPML –ø–µ—Ä–µ–∫–ª–∞–¥–∏: {e}")

        # === –ó–∞–ø–∏—Å —É CSV ===
        file_exists = os.path.exists(csv_path)
        file_is_empty = not file_exists or os.path.getsize(csv_path) == 0

        with open(csv_path, "a", newline="", encoding="utf-8") as f:
            writer = csv.DictWriter(f, fieldnames=row.keys(), quoting=csv.QUOTE_ALL)
            if file_is_empty:
                writer.writeheader()
            writer.writerow(row)

        elapsed = int(time.time() - start_time)
        logging.info(f"‚úÖ –ï–∫—Å–ø–æ—Ä—Ç–æ–≤–∞–Ω–æ —Ç–æ–≤–∞—Ä ID {product_id} ({len(row)} –ø–æ–ª—ñ–≤) ‚Üí {csv_path} –∑–∞ {elapsed} —Å–µ–∫.")

    except Exception as e:
        logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –µ–∫—Å–ø–æ—Ä—Ç—É: {e}", exc_info=True)