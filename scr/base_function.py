from woocommerce import API
import json
import os, csv, shutil, logging, requests, mimetypes, glob
import logging
import html
import re
from datetime import datetime
from typing import Dict, Tuple, List, Optional, Any
from PIL import Image
from bs4 import BeautifulSoup
import time


def load_settings():
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó –∑ settings.json
    """
    config_path = os.path.join(os.path.dirname(__file__), "..", "config", "settings.json")
    try:
        with open(config_path, "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: —Ñ–∞–π–ª –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∑–∞ —à–ª—è—Ö–æ–º: {config_path}")
        return None
    except json.JSONDecodeError:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: —Ñ–∞–π–ª –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó –ø–æ—à–∫–æ–¥–∂–µ–Ω–∏–π: {config_path}")
        return None



def get_wc_api(settings):
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó –∑ settings.json
    """
    config_path = os.path.join(os.path.dirname(__file__), "..", "config", "settings.json")
    with open(config_path, "r", encoding="utf-8") as f:
        settings = json.load(f)

    wcapi = API(
        url=settings["url"],
        consumer_key=settings["consumer_key"],
        consumer_secret=settings["consumer_secret"],
        version="wc/v3",
        timeout=120,
        query_string_auth=True
    )
    return wcapi

def check_version():
    wcapi = get_wc_api()
    response = wcapi.get("system_status")
    if response.status_code == 200:
        data = response.json()
        print("WooCommerce version:", data.get("environment", {}).get("version"))
    else:
        print("Error:", response.status_code, response.text)



def setup_new_log_file():
    """
    –ü–µ—Ä–µ–π–º–µ–Ω–æ–≤—É—î —ñ—Å–Ω—É—é—á–∏–π –ª–æ–≥-—Ñ–∞–π–ª —Ç–∞ –Ω–∞–ª–∞—à—Ç–æ–≤—É—î –Ω–æ–≤–∏–π,
    –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—á–∏ —à–ª—è—Ö –∑ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω—å.
    """
    settings = load_settings()
    if not settings or "paths" not in settings or "main_log_file" not in settings["paths"]:
        print("‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ —à–ª—è—Ö –¥–æ –ª–æ–≥-—Ñ–∞–π–ª—É –≤ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è—Ö.")
        return

    current_log_path = os.path.join(os.path.dirname(__file__), "..", settings["paths"]["main_log_file"])
    log_dir = os.path.dirname(current_log_path)
    
    os.makedirs(log_dir, exist_ok=True)
    
    if os.path.exists(current_log_path):
        timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        file_name, file_extension = os.path.splitext(os.path.basename(current_log_path))
        new_log_path = os.path.join(log_dir, f"{file_name}_{timestamp}{file_extension}")
        try:
            os.rename(current_log_path, new_log_path)
            print(f"‚úÖ –°—Ç–∞—Ä–∏–π –ª–æ–≥-—Ñ–∞–π–ª –ø–µ—Ä–µ–π–º–µ–Ω–æ–≤–∞–Ω–æ –Ω–∞ {os.path.basename(new_log_path)}")
        except OSError as e:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–π–º–µ–Ω—É–≤–∞–Ω–Ω—ñ –ª–æ–≥-—Ñ–∞–π–ª—É: {e}")

    logging.basicConfig(
        filename=current_log_path,
        level=logging.INFO,
        format='%(asctime)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S',
        filemode='a'
    )
    logging.info("--- –ù–æ–≤–∏–π —Å–µ–∞–Ω—Å –ª–æ–≥—É–≤–∞–Ω–Ω—è —Ä–æ–∑–ø–æ—á–∞—Ç–æ ---")

def log_message_to_existing_file():
    """
    –ù–∞–ª–∞—à—Ç–æ–≤—É—î –ª–æ–≥—É–≤–∞–Ω–Ω—è –¥–ª—è –¥–æ–ø–∏—Å—É–≤–∞–Ω–Ω—è –≤ —ñ—Å–Ω—É—é—á–∏–π —Ñ–∞–π–ª,
    –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—á–∏ —à–ª—è—Ö –∑ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω—å.
    """
    settings = load_settings()
    if not settings or "paths" not in settings or "main_log_file" not in settings["paths"]:
        print("‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ —à–ª—è—Ö –¥–æ –ª–æ–≥-—Ñ–∞–π–ª—É –≤ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è—Ö.")
        return

    current_log_path = os.path.join(os.path.dirname(__file__), "..", settings["paths"]["main_log_file"])
    log_dir = os.path.dirname(current_log_path)
    
    os.makedirs(log_dir, exist_ok=True)

    if not logging.getLogger().hasHandlers():
        logging.basicConfig(
            filename=current_log_path,
            level=logging.INFO,
            format='%(asctime)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S',
            filemode='a'
        )
    logging.info("--- –ü–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –¥–æ–¥–∞–Ω–æ –¥–æ —ñ—Å–Ω—É—é—á–æ–≥–æ –ª–æ–≥—É ---")



def check_csv_data(profile_id):
    """
    –ü–µ—Ä–µ–≤—ñ—Ä—è—î CSV-—Ñ–∞–π–ª –Ω–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω—ñ—Å—Ç—å –ø—Ä–∞–≤–∏–ª–∞–º, –≤–∏–∑–Ω–∞—á–µ–Ω–∏–º —É settings.json.
    
    Args:
        profile_id (str): ID –ø—Ä–æ—Ñ—ñ–ª—é –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ –∑ 'validation_profiles' –≤ settings.json.
    
    Returns:
        bool: True, —è–∫—â–æ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ –ø—Ä–æ–π—à–ª–∞ —É—Å–ø—ñ—à–Ω–æ, —ñ–Ω–∞–∫—à–µ False.
    """
    # 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω—å
    # –¶–µ–π –±–ª–æ–∫ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î –∑–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó –∑ —Ñ–∞–π–ª—É settings.json
    # —Ç–∞ –ø–µ—Ä–µ–≤—ñ—Ä—è—î, —á–∏ —ñ—Å–Ω—É—î –≤–∫–∞–∑–∞–Ω–∏–π –ø—Ä–æ—Ñ—ñ–ª—å –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó.
    # –Ø–∫—â–æ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –∞–±–æ –ø—Ä–æ—Ñ—ñ–ª—å –≤—ñ–¥—Å—É—Ç–Ω—ñ–π, —Ñ—É–Ω–∫—Ü—ñ—è –∑–∞–≤–µ—Ä—à—É—î —Ä–æ–±–æ—Ç—É.
    
    log_message_to_existing_file()
    
    try:
        with open(os.path.join(os.path.dirname(__file__), "..", "config", "settings.json"), "r", encoding="utf-8") as f:
            settings = json.load(f)
    except (FileNotFoundError, json.JSONDecodeError) as e:
        logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó: {e}")
        return False
        
    profiles = settings.get("validation_profiles", {})
    if profile_id not in profiles:
        logging.error(f"‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –ø—Ä–æ—Ñ—ñ–ª—å –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó –∑ ID '{profile_id}' –≤ settings.json.")
        return False
    
    # 2. –û—Ç—Ä–∏–º–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö –ø—Ä–æ—Ñ—ñ–ª—é
    # –û—Ç—Ä–∏–º—É—î–º–æ —à–ª—è—Ö –¥–æ —Ñ–∞–π–ª—É —Ç–∞ –ø—Ä–∞–≤–∏–ª–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó –¥–ª—è –æ–±—Ä–∞–Ω–æ–≥–æ –ø—Ä–æ—Ñ—ñ–ª—é.
    profile = profiles[profile_id]
    csv_path_relative = profile.get("path")
    validation_rules = profile.get("rules")
    
    if not csv_path_relative or validation_rules is None:
        logging.error("‚ùå –ù–µ–ø–æ–≤–Ω—ñ –¥–∞–Ω—ñ –≤ –ø—Ä–æ—Ñ—ñ–ª—ñ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó.")
        return False
        
    # 3. –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ —Ñ–∞–π–ª—É
    # –§–æ—Ä–º—É—î–º–æ –ø–æ–≤–Ω–∏–π —à–ª—è—Ö –¥–æ —Ñ–∞–π–ª—É —Ç–∞ –ø–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –π–æ–≥–æ —ñ—Å–Ω—É–≤–∞–Ω–Ω—è –Ω–∞ –¥–∏—Å–∫—É.
    base_dir = os.path.join(os.path.dirname(__file__), "..")
    full_csv_path = os.path.join(base_dir, csv_path_relative)
    
    if not os.path.exists(full_csv_path):
        logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞: —Ñ–∞–π–ª –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return False
        
    logging.info(f"üîé –ü–æ—á–∞—Ç–æ–∫ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ —Ñ–∞–π–ª—É")
    
    # 4. –ß–∏—Ç–∞–Ω–Ω—è —Ç–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—è –¥–∞–Ω–∏—Ö
    # –í—ñ–¥–∫—Ä–∏–≤–∞—î–º–æ —Ñ–∞–π–ª —Ç–∞ –ø–æ—á–∏–Ω–∞—î–º–æ —ñ—Ç–µ—Ä–∞—Ü—ñ—é –ø–æ –π–æ–≥–æ –≤–º—ñ—Å—Ç—É.
    try:
        with open(full_csv_path, "r", encoding="utf-8") as f:
            reader = csv.reader(f)
            try:
                headers = next(reader)
            except StopIteration:
                logging.error("‚ùå –§–∞–π–ª –ø–æ—Ä–æ–∂–Ω—ñ–π. –í—ñ–¥—Å—É—Ç–Ω—ñ –∑–∞–≥–æ–ª–æ–≤–∫–∏.")
                return False
            
            # 5. –û–Ω–æ–≤–ª–µ–Ω–∞ –ª–æ–≥—ñ–∫–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ –∑–∞–≥–æ–ª–æ–≤–∫—ñ–≤
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ –≤—Å—ñ –æ—á—ñ–∫—É–≤–∞–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏ –ø—Ä–∏—Å—É—Ç–Ω—ñ —É –∑–∞–≥–æ–ª–æ–≤–∫–∞—Ö —Ñ–∞–π–ª—É
            rule_columns = list(validation_rules.keys())
            headers_set = set(headers)
            for col_name in rule_columns:
                if col_name not in headers_set:
                    logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞: –æ—á—ñ–∫—É–≤–∞–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ '{col_name}' –≤—ñ–¥—Å—É—Ç–Ω—è —É —Ñ–∞–π–ª—ñ.")
                    return False
            
            # –°—Ç–≤–æ—Ä—é—î–º–æ —Å–ª–æ–≤–Ω–∏–∫ –¥–ª—è —à–≤–∏–¥–∫–æ–≥–æ –¥–æ—Å—Ç—É–ø—É –¥–æ —ñ–Ω–¥–µ–∫—Å—ñ–≤ –∫–æ–ª–æ–Ω–æ–∫
            header_map = {name: index for index, name in enumerate(headers)}
            
            # 6. –í–∞–ª—ñ–¥–∞—Ü—ñ—è –∫–æ–∂–Ω–æ–≥–æ —Ä—è–¥–∫–∞
            for i, row in enumerate(reader):
                row_number = i + 2
                if not row or all(not col.strip() for col in row):
                    logging.info(f"‚úÖ –†—è–¥–æ–∫ {row_number} –ø–æ—Ä–æ–∂–Ω—ñ–π –∞–±–æ –º—ñ—Å—Ç–∏—Ç—å –ª–∏—à–µ –ø—Ä–æ–±—ñ–ª–∏. –ü—Ä–æ–ø—É—Å–∫–∞—é.")
                    continue
                
                # 7. –í–∞–ª—ñ–¥–∞—Ü—ñ—è –∫–æ–∂–Ω–æ–≥–æ –ø–æ–ª—è, —è–∫–µ —î –≤ –ø—Ä–∞–≤–∏–ª–∞—Ö
                for col_name, rule_type in validation_rules.items():
                    try:
                        col_index = header_map.get(col_name)
                        if col_index is None:
                            # –¶–µ –º–∞–ª–æ –±—É—Ç–∏ —Å–ø—ñ–π–º–∞–Ω–æ –Ω–∞ –µ—Ç–∞–ø—ñ 5, –∞–ª–µ —Ü–µ –¥–æ–¥–∞—Ç–∫–æ–≤–∞ –ø–µ—Ä–µ—Å—Ç—Ä–∞—Ö–æ–≤–∫–∞
                            continue
                        
                        if col_index >= len(row):
                            logging.error(f"‚ùå –†—è–¥–æ–∫ {row_number}: –†—è–¥–æ–∫ –∫–æ—Ä–æ—Ç—à–∏–π –∑–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –æ—á—ñ–∫—É–≤–∞–Ω–∏—Ö –∫–æ–ª–æ–Ω–æ–∫.")
                            return False
                        
                        value = row[col_index].strip()

                        # 7.0. –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ –æ–±–æ–≤‚Äô—è–∑–∫–æ–≤—ñ—Å—Ç—å –∑–∞–ø–æ–≤–Ω–µ–Ω–Ω—è
                        if rule_type == "not_empty":
                            if not value:
                                logging.error(f"‚ùå –†—è–¥–æ–∫ {row_number}, –∫–æ–ª–æ–Ω–∫–∞ '{col_name}': –ø–æ–ª–µ –Ω–µ –ø–æ–≤–∏–Ω–Ω–æ –±—É—Ç–∏ –ø–æ—Ä–æ–∂–Ω—ñ–º.")
                                return False
                            continue  # –Ω–µ –ø–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –¥–∞–ª—ñ
                        
                        # 7.1. –í–∞–ª—ñ–¥–∞—Ü—ñ—è —Ü—ñ–ª–∏—Ö —á–∏—Å–µ–ª
                        if rule_type == "integer":
                            if not value:
                                logging.error(f"‚ùå –†—è–¥–æ–∫ {row_number}, –∫–æ–ª–æ–Ω–∫–∞ '{col_name}': –æ—á—ñ–∫—É—î—Ç—å—Å—è —Ü—ñ–ª–µ —á–∏—Å–ª–æ, –∞–ª–µ –ø–æ–ª–µ –ø–æ—Ä–æ–∂–Ω—î.")
                                return False
                            if not value.lstrip('-').isdigit():
                                logging.error(f"‚ùå –†—è–¥–æ–∫ {row_number}, –∫–æ–ª–æ–Ω–∫–∞ '{col_name}': –æ—á—ñ–∫—É—î—Ç—å—Å—è —Ü—ñ–ª–µ —á–∏—Å–ª–æ, –∞–ª–µ –æ—Ç—Ä–∏–º–∞–Ω–æ '{value}'.")
                                return False

                        # 7.2. –í–∞–ª—ñ–¥–∞—Ü—ñ—è –∑–Ω–∞—á–µ–Ω—å –∑—ñ —Å–ø–∏—Å–∫—É
                        elif isinstance(rule_type, list):
                            if not value:
                                logging.error(f"‚ùå –†—è–¥–æ–∫ {row_number}, –∫–æ–ª–æ–Ω–∫–∞ '{col_name}': –æ—á—ñ–∫—É—î—Ç—å—Å—è –æ–¥–Ω–µ –∑—ñ –∑–Ω–∞—á–µ–Ω—å {rule_type}, –∞–ª–µ –ø–æ–ª–µ –ø–æ—Ä–æ–∂–Ω—î.")
                                return False
                            if value not in rule_type:
                                logging.error(f"‚ùå –†—è–¥–æ–∫ {row_number}, –∫–æ–ª–æ–Ω–∫–∞ '{col_name}': –æ—á—ñ–∫—É—î—Ç—å—Å—è –æ–¥–Ω–µ –∑—ñ –∑–Ω–∞—á–µ–Ω—å {rule_type}, –∞–ª–µ –æ—Ç—Ä–∏–º–∞–Ω–æ '{value}'.")
                                return False
                        
                        # 7.3. –í–∞–ª—ñ–¥–∞—Ü—ñ—è —Ñ–æ—Ä–º–∞—Ç—É –¥–∞—Ç–∏-—á–∞—Å—É
                        elif rule_type == "datetime":
                            if value:
                                try:
                                    datetime.strptime(value, "%Y-%m-%dT%H:%M:%S")
                                except ValueError:
                                    logging.error(f"‚ùå –†—è–¥–æ–∫ {row_number}, –∫–æ–ª–æ–Ω–∫–∞ '{col_name}': –Ω–µ–≤—ñ—Ä–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç–∏-—á–∞—Å—É. –û—á—ñ–∫—É—î—Ç—å—Å—è 'YYYY-MM-DDTHH:MM:SS', –∞–ª–µ –æ—Ç—Ä–∏–º–∞–Ω–æ '{value}'.")
                                    return False

                        # 7.4. –í–∞–ª—ñ–¥–∞—Ü—ñ—è —Ü—ñ–ª–∏—Ö —á–∏—Å–µ–ª (–¥–æ–ø—É—Å–∫–∞—î –ø–æ—Ä–æ–∂–Ω—î –ø–æ–ª–µ)
                        if rule_type == "integer_or_empty":
                            if value == "":
                                continue  # –ü–æ—Ä–æ–∂–Ω—î –∑–Ω–∞—á–µ–Ω–Ω—è ‚Äî –¥–æ–∑–≤–æ–ª–µ–Ω–µ
                            if not value.lstrip('-').isdigit():
                                logging.error(f"‚ùå –†—è–¥–æ–∫ {row_number}, –∫–æ–ª–æ–Ω–∫–∞ '{col_name}': –æ—á—ñ–∫—É—î—Ç—å—Å—è —Ü—ñ–ª–µ —á–∏—Å–ª–æ –∞–±–æ –ø–æ—Ä–æ–∂–Ω—î –ø–æ–ª–µ, –∞–ª–µ –æ—Ç—Ä–∏–º–∞–Ω–æ '{value}'.")
                                return False

                        # 7.5. –í–∞–ª—ñ–¥–∞—Ü—ñ—è —á–∏—Å–µ–ª –∑ –ø–ª–∞–≤–∞—é—á–æ—é –∫–æ–º–æ—é (float) (–¥–æ–ø—É—Å–∫–∞—î –ø–æ—Ä–æ–∂–Ω—î –ø–æ–ª–µ)
                        elif rule_type == "float_or_empty":
                            if value == "":
                                continue  # –¥–æ–∑–≤–æ–ª—è—î–º–æ –ø—É—Å—Ç–µ –ø–æ–ª–µ

                            # –î–æ–∑–≤–æ–ª—è—î–º–æ —î–≤—Ä–æ–ø–µ–π—Å—å–∫–∏–π —Ñ–æ—Ä–º–∞—Ç –∑ –∫–æ–º–æ—é ‚Äî –∑–∞–º—ñ–Ω—é—î–º–æ –Ω–∞ –∫—Ä–∞–ø–∫—É
                            normalized_value = value.replace(",", ".")
                            try:
                                float(normalized_value)
                            except ValueError:
                                logging.error(
                                    f"‚ùå –†—è–¥–æ–∫ {row_number}, –∫–æ–ª–æ–Ω–∫–∞ '{col_name}': –æ—á—ñ–∫—É—î—Ç—å—Å—è —á–∏—Å–ª–æ (float) –∞–±–æ –ø–æ—Ä–æ–∂–Ω—î –ø–æ–ª–µ, "
                                    f"–∞–ª–µ –æ—Ç—Ä–∏–º–∞–Ω–æ '{value}'."
                                )
                                return False
                                    
                    except (ValueError, IndexError):
                        logging.error(f"‚ùå –ù–µ–ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –≤ —Ä—è–¥–∫—É {row_number}. –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∑—É–ø–∏–Ω–µ–Ω–∞.")
                        return False

    except Exception as e:
        logging.error(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –Ω–µ–≤—ñ–¥–æ–º–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å —á–∏—Ç–∞–Ω–Ω—è CSV: {e}", exc_info=True)
        return False
        
    logging.info(f"‚úÖ –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ñ–∞–π–ª—É –ø—Ä–æ–π—à–ª–∞ —É—Å–ø—ñ—à–Ω–æ.")
    return True

def get_config_path(filename):
    """–ü–æ–≤–µ—Ä—Ç–∞—î –ø–æ–≤–Ω–∏–π —à–ª—è—Ö –¥–æ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó."""
    # –ü—Ä–∏–ø—É—Å–∫–∞—î–º–æ, —â–æ config –∑–Ω–∞—Ö–æ–¥–∏—Ç—å—Å—è –Ω–∞ –æ–¥–∏–Ω —Ä—ñ–≤–µ–Ω—å –≤–∏—â–µ –≤—ñ–¥ scr
    current_dir = os.path.dirname(os.path.abspath(__file__))
    config_dir = os.path.abspath(os.path.join(current_dir, '..', 'config'))
    return os.path.join(config_dir, filename)



def load_attributes_csv():
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –ø—Ä–∞–≤–∏–ª–∞ –∑–∞–º—ñ–Ω–∏ –∞—Ç—Ä–∏–±—É—Ç—ñ–≤ –∑ attribute.csv (–≥—ñ–±—Ä–∏–¥–Ω–∞ –±–ª–æ—á–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞).
    –ü–æ–≤–µ—Ä—Ç–∞—î:
    1. replacements_map: –°–ª–æ–≤–Ω–∏–∫ {col_index: {original_value: new_value}} –¥–ª—è —à–≤–∏–¥–∫–æ–≥–æ –ø–æ—à—É–∫—É.
    2. raw_data: –°–ø–∏—Å–æ–∫ —Å–∏—Ä–∏—Ö —Ä—è–¥–∫—ñ–≤ –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ —Ñ–∞–π–ª—É.
    """
    attribute_path = get_config_path('attribute.csv')
    replacements_map = {}
    raw_data = []          
    
    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫
    default_header = ["column_number", "attr_site_name", "atr_a", "atr_b", "atr_c", "atr_d", "atr_e", "atr_f", "atr_g", "atr_h", "atr_i"]
    current_col_index = None # –í—ñ–¥—Å—Ç–µ–∂—É—î–º–æ –ø–æ—Ç–æ—á–Ω–∏–π –±–ª–æ–∫

    try:
        with open(attribute_path, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            
            try:
                header = next(reader)
                raw_data.append(header)
                max_row_len = len(header)
            except StopIteration:
                return {}, [default_header]

            for row in reader:
                # –ù–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ –¥–æ–≤–∂–∏–Ω—É —Ä—è–¥–∫–∞
                row = row[:max_row_len] + [''] * (max_row_len - len(row))
                raw_data.append(row)
                
                # 1. –Ø–∫—â–æ —Ü–µ —Ä—è–¥–æ–∫-–∑–∞–≥–æ–ª–æ–≤–æ–∫ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, "27",,,,,)
                if row and row[0].strip().isdigit():
                    try:
                        current_col_index = int(row[0].strip())
                        if current_col_index not in replacements_map:
                            replacements_map[current_col_index] = {}
                    except ValueError:
                        current_col_index = None
                        continue
                
                # 2. –Ø–∫—â–æ —Ü–µ —Ä—è–¥–æ–∫-–ø—Ä–∞–≤–∏–ª–æ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, ,,,—á–æ—Ä–Ω–∏–π,,)
                elif current_col_index is not None and len(row) >= 3:
                    
                    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–æ–≤–∞–Ω–µ –∑–Ω–∞—á–µ–Ω–Ω—è –∑–Ω–∞—Ö–æ–¥–∏—Ç—å—Å—è –≤ –∫–æ–ª–æ–Ω—Ü—ñ 1 (attr_site_name)
                    new_value = row[1].strip() 
                    
                    # –ü–µ—Ä–µ–≥–ª—è–¥–∞—î–º–æ –≤—Å—ñ –∑–Ω–∞—á–µ–Ω–Ω—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫—ñ–≤ (–ø–æ—á–∏–Ω–∞—é—á–∏ –∑ —ñ–Ω–¥–µ–∫—Å—É 2)
                    for original in row[2:]:
                        original = original.strip().lower()
                        if original:
                            # –ö–ª—é—á - –æ—Ä–∏–≥—ñ–Ω–∞–ª (lower), –ó–Ω–∞—á–µ–Ω–Ω—è - –∑–∞–º—ñ–Ω–∞ (–∑ attr_site_name)
                            replacements_map[current_col_index][original] = new_value

        return replacements_map, raw_data
    
    except FileNotFoundError:
        logging.warning(f"–§–∞–π–ª –∞—Ç—Ä–∏–±—É—Ç—ñ–≤ 'attribute.csv' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ. –ë—É–¥–µ —Å—Ç–≤–æ—Ä–µ–Ω–æ –Ω–æ–≤–∏–π.")
        return {}, [default_header]
    except Exception as e:
        logging.error(f"–í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ attribute.csv: {e}")
        return {}, [default_header]

def save_attributes_csv(raw_data):
    """
    –ó–±–µ—Ä—ñ–≥–∞—î –æ–Ω–æ–≤–ª–µ–Ω—ñ —Å–∏—Ä—ñ –¥–∞–Ω—ñ —É attribute.csv.
    """
    attribute_path = get_config_path('attribute.csv')
    try:
        # 'newline=''' –≤–∞–∂–ª–∏–≤–∏–π –¥–ª—è –∫–æ—Ä–µ–∫—Ç–Ω–æ–≥–æ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è CSV –Ω–∞ —Ä—ñ–∑–Ω–∏—Ö –û–°
        with open(attribute_path, 'w', encoding='utf-8', newline='') as f:
            writer = csv.writer(f)
            writer.writerows(raw_data)
        logging.info("–§–∞–π–ª –∞—Ç—Ä–∏–±—É—Ç—ñ–≤ attribute.csv –æ–Ω–æ–≤–ª–µ–Ω–æ.")
    except Exception as e:
        logging.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—ñ —Ñ–∞–π–ª—É –∞—Ç—Ä–∏–±—É—Ç—ñ–≤ attribute.csv: {e}")



def load_category_csv():
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –ø—Ä–∞–≤–∏–ª–∞ –∑–∞–º—ñ–Ω–∏ –∫–∞—Ç–µ–≥–æ—Ä—ñ–π –∑ category.csv.
    –ü–æ–≤–µ—Ä—Ç–∞—î:
    1. category_map: –°–ª–æ–≤–Ω–∏–∫ {supplier_id: {(name1, name2, name3): category_value}}
    2. raw_data: –°–ø–∏—Å–æ–∫ —Å–∏—Ä–∏—Ö —Ä—è–¥–∫—ñ–≤ –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ —Ñ–∞–π–ª—É.
    """
    category_path = get_config_path('category.csv')
    category_map = {}
    raw_data = []          
    
    default_header = ["postachalnyk", "name_1", "name_2", "name_3", "category"]
    current_supplier_id = None

    try:
        with open(category_path, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            
            try:
                header = next(reader)
                raw_data.append(header)
                max_row_len = len(header)
            except StopIteration:
                return {}, [default_header]

            for row in reader:
                row = row[:max_row_len] + [''] * (max_row_len - len(row))
                raw_data.append(row)
                
                # 1. –Ø–∫—â–æ —Ü–µ —Ä—è–¥–æ–∫-–∑–∞–≥–æ–ª–æ–≤–æ–∫ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, "1",,,,)
                if row and row[0].strip().isdigit():
                    try:
                        current_supplier_id = int(row[0].strip())
                        if current_supplier_id not in category_map:
                            category_map[current_supplier_id] = {}
                    except ValueError:
                        current_supplier_id = None
                        continue
                
                # 2. –Ø–∫—â–æ —Ü–µ —Ä—è–¥–æ–∫-–ø—Ä–∞–≤–∏–ª–æ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, ,"–õ—è–ª—å–∫–∏","–ö—É–∫–ª–∏","–ù–∞–¥—É–≤–Ω—ñ","–ù–∞–¥—É–≤–Ω—ñ –ª—è–ª—å–∫–∏")
                elif current_supplier_id is not None and len(row) >= 5:
                    
                    # –ö–ª—é—á—ñ –¥–ª—è –º–∞–ø–∏: (name_1, name_2, name_3) - –≤—Å—ñ –≤ –Ω–∏–∂–Ω—å–æ–º—É —Ä–µ–≥—ñ—Å—Ç—Ä—ñ
                    key_tuple = (
                        row[1].strip().lower(), 
                        row[2].strip().lower(), 
                        row[3].strip().lower()
                    )
                    
                    # –ó–Ω–∞—á–µ–Ω–Ω—è: category (–±–µ–∑ –∑–º—ñ–Ω–∏ —Ä–µ–≥—ñ—Å—Ç—Ä—É)
                    category_value = row[4].strip()
                    
                    category_map[current_supplier_id][key_tuple] = category_value

        return category_map, raw_data
    
    except FileNotFoundError:
        logging.warning(f"–§–∞–π–ª –∫–∞—Ç–µ–≥–æ—Ä—ñ–π 'category.csv' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ. –ë—É–¥–µ —Å—Ç–≤–æ—Ä–µ–Ω–æ –Ω–æ–≤–∏–π.")
        return {}, [default_header]
    except Exception as e:
        logging.error(f"–í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ category.csv: {e}")
        return {}, [default_header]

def save_category_csv(raw_data):
    """
    –ó–±–µ—Ä—ñ–≥–∞—î –æ–Ω–æ–≤–ª–µ–Ω—ñ —Å–∏—Ä—ñ –¥–∞–Ω—ñ —É category.csv.
    """
    category_path = get_config_path('category.csv')
    try:
        with open(category_path, 'w', encoding='utf-8', newline='') as f:
            writer = csv.writer(f)
            writer.writerows(raw_data)
        logging.info("–§–∞–π–ª –∫–∞—Ç–µ–≥–æ—Ä—ñ–π category.csv –æ–Ω–æ–≤–ª–µ–Ω–æ.")
    except Exception as e:
        logging.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—ñ —Ñ–∞–π–ª—É –∫–∞—Ç–µ–≥–æ—Ä—ñ–π category.csv: {e}")

def load_poznachky_csv():
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î —Å—Ç–∞—Ç–∏—á–Ω–∏–π —Å–ø–∏—Å–æ–∫ –ø–æ–∑–Ω–∞—á–æ–∫ –∑ poznachky.csv.
    –ü–æ–≤–µ—Ä—Ç–∞—î:
    1. poznachky_list: –°–ø–∏—Å–æ–∫ —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö –ø–æ–∑–Ω–∞—á–æ–∫ (—É –Ω–∏–∂–Ω—å–æ–º—É —Ä–µ–≥—ñ—Å—Ç—Ä—ñ).
    """
    poznachky_path = get_config_path('poznachky.csv')
    poznachky_list = []
    
    try:
        with open(poznachky_path, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            
            try:
                # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫ "Poznachky"
                next(reader) 
            except StopIteration:
                return []

            for row in reader:
                if row and row[0].strip():
                    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –ø–æ–∑–Ω–∞—á–∫–∏ —É –Ω–∏–∂–Ω—å–æ–º—É —Ä–µ–≥—ñ—Å—Ç—Ä—ñ –¥–ª—è —É–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–æ–≥–æ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è
                    poznachky_list.append(row[0].strip().lower())

        # –°–æ—Ä—Ç—É—î–º–æ –≤—ñ–¥ –Ω–∞–π–¥–æ–≤—à–∏—Ö –¥–æ –Ω–∞–π–∫–æ—Ä–æ—Ç—à–∏—Ö, —â–æ–± –∑–Ω–∞–π—Ç–∏ –Ω–∞–π–∫—Ä–∞—â–µ —Å–ø—ñ–≤–ø–∞–¥—ñ–Ω–Ω—è
        poznachky_list.sort(key=len, reverse=True)
        
        return poznachky_list
    
    except FileNotFoundError:
        logging.warning(f"–§–∞–π–ª –ø–æ–∑–Ω–∞—á–æ–∫ 'poznachky.csv' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return []
    except Exception as e:
        logging.error(f"–í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ poznachky.csv: {e}")
        return []



def clear_directory(folder_path: str):
    """–û—á–∏—â–∞—î –∞–±–æ —Å—Ç–≤–æ—Ä—é—î –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—é."""
    if not os.path.exists(folder_path):
        os.makedirs(folder_path, exist_ok=True)
        return
    for item in os.listdir(folder_path):
        path = os.path.join(folder_path, item)
        try:
            if os.path.isfile(path) or os.path.islink(path):
                os.unlink(path)
            elif os.path.isdir(path):
                shutil.rmtree(path)
        except Exception as e:
            logging.error(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –≤–∏–¥–∞–ª–∏—Ç–∏ {path}: {e}")

def move_gifs(src: str, dest: str) -> int:
    """–ü–µ—Ä–µ–º—ñ—â—É—î –≤—Å—ñ GIF —ñ–∑ src —É dest."""
    moved = 0
    os.makedirs(dest, exist_ok=True)
    for root, _, files in os.walk(src):
        for f in files:
            if f.lower().endswith('.gif'):
                src_path = os.path.join(root, f)
                rel = os.path.relpath(src_path, src)
                dest_path = os.path.join(dest, rel)
                os.makedirs(os.path.dirname(dest_path), exist_ok=True)
                shutil.move(src_path, dest_path)
                moved += 1
    logging.info(f"üü£ –ü–µ—Ä–µ–º—ñ—â–µ–Ω–æ {moved} GIF-—Ñ–∞–π–ª—ñ–≤.")
    return moved

def convert_to_webp_square(src: str, dest: str) -> int:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç—É—î JPG/PNG ‚Üí WEBP, –≤–∏—Ä—ñ–≤–Ω—é—î –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –¥–æ –∫–≤–∞–¥—Ä–∞—Ç—É
    —Ç–∞ –∫–æ—Ä–µ–∫—Ç–Ω–æ –æ–±—Ä–æ–±–ª—è—î –ø—Ä–æ–∑–æ—Ä—ñ—Å—Ç—å (RGBA / –ø–∞–ª—ñ—Ç—Ä–æ–≤—ñ P-–∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è).
    """
    import os
    import logging
    from PIL import Image

    converted = 0

    for root, _, files in os.walk(src):
        rel = os.path.relpath(root, src)
        out_dir = os.path.join(dest, rel)
        os.makedirs(out_dir, exist_ok=True)

        for f in files:
            if not f.lower().endswith(('.jpg', '.jpeg', '.png', '.webp')):
                continue

            try:
                img_path = os.path.join(root, f)
                img = Image.open(img_path)

                # üîπ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –∫–æ–ª—å–æ—Ä–æ–≤–æ–≥–æ —Ä–µ–∂–∏–º—É (–¥–ª—è —É–Ω–∏–∫–Ω–µ–Ω–Ω—è warning)
                if img.mode == "P":
                    img = img.convert("RGBA")
                elif img.mode not in ("RGB", "RGBA"):
                    img = img.convert("RGB")

                w, h = img.size
                max_side = max(w, h)

                # üîπ –Ø–∫—â–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –º–∞—î –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª ‚Äî —Å—Ç–≤–æ—Ä—é—î–º–æ –ø—Ä–æ–∑–æ—Ä–µ –ø–æ–ª–æ—Ç–Ω–æ
                if img.mode == "RGBA":
                    canvas = Image.new("RGBA", (max_side, max_side), (255, 255, 255, 0))
                else:
                    canvas = Image.new("RGB", (max_side, max_side), (255, 255, 255))

                # –¶–µ–Ω—Ç—Ä—É–≤–∞–Ω–Ω—è
                canvas.paste(img, ((max_side - w) // 2, (max_side - h) // 2))

                # üîπ –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —É —Ñ–æ—Ä–º–∞—Ç—ñ WEBP
                new_name = os.path.splitext(f)[0] + '.webp'
                out_path = os.path.join(out_dir, new_name)
                canvas.save(out_path, 'webp', quality=90)

                converted += 1

            except Exception as e:
                logging.error(f"‚ùå WEBP-–∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è '{f}' –Ω–µ –≤–¥–∞–ª–∞—Å—è: {e}")

    logging.info(f"üü¢ WEBP-–∫–æ–Ω–≤–µ—Ä—Ç–æ–≤–∞–Ω–æ {converted} –∑–æ–±—Ä–∞–∂–µ–Ω—å.")
    return converted

def download_product_images(url: str, sku: str, category: str, base_path: str, cat_map: Dict[str, str]) -> List[str]:
    """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –≤—Å—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Ç–æ–≤–∞—Ä—É –∑ URL."""
    cat_slug = cat_map.get(category.strip()) or category.strip().lower().replace(' ', '_').replace(',', '')
    dest = os.path.join(base_path, cat_slug)
    os.makedirs(dest, exist_ok=True)

    try:
        page = requests.get(url, timeout=10)
        page.raise_for_status()
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Å—Ç–æ—Ä—ñ–Ω–∫—É {url}: {e}")
        return []

    soup = BeautifulSoup(page.content, 'html.parser')
    links = {a.get('href') for a in soup.find_all('a', class_='thumb_image_container') if a.get('href')}
    files = []

    for i, img_url in enumerate(links, 1):
        try:
            r = requests.get(img_url, timeout=10)
            r.raise_for_status()
            mime = r.headers.get('Content-Type')
            ext = mimetypes.guess_extension(mime) or '.jpg'
            fname = f"{sku}-{i}{ext}"
            with open(os.path.join(dest, fname), 'wb') as f:
                f.write(r.content)
            files.append(fname)
        except Exception:
            continue

    # üü¢ –õ–æ–≥—É–≤–∞–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É
    logging.info(f"üì∏ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(files)} –∑–æ–±—Ä–∞–∂–µ–Ω—å –¥–ª—è SKU {sku}: {', '.join(files)}")

    return files

def sync_webp_column(sl_path: str, webp_path: str, col_index: int, sku_index: int) -> int:
    """–û–Ω–æ–≤–ª—é—î –∫–æ–ª–æ–Ω–∫—É WEBP/GIF-—Å–ø–∏—Å–∫—ñ–≤ —É CSV."""
    with open(sl_path, 'r', encoding='utf-8') as f:
        reader = list(csv.reader(f))
    if not reader:
        return 0

    header, *rows = reader
    sku_map = {}
    for root, _, files in os.walk(webp_path):
        for f in files:
            if '-' in f and f.lower().endswith(('.webp', '.gif')):
                sku = f.split('-')[0]
                sku_map.setdefault(sku, []).append(f)

    updated = 0
    for row in rows:
        if len(row) <= max(col_index, sku_index):
            row.extend([''] * (max(col_index, sku_index) + 1 - len(row)))
        sku = row[sku_index].strip()
        if sku in sku_map:
            row[col_index] = ', '.join(sorted(sku_map[sku]))
            updated += 1
    with open(sl_path, 'w', encoding='utf-8', newline='') as f:
        csv.writer(f).writerows([header] + rows)
    logging.info(f"üîÅ –û–Ω–æ–≤–ª–µ–Ω–æ {updated} SKU —É –∫–æ–ª–æ–Ω—Ü—ñ WEBP.")
    return updated

def copy_to_site(src: str, dest: str):
    """–ö–æ–ø—ñ—é—î WEBP/GIF –¥–æ —Ñ—ñ–Ω–∞–ª—å–Ω–æ—ó –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó –∑ –ø—Ä–∞–≤–∞–º–∏."""
    uid, gid = 33, 33
    fperm, dperm = 0o644, 0o755
    copied = 0

    for root, _, files in os.walk(src):
        rel = os.path.relpath(root, src)
        out_dir = os.path.join(dest, rel)
        os.makedirs(out_dir, mode=dperm, exist_ok=True)
        for f in files:
            if not f.lower().endswith(('.webp', '.gif')):
                continue
            src_f = os.path.join(root, f)
            dst_f = os.path.join(out_dir, f)
            shutil.copy2(src_f, dst_f)
            try:
                os.chown(dst_f, uid, gid)
                os.chmod(dst_f, fperm)
                copied += 1
            except PermissionError:
                logging.warning(f"‚ö†Ô∏è –ù–µ–º–∞—î –ø—Ä–∞–≤ –¥–ª—è –∑–º—ñ–Ω–∏ –≤–ª–∞—Å–Ω–∏–∫–∞ {dst_f}")
    logging.info(f"üì¶ –°–∫–æ–ø—ñ–π–æ–≤–∞–Ω–æ {copied} —Ñ–∞–π–ª—ñ–≤ —É {dest}.")
    return copied








def _process_batch_update(wcapi: Any, batch_data: List[Dict[str, Any]], errors_list: List[str]) -> int:
    """–í–∏–∫–æ–Ω—É—î –ø–∞–∫–µ—Ç–Ω–∏–π –∑–∞–ø–∏—Ç 'update' –¥–æ WooCommerce API."""
    
    payload = {"update": batch_data}
    
    try:
        logging.info(f"–ù–∞–¥—Å–∏–ª–∞—é –ø–∞–∫–µ—Ç –Ω–∞ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è ({len(batch_data)} —Ç–æ–≤–∞—Ä—ñ–≤)...")
        
        response = wcapi.post("products/batch", data=payload) 
        
        if response.status_code == 200:
            result = response.json()
            updated_count = len(result.get('update', []))
            
            # –î–µ—Ç–∞–ª—å–Ω–µ –ª–æ–≥—É–≤–∞–Ω–Ω—è –ø–æ–º–∏–ª–æ–∫, —è–∫—ñ –ø–æ–≤–µ—Ä–Ω—É–≤ API
            api_errors = result.get('errors', [])
            if api_errors:
                for err in api_errors:
                    err_msg = f"API-–ü–æ–º–∏–ª–∫–∞ (ID: {err.get('id', 'N/A')}): {err.get('message', '–ù–µ–≤—ñ–¥–æ–º–∞ –ø–æ–º–∏–ª–∫–∞')}"
                    errors_list.append(err_msg)
                    logging.error(err_msg)
                
            logging.info(f"‚úÖ –ü–∞–∫–µ—Ç –æ–Ω–æ–≤–ª–µ–Ω–æ. –£—Å–ø—ñ—à–Ω–æ –æ–±—Ä–æ–±–ª–µ–Ω–æ API: {updated_count} —Ç–æ–≤–∞—Ä—ñ–≤. –ü–æ–º–∏–ª–æ–∫ —É –ø–∞–∫–µ—Ç—ñ: {len(api_errors)}")
            return updated_count
        else:
            err_msg = f"‚ùå –ö—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞ API ({response.status_code}) –ø—Ä–∏ –ø–∞–∫–µ—Ç–Ω–æ–º—É –æ–Ω–æ–≤–ª–µ–Ω–Ω—ñ. –ü–æ–º–∏–ª–∫–∞: {response.text[:200]}..."
            errors_list.append(err_msg)
            logging.critical(err_msg)
            return 0
            
    except Exception as e:
        err_msg = f"‚ùå –ù–µ–ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –≤—ñ–¥–ø—Ä–∞–≤–∫–∏ –ø–∞–∫–µ—Ç—É: {e}"
        errors_list.append(err_msg)
        logging.critical(err_msg, exc_info=True)
        return 0
    

def find_media_ids_for_sku(wcapi, sku: str, uploads_path: str) -> List[Dict[str, Any]]:
    """
    –ó–Ω–∞—Ö–æ–¥–∏—Ç—å —É—Å—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –¥–ª—è SKU —É uploads_path —Ç–∞ –ø–æ–≤–µ—Ä—Ç–∞—î —Å–ø–∏—Å–æ–∫ ID –¥–ª—è WooCommerce.
    –ü—ñ–¥—Ç—Ä–∏–º—É—î —Ä—ñ–∑–Ω—ñ —Ä–æ–∑—à–∏—Ä–µ–Ω–Ω—è —Ç–∞ –ø—ñ–¥–ø–∞–ø–∫–∏.
    """
    def _get_media_id_by_filename(filename: str) -> int | None:
        """–í–Ω—É—Ç—Ä—ñ—à–Ω—è —Ñ—É–Ω–∫—Ü—ñ—è: —à—É–∫–∞—î ID –º–µ–¥—ñ–∞ –∑–∞ slug –∞–±–æ title"""
        import requests

        file_slug = os.path.splitext(filename)[0]

        # –ü–æ—à—É–∫ –∑–∞ slug
        try:
            response = wcapi.get("media", params={'search': file_slug, 'per_page': 1, 'orderby': 'slug'})
            if response.status_code == 200:
                items = response.json()
                if items:
                    item = items[0]
                    if item.get('slug') == file_slug or item.get('title', {}).get('rendered') == filename:
                        return item['id']
        except Exception as e:
            logging.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –ø–æ—à—É–∫—É –º–µ–¥—ñ–∞ ID –¥–ª—è {filename} (slug): {e}")

        # –ü–æ—à—É–∫ –∑–∞ —Ç–æ—á–Ω–∏–º title
        try:
            response = wcapi.get("media", params={'search': filename, 'per_page': 1, 'orderby': 'title'})
            if response.status_code == 200:
                items = response.json()
                if items:
                    item = items[0]
                    if item.get('title', {}).get('rendered') == filename:
                        return item['id']
        except Exception as e:
            logging.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –ø–æ—à—É–∫—É –º–µ–¥—ñ–∞ ID –¥–ª—è {filename} (title): {e}")

        logging.warning(f"‚ö†Ô∏è –ú–µ–¥—ñ–∞ ID –¥–ª—è —Ñ–∞–π–ª—É '{filename}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return None

    media_ids = []
    pattern = os.path.join(uploads_path, '**', f'{sku}*.*')
    files = glob.glob(pattern, recursive=True)
    for file_path in files:
        filename = os.path.basename(file_path)
        media_id = _get_media_id_by_filename(filename)
        if media_id:
            media_ids.append({"id": media_id})

    if not media_ids:
        logging.warning(f"‚ö†Ô∏è SKU {sku}: –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∑–æ–±—Ä–∞–∂–µ–Ω—å —É '{uploads_path}'")
    return media_ids



# --- –î–û–ü–û–ú–Ü–ñ–ù–ê –§–£–ù–ö–¶–Ü–Ø –î–õ–Ø –ü–ê–ö–ï–¢–ù–û–ì–û –ó–ê–ü–ò–°–£ (–°—Ç–≤–æ—Ä–µ–Ω–Ω—è) (–±–µ–∑ –∑–º—ñ–Ω) ---
def _process_batch_create(wcapi: Any, batch_data: List[Dict[str, Any]], errors_list: List[str]) -> int:
    """–í–∏–∫–æ–Ω—É—î –ø–∞–∫–µ—Ç–Ω–∏–π –∑–∞–ø–∏—Ç 'create' –¥–æ WooCommerce API."""
    
    payload = {"create": batch_data}
    
    try:
        logging.info(f"–ù–∞–¥—Å–∏–ª–∞—é –ø–∞–∫–µ—Ç –Ω–∞ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è ({len(batch_data)} —Ç–æ–≤–∞—Ä—ñ–≤)...")
        response = wcapi.post("products/batch", data=payload) 
        
        if response.status_code == 200:
            result = response.json()
            created_count = len(result.get('create', []))
            
            api_errors = result.get('errors', [])
            if api_errors:
                for err in api_errors:
                    err_msg = f"API-–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—ñ: SKU '{err.get('data', {}).get('resource_id', 'N/A')}', Code: {err.get('code', 'N/A')}: {err.get('message', '–ù–µ–≤—ñ–¥–æ–º–∞ –ø–æ–º–∏–ª–∫–∞')}"
                    errors_list.append(err_msg)
                    logging.error(err_msg)
                
            logging.info(f"‚úÖ –ü–∞–∫–µ—Ç —Å—Ç–≤–æ—Ä–µ–Ω–æ. –£—Å–ø—ñ—à–Ω–æ –æ–±—Ä–æ–±–ª–µ–Ω–æ API: {created_count} —Ç–æ–≤–∞—Ä—ñ–≤. –ü–æ–º–∏–ª–æ–∫ —É –ø–∞–∫–µ—Ç—ñ: {len(api_errors)}")
            return created_count
        else:
            err_msg = f"‚ùå –ö—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞ API ({response.status_code}) –ø—Ä–∏ –ø–∞–∫–µ—Ç–Ω–æ–º—É —Å—Ç–≤–æ—Ä–µ–Ω–Ω—ñ. –ü–æ–º–∏–ª–∫–∞: {response.text[:200]}..."
            errors_list.append(err_msg)
            logging.critical(err_msg)
            return 0
            
    except Exception as e:
        err_msg = f"‚ùå –ù–µ–ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –≤—ñ–¥–ø—Ä–∞–≤–∫–∏ –ø–∞–∫–µ—Ç—É: {e}"
        errors_list.append(err_msg)
        logging.critical(err_msg, exc_info=True)
        return 0
    

def _clean_text(value: str) -> str:
    """–û—á–∏—â—É—î HTML-—Ç–µ–≥–∏, –∫–æ–¥—É–≤–∞–Ω–Ω—è —ñ –∑–∞–π–≤—ñ –ø—Ä–æ–±—ñ–ª–∏."""
    if not value:
        return ""
    value = html.unescape(str(value))  # —Ä–æ–∑–∫–æ–¥–æ–≤—É—î &#8211; ‚Üí ‚Äì
    value = re.sub(r"<.*?>", "", value)  # –≤–∏–¥–∞–ª—è—î HTML-—Ç–µ–≥–∏
    return value.strip()

def export_product_by_id():
    """
    –ï–∫—Å–ø–æ—Ä—Ç—É—î –≤—Å—ñ –¥–∞–Ω—ñ —Ç–æ–≤–∞—Ä—É –∑–∞ –≤–≤–µ–¥–µ–Ω–∏–º ID —É /csv/input/ID_tovar.csv.
    –í–∏–ø—Ä–∞–≤–ª–µ–Ω–æ HTML-–∫–æ–¥—É–≤–∞–Ω–Ω—è, –µ–∫—Ä–∞–Ω—É–≤–∞–Ω–Ω—è CSV —ñ –¥–æ–¥–∞–Ω–æ –ø–µ—Ä–µ–∫–ª–∞–¥–∏ WPML.
    """
    log_message_to_existing_file()
    settings = load_settings()
    if not settings:
        logging.error("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è.")
        return

    wcapi = get_wc_api(settings)
    if not wcapi:
        logging.error("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è —Å—Ç–≤–æ—Ä–∏—Ç–∏ –æ–±'—î–∫—Ç WooCommerce API.")
        return

    product_id = input("–í–≤–µ–¥—ñ—Ç—å ID —Ç–æ–≤–∞—Ä—É –¥–ª—è –µ–∫—Å–ø–æ—Ä—Ç—É: ").strip()
    if not product_id.isdigit():
        logging.error("‚ùå –ù–µ–∫–æ—Ä–µ–∫—Ç–Ω–∏–π ID —Ç–æ–≤–∞—Ä—É.")
        return
    product_id = int(product_id)

    output_dir = "/var/www/scripts/update/csv/input"
    os.makedirs(output_dir, exist_ok=True)
    csv_path = os.path.join(output_dir, "ID_tovar.csv")

    start_time = time.time()
    try:
        # === –û—Å–Ω–æ–≤–Ω—ñ –¥–∞–Ω—ñ —Ç–æ–≤–∞—Ä—É ===
        response = wcapi.get(f"products/{product_id}", params={"context": "edit"})
        if response.status_code != 200:
            logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ {response.status_code}: {response.text}")
            return
        product = response.json()
        if not isinstance(product, dict):
            logging.error(f"‚ùå –ù–µ–∫–æ—Ä–µ–∫—Ç–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ API –¥–ª—è —Ç–æ–≤–∞—Ä—É ID {product_id}")
            return

        row = {"id": product_id}

        # === –û—Å–Ω–æ–≤–Ω—ñ –ø–æ–ª—è ===
        for key, value in product.items():
            if isinstance(value, dict):
                for subkey, subval in value.items():
                    row[f"{key}.{subkey}"] = _clean_text(subval)
            elif isinstance(value, list):
                if key == "meta_data":
                    for meta in value:
                        k = meta.get("key")
                        v = meta.get("value")
                        if k:
                            row[f"–ú–µ—Ç–∞: {k}"] = _clean_text(v)
                elif key == "categories":
                    row["categories"] = ", ".join([_clean_text(v.get("name", "")) for v in value])
                elif key == "tags":
                    row["tags"] = ", ".join([_clean_text(v.get("name", "")) for v in value])
                elif key == "images":
                    for idx, img in enumerate(value, start=1):
                        row[f"image_{idx}_id"] = img.get("id", "")
                        row[f"image_{idx}_src"] = img.get("src", "")
                        row[f"image_{idx}_name"] = _clean_text(img.get("name", ""))
                        row[f"image_{idx}_alt"] = _clean_text(img.get("alt", ""))
                        row[f"image_{idx}_title"] = _clean_text(img.get("title", ""))
                        row[f"image_{idx}_caption"] = _clean_text(img.get("caption", ""))
                        row[f"image_{idx}_description"] = _clean_text(img.get("description", ""))
                else:
                    row[key] = ", ".join(map(_clean_text, map(str, value)))
            else:
                row[key] = _clean_text(value)

        # === –ü–µ—Ä–µ–∫–ª–∞–¥–∏ WPML ===
        try:
            wpml_resp = wcapi.get(f"products/{product_id}/translations")
            if wpml_resp.status_code == 200:
                translations = wpml_resp.json()
                for lang, tr in translations.items():
                    if isinstance(tr, dict):
                        row[f"wpml_{lang}_id"] = tr.get("id", "")
                        row[f"wpml_{lang}_name"] = _clean_text(tr.get("name", ""))
                        row[f"wpml_{lang}_slug"] = tr.get("slug", "")
                        row[f"wpml_{lang}_status"] = tr.get("status", "")
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è –ù–µ–º–æ–∂–ª–∏–≤–æ –æ—Ç—Ä–∏–º–∞—Ç–∏ WPML –ø–µ—Ä–µ–∫–ª–∞–¥–∏: {e}")

        # === –ó–∞–ø–∏—Å —É CSV ===
        file_exists = os.path.exists(csv_path)
        file_is_empty = not file_exists or os.path.getsize(csv_path) == 0

        with open(csv_path, "a", newline="", encoding="utf-8") as f:
            writer = csv.DictWriter(f, fieldnames=row.keys(), quoting=csv.QUOTE_ALL)
            if file_is_empty:
                writer.writeheader()
            writer.writerow(row)

        elapsed = int(time.time() - start_time)
        logging.info(f"‚úÖ –ï–∫—Å–ø–æ—Ä—Ç–æ–≤–∞–Ω–æ —Ç–æ–≤–∞—Ä ID {product_id} ({len(row)} –ø–æ–ª—ñ–≤) ‚Üí {csv_path} –∑–∞ {elapsed} —Å–µ–∫.")

    except Exception as e:
        logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –µ–∫—Å–ø–æ—Ä—Ç—É: {e}", exc_info=True)





def update_image_seo_by_sku():
    """
    –û–Ω–æ–≤–ª—é—î SEO-–∞—Ç—Ä–∏–±—É—Ç–∏ –∑–æ–±—Ä–∞–∂–µ–Ω—å —Ç–æ–≤–∞—Ä—É –∑–∞ SKU.
    - –û–Ω–æ–≤–ª—é—î alt/title —á–µ—Ä–µ–∑ WooCommerce (wc/v3 products PUT).
    - –û–Ω–æ–≤–ª—é—î caption/description —á–µ—Ä–µ–∑ WP REST API (wp/v2/media/{id}) –∑ Basic Auth,
      –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—á–∏ credentials –∑ settings.json: 'login' —ñ 'pass'.
    """
    logging.basicConfig(level=logging.INFO)
    print("üñºÔ∏è –ó–∞–ø—É—Å–∫–∞—é –æ–Ω–æ–≤–ª–µ–Ω–Ω—è SEO-–∞—Ç—Ä–∏–±—É—Ç—ñ–≤ –∑–æ–±—Ä–∞–∂–µ–Ω—å...")

    settings = load_settings()
    if not settings:
        logging.critical("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è.")
        return

    # --- –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –¥–ª—è WooCommerce API (wc/v3) ---
    try:
        wcapi = get_wc_api(settings)
    except Exception as e:
        logging.critical(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è —Å—Ç–≤–æ—Ä–∏—Ç–∏ –æ–±'—î–∫—Ç WooCommerce API: {e}")
        return

    base_url = settings.get("url", "").rstrip("/")
    api_key = settings.get("consumer_key")
    api_secret = settings.get("consumer_secret")

    wp_login = settings.get("login")   # username –∞–±–æ –ª–æ–≥—ñ–Ω
    wp_pass = settings.get("pass")     # application password –∞–±–æ –ø–∞—Ä–æ–ª—å

    if not base_url or not api_key or not api_secret:
        logging.critical("‚ùå –ù–µ–ø–æ–≤–Ω—ñ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è API (url, consumer_key –∞–±–æ consumer_secret).")
        return

    # 1) –í–≤–µ–¥–µ–Ω–Ω—è SKU
    sku = input("üîç –í–≤–µ–¥—ñ—Ç—å SKU —Ç–æ–≤–∞—Ä—É: ").strip()
    if not sku:
        print("‚ùå SKU –Ω–µ –≤–≤–µ–¥–µ–Ω–æ.")
        return

    # 2) –û—Ç—Ä–∏–º—É—î–º–æ —Ç–æ–≤–∞—Ä –ø–æ SKU
    try:
        resp = wcapi.get("products", params={"sku": sku})
        if resp.status_code != 200:
            logging.error(f"‚ùå WooCommerce products GET returned {resp.status_code}: {resp.text[:200]}")
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –ø–æ—à—É–∫—É —Ç–æ–≤–∞—Ä—É (—Å—Ç–∞—Ç—É—Å {resp.status_code}). –ü–µ—Ä–µ–≤—ñ—Ä –ª–æ–≥–∏.")
            return
        products = resp.json()
        if not products:
            print(f"‚ùå –¢–æ–≤–∞—Ä –∑—ñ SKU {sku} –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
            return
        product = products[0]
    except Exception as e:
        logging.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Ç—ñ –¥–æ WooCommerce: {e}", exc_info=True)
        print("‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑'—î–¥–Ω–∞–Ω–Ω—ñ –∑ WooCommerce.")
        return

    product_name = product.get("name", "").strip()
    product_id = product.get("id")
    image_list: List[Dict[str, Any]] = product.get("images", [])  # —Å–ø–∏—Å–æ–∫ dict –∑ keys: id, src, name, alt

    if not product_name:
        print("‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –Ω–∞–∑–≤–∏ —Ç–æ–≤–∞—Ä—É.")
        return

    if not image_list:
        print(f"‚ùå –¢–æ–≤–∞—Ä {product_name} –Ω–µ –º–∞—î –ø—Ä–∏–≤'—è–∑–∞–Ω–∏—Ö –∑–æ–±—Ä–∞–∂–µ–Ω—å —É –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ WC API.")
        return

    print(f"‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ —Ç–æ–≤–∞—Ä: {product_name}")
    print(f"üñºÔ∏è –ó–Ω–∞–π–¥–µ–Ω–æ {len(image_list)} –ø—Ä–∏–≤'—è–∑–∞–Ω–∏—Ö –∑–æ–±—Ä–∞–∂–µ–Ω—å. –ü–æ—á–∏–Ω–∞—é –æ–Ω–æ–≤–ª–µ–Ω–Ω—è...")

    seo_data = {
        "title": product_name,
        "alt": f"–ö—É–ø–∏—Ç–∏ —Ç–æ–≤–∞—Ä {product_name} –≤ —Å–µ–∫—Å-—à–æ–ø—ñ Eros.in.ua",
        "caption": f"{product_name} ‚Äì —ñ–Ω–Ω–æ–≤–∞—Ü—ñ–π–Ω–∞ —Å–µ–∫—Å-—ñ–≥—Ä–∞—à–∫–∞ –¥–ª—è –≤–∞—à–æ–≥–æ –∑–∞–¥–æ–≤–æ–ª–µ–Ω–Ω—è",
        "description": f"{product_name} –∫—É–ø–∏—Ç–∏ –≤ —ñ–Ω—Ç–µ—Ä–Ω–µ—Ç-–º–∞–≥–∞–∑–∏–Ω—ñ Eros.in.ua. –í–µ–ª–∏–∫–∏–π –≤–∏–±—ñ—Ä —Å–µ–∫—Å-—ñ–≥—Ä–∞—à–æ–∫, –Ω–∏–∑—å–∫–∞ —Ü—ñ–Ω–∞, —à–≤–∏–¥–∫–∞ –±–µ–∑–∫–æ—à—Ç–æ–≤–Ω–∞ –¥–æ—Å—Ç–∞–≤–∫–∞."
    }

    # --- –î–æ–ø–æ–º—ñ–∂–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è: –∑–Ω–∞–π—Ç–∏ media id –ø–æ filename —á–µ—Ä–µ–∑ WP REST API (search) ---
    def find_media_id_by_filename(filename: str) -> int:
        """
        –ü–æ–≤–µ—Ä—Ç–∞—î media id –∞–±–æ None. –ü—Ä–∞—Ü—é—î —á–µ—Ä–µ–∑ /wp-json/wp/v2/media?search=<filename>
        –ü–æ—Ç—Ä—ñ–±–Ω–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ü—ñ—è, —è–∫—â–æ WP –∑–∞–∫—Ä–∏—Ç–∏–π. –ú–∏ —Å–ø—Ä–æ–±—É—î–º–æ –±–µ–∑ auth –ø–µ—Ä—à–∏–º, –ø–æ—Ç—ñ–º –∑ auth.
        """
        search_url = f"{base_url}/wp-json/wp/v2/media"
        params = {"search": filename, "per_page": 10}
        headers = {"Accept": "application/json"}

        # –°–ø—Ä–æ–±–∞ –±–µ–∑ auth
        try:
            r = requests.get(search_url, params=params, headers=headers, timeout=15, verify=True)
            if r.status_code == 200:
                items = r.json()
                for it in items:
                    src = it.get("source_url", "") or it.get("guid", {}).get("rendered", "")
                    if filename.lower() in (os.path.basename(src).lower()):
                        return it.get("id")
            # —è–∫—â–æ –Ω–µ –≤–¥–∞–ª–æ—Å—å –∞–±–æ –ø–æ—Ä–æ–∂–Ω—å–æ ‚Äî —Å–ø—Ä–æ–±—É—î–º–æ –∑ auth —è–∫—â–æ —î
        except Exception as e:
            logging.debug(f"find_media_id_by_filename (no auth) error: {e}")

        if wp_login and wp_pass:
            try:
                r = requests.get(search_url, params=params, headers=headers, auth=(wp_login, wp_pass), timeout=15, verify=True)
                if r.status_code == 200:
                    items = r.json()
                    for it in items:
                        src = it.get("source_url", "") or it.get("guid", {}).get("rendered", "")
                        if filename.lower() in (os.path.basename(src).lower()):
                            return it.get("id")
                else:
                    logging.debug(f"find_media_id_by_filename (auth) status {r.status_code}: {r.text[:200]}")
            except Exception as e:
                logging.debug(f"find_media_id_by_filename (auth) exception: {e}")

        return None

    # --- –û—Å–Ω–æ–≤–Ω–∏–π —Ü–∏–∫–ª –æ–Ω–æ–≤–ª–µ–Ω–Ω—è ---
    updated = 0
    failed = 0

    # We'll batch update product images alt/title via product PUT if possible
    # Prepare a copy of current images with alt changes to minimize number of product PUTs.
    wc_images_update = []
    for img in image_list:
        media_id = img.get("id")
        src = img.get("src") or ""
        filename = os.path.basename(src) if src else None

        # Prefer media_id; if missing, try to find by filename
        if not media_id and filename:
            found_id = find_media_id_by_filename(filename)
            if found_id:
                media_id = found_id
                logging.info(f"–ó–Ω–∞–π–¥–µ–Ω–æ media_id {media_id} –ø–æ —Ñ–∞–π–ª—É {filename}")
            else:
                logging.warning(f"–ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ media record –¥–ª—è {filename}. –ü—Ä–æ–ø—É—Å–∫–∞—é.")
                continue

        if media_id:
            # For WooCommerce product update we will set alt and name (title)
            wc_images_update.append({"id": media_id, "alt": seo_data["alt"], "name": seo_data["title"]})

    # If we have any image updates for WooCommerce ‚Äî send one PUT to products/{id}
    if wc_images_update and product_id:
        try:
            resp_put = wcapi.put(f"products/{product_id}", {"images": wc_images_update})
            if resp_put.status_code == 200:
                logging.info("‚úÖ WooCommerce: alt/title –æ–Ω–æ–≤–ª–µ–Ω–æ —á–µ—Ä–µ–∑ products PUT")
                updated += len(wc_images_update)
            else:
                logging.error(f"‚ùå WooCommerce products PUT returned {resp_put.status_code}: {resp_put.text[:300]}")
                # don't return ‚Äî try per-media WP updates below
        except Exception as e:
            logging.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ WooCommerce products PUT: {e}")

    # Now, attempt to update caption/description via wp/v2/media for each image
    for img in image_list:
        media_id = img.get("id")
        src = img.get("src") or ""
        filename = os.path.basename(src) if src else None

        if not media_id:
            if filename:
                media_id = find_media_id_by_filename(filename)
                if media_id:
                    logging.info(f"–ó–Ω–∞–π–¥–µ–Ω–æ media_id {media_id} –¥–ª—è {filename} —á–µ—Ä–µ–∑ –ø–æ—à—É–∫.")
                else:
                    logging.warning(f"–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–Ω–∞–π—Ç–∏ media_id –¥–ª—è {filename}. –ü—Ä–æ–ø—É—Å–∫–∞—é WP media update.")
                    failed += 1
                    continue
            else:
                logging.warning("–ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è –Ω–µ –º–∞—î src —Ç–∞ id ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞—é.")
                failed += 1
                continue

        media_endpoint = f"{base_url}/wp-json/wp/v2/media/{media_id}"
        update_data = {
            "title": seo_data["title"],
            "alt_text": seo_data["alt"],
            "caption": seo_data["caption"],
            "description": seo_data["description"]
        }

        # –¢—Ä–µ–±–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü—ñ—è –¥–ª—è wp/v2/media (Application Password –∞–±–æ user/pass)
        if not wp_login or not wp_pass:
            logging.warning("‚ö†Ô∏è –í settings.json –Ω–µ –∑–Ω–∞–π–¥–µ–Ω—ñ 'login' —Ç–∞ 'pass' ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞—é –æ–Ω–æ–≤–ª–µ–Ω–Ω—è caption/description —á–µ—Ä–µ–∑ wp/v2/media.")
            failed += 1
            continue

        try:
            r = requests.put(media_endpoint, auth=(wp_login, wp_pass), json=update_data, timeout=20, verify=True)
            if r.status_code == 200:
                print(f"‚úÖ –û–Ω–æ–≤–ª–µ–Ω–æ –º–µ–¥—ñ–∞ ID {media_id} ({filename if filename else ''})")
                updated += 1
            else:
                logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è ID {media_id}. –°—Ç–∞—Ç—É—Å: {r.status_code}. –ü–æ–º–∏–ª–∫–∞: {r.text[:300]}")
                failed += 1
        except requests.exceptions.RequestException as e:
            logging.error(f"–ö—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –∑–∞–ø–∏—Ç—É –¥–ª—è {media_id}: {e}")
            failed += 1

    print(f"üéØ –ó–∞–≤–µ—Ä—à–µ–Ω–æ. –£—Å–ø—ñ—à–Ω–æ –æ–Ω–æ–≤–ª–µ–Ω–æ: {updated}, –Ω–µ –≤–¥–∞–ª–æ—Å—è: {failed}.")




def translate_texts_deepl_batch(texts, target_lang="RU", api_key=None, api_url=None):
    """
    –ü–µ—Ä–µ–∫–ª–∞–¥–∞—î —Å–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç—ñ–≤ —á–µ—Ä–µ–∑ DeepL API –æ–¥–Ω–∏–º –∑–∞–ø–∏—Ç–æ–º.
    –ü–æ–≤–µ—Ä—Ç–∞—î —Å–ø–∏—Å–æ–∫ –ø–µ—Ä–µ–∫–ª–∞–¥–µ–Ω–∏—Ö —Ç–µ–∫—Å—Ç—ñ–≤.
    """
    if not api_key:
        logging.error("API –∫–ª—é—á DeepL –Ω–µ –≤–∫–∞–∑–∞–Ω–æ!")
        return texts

    if not api_url:
        api_url = "https://api-free.deepl.com/v2/translate"

    try:
        response = requests.post(
            api_url,
            data={
                "auth_key": api_key,
                "text": texts,
                "target_lang": target_lang
            },
            timeout=30
        )
        response.raise_for_status()
        data = response.json()
        return [t["text"] for t in data["translations"]]
    except Exception as e:
        logging.error(f"–ü–æ–º–∏–ª–∫–∞ –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –ø–µ—Ä–µ–∫–ª–∞–¥—É —á–µ—Ä–µ–∑ DeepL: {e}")
        return texts

def translate_csv_to_ru(batch_size=20):
    """
    –ü–µ—Ä–µ–∫–ª–∞–¥–∞—î –∫–ª—é—á–æ–≤—ñ –∫–æ–ª–æ–Ω–∫–∏ CSV –∑ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—ó –Ω–∞ —Ä–æ—Å—ñ–π—Å—å–∫—É —á–µ—Ä–µ–∑ DeepL.
    –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î —à–ª—è—Ö–∏ —Ç–∞ –∫–ª—é—á—ñ –∑ settings.json.
    –ü—Ä–∞—Ü—é—î –ø–∞–∫–µ—Ç–∞–º–∏, —â–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ –±–ª–æ–∫—É–≤–∞–Ω–Ω—è API.
    """
    log_message_to_existing_file()
    logging.info("üöÄ –ü–æ—á–∞—Ç–æ–∫ –ø–µ—Ä–µ–∫–ª–∞–¥—É CSV –Ω–∞ —Ä–æ—Å—ñ–π—Å—å–∫—É...")

    settings = load_settings()
    if not settings:
        logging.error("‚ùå –ù–µ–º–æ–∂–ª–∏–≤–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ settings.json")
        return

    input_path = settings["paths"].get("csv_path_sl_new_prod")
    output_path = settings["paths"].get("csv_path_sl_new_prod_ru")
    api_key = settings.get("deepl_api_key")
    api_url = settings.get("DEEPL_API_URL", "https://api-free.deepl.com/v2/translate")

    if not all([input_path, output_path, api_key]):
        logging.error("‚ùå –í settings.json –Ω–µ –≤–∫–∞–∑–∞–Ω—ñ –≤—Å—ñ –Ω–µ–æ–±—Ö—ñ–¥–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ (—à–ª—è—Ö–∏ –∞–±–æ deepl_api_key)")
        return

    # –¢–≤–æ—ó —Ä–µ–∞–ª—å–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –ø–µ—Ä–µ–∫–ª–∞–¥—É
    columns_to_translate = ["name", "content", "excerpt", "rank_math_focus_keyword"]

    try:
        with open(input_path, mode='r', encoding='utf-8') as f_in, \
             open(output_path, mode='w', encoding='utf-8', newline='') as f_out:

            reader = csv.DictReader(f_in)
            headers = reader.fieldnames
            if not headers:
                logging.error("‚ùå –§–∞–π–ª –ø–æ—Ä–æ–∂–Ω—ñ–π –∞–±–æ –Ω–µ–º–∞—î –∑–∞–≥–æ–ª–æ–≤–∫—ñ–≤.")
                return

            writer = csv.DictWriter(f_out, fieldnames=headers)
            writer.writeheader()

            batch_rows = []
            batch_texts = []

            for idx, row in enumerate(reader, start=2):
                texts_to_translate = []
                for col in columns_to_translate:
                    texts_to_translate.append(row.get(col, ""))

                batch_rows.append(row)
                batch_texts.append(texts_to_translate)

                # –ü–µ—Ä–µ–∫–ª–∞–¥ –ø–∞–∫–µ—Ç–æ–º
                if len(batch_rows) >= batch_size:
                    # –¢—Ä–∞–Ω—Å–ø–æ–Ω—É—î–º–æ —Å–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç—ñ–≤ –¥–ª—è DeepL (–ø–æ—Ç—Ä—ñ–±–Ω–æ –Ω–∞–¥—Å–∏–ª–∞—Ç–∏ —Ä—è–¥–∫–∏ –æ–∫—Ä–µ–º–æ)
                    flattened_texts = [t for sublist in batch_texts for t in sublist]
                    translated_flat = translate_texts_deepl_batch(flattened_texts, api_key=api_key, api_url=api_url)

                    # –†–æ–∑–ø–∞–∫–æ–≤—É—î–º–æ –Ω–∞–∑–∞–¥ —É —Ä—è–¥–∫–∏
                    for i, r in enumerate(batch_rows):
                        for j, col in enumerate(columns_to_translate):
                            r[col] = translated_flat[i * len(columns_to_translate) + j]
                            logging.info(f"–†—è–¥–æ–∫ {idx - len(batch_rows) + i + 2}: –∫–æ–ª–æ–Ω–∫–∞ '{col}' –ø–µ—Ä–µ–∫–ª–∞–¥–µ–Ω–∞.")
                        writer.writerow(r)

                    batch_rows = []
                    batch_texts = []
                    time.sleep(1)  # –ø–∞—É–∑–∞ –º—ñ–∂ –ø–∞–∫–µ—Ç–∞–º–∏

            # –ü–µ—Ä–µ–∫–ª–∞–¥ –∑–∞–ª–∏—à–∫—É —Ä—è–¥–∫—ñ–≤
            if batch_rows:
                flattened_texts = [t for sublist in batch_texts for t in sublist]
                translated_flat = translate_texts_deepl_batch(flattened_texts, api_key=api_key, api_url=api_url)
                for i, r in enumerate(batch_rows):
                    for j, col in enumerate(columns_to_translate):
                        r[col] = translated_flat[i * len(columns_to_translate) + j]
                        logging.info(f"–†—è–¥–æ–∫ {idx - len(batch_rows) + i + 2}: –∫–æ–ª–æ–Ω–∫–∞ '{col}' –ø–µ—Ä–µ–∫–ª–∞–¥–µ–Ω–∞.")
                    writer.writerow(r)

        logging.info(f"‚úÖ –ü–µ—Ä–µ–∫–ª–∞–¥ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –§–∞–π–ª –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {output_path}")

    except FileNotFoundError:
        logging.error(f"‚ùå –í—Ö—ñ–¥–Ω–∏–π —Ñ–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {input_path}")
    except Exception as e:
        logging.error(f"‚ùå –ù–µ–ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–∫–ª–∞–¥—ñ CSV: {e}")