import csv, pymysql, html, os, re, logging, requests, shutil, io
import pandas as pd
from scr.oc_base_function import oc_setup_new_log_file, oc_log_message, oc_connect_db, load_oc_settings

# –ì–û–õ–û–í–ù–ê –§–£–ù–ö–¶–Ü–Ø 1: –ï–∫—Å–ø–æ—Ä—Ç —Ç–æ–≤–∞—Ä—ñ–≤ –∑ –±–¥
def oc_export_products():
    """
    –û—Å–Ω–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –µ–∫—Å–ø–æ—Ä—Ç—É —Ç–æ–≤–∞—Ä—ñ–≤:
    1. –ù–∞–ª–∞—à—Ç–æ–≤—É—î –Ω–æ–≤–∏–π –ª–æ–≥.
    2. –ß–∏—Ç–∞—î –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —Ç–∞ –ø—Ä–µ—Å–µ—Ç–∏.
    3. –í–∏–∫–æ–Ω—É—î SQL –∑–∞–ø–∏—Ç.
    4. –ó–±–µ—Ä—ñ–≥–∞—î —Ä–µ–∑—É–ª—å—Ç–∞—Ç —É CSV.
    """

    # 1. –°—Ç–≤–æ—Ä—é—î–º–æ –Ω–æ–≤–∏–π –ª–æ–≥ (—ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è logging)
    oc_setup_new_log_file()
    
    start_msg = "‚ñ∂ –°—Ç–∞—Ä—Ç –µ–∫—Å–ø–æ—Ä—Ç—É —Ç–æ–≤–∞—Ä—ñ–≤ OpenCart"
    logging.info(start_msg)
    print(start_msg)

    # 2. –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è
    settings = load_oc_settings()
    if not settings or "presets" not in settings:
        err_msg = "‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –ø—Ä–µ—Å–µ—Ç–∏ –≤ oc_settings.yaml"
        logging.error(err_msg)
        print(err_msg)
        return

    presets = settings["presets"]
    # –û—Ç—Ä–∏–º—É—î–º–æ –±–∞–∑–æ–≤–∏–π —à–ª—è—Ö –¥–ª—è CSV
    csv_base_path = settings["paths"]["output_file"]

    # 3. –í–∏–±—ñ—Ä –ø—Ä–µ—Å–µ—Ç—É
    print("\n–í–∏–±–µ—Ä—ñ—Ç—å –ø—Ä–µ—Å–µ—Ç –¥–ª—è –µ–∫—Å–ø–æ—Ä—Ç—É:\n")
    for key, preset in presets.items():
        print(f" [{key}] - {preset['name']}")

    user_input = input("\n–í–∞—à –≤–∏–±—ñ—Ä: ").strip()

    # --- –í–ò–ü–†–ê–í–õ–ï–ù–ù–Ø: –†–û–ó–£–ú–ù–ò–ô –ü–û–®–£–ö –ö–õ–Æ–ß–ê ---
    # –°–ø–æ—á–∞—Ç–∫—É –ø—Ä–∏–ø—É—Å–∫–∞—î–º–æ, —â–æ –∫–ª—é—á–∞ –Ω–µ–º–∞—î
    preset_id = None

    # 1. –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ —î —Ç–∞–∫–∏–π –∫–ª—é—á —è–∫ —Ä—è–¥–æ–∫ (–Ω–∞ –≤–∏–ø–∞–¥–æ–∫ –∫–ª—é—á—ñ–≤ —Ç–∏–ø—É "all")
    if user_input in presets:
        preset_id = user_input
    else:
        # 2. –Ø–∫—â–æ –Ω—ñ, –ø—Ä–æ–±—É—î–º–æ –ø–µ—Ä–µ—Ç–≤–æ—Ä–∏—Ç–∏ –≤–≤–µ–¥–µ–Ω–Ω—è –Ω–∞ —á–∏—Å–ª–æ (–¥–ª—è –∫–ª—é—á—ñ–≤ 1, 2...)
        try:
            user_input_int = int(user_input)
            if user_input_int in presets:
                preset_id = user_input_int
        except ValueError:
            pass # –¶–µ –±—É–ª–æ –Ω–µ —á–∏—Å–ª–æ, —ñ —Ç–∞–∫–æ–≥–æ —Ä—è–¥–∫–∞ —Ç–µ–∂ –Ω–µ–º–∞—î

    # –Ø–∫—â–æ –ø—ñ—Å–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–æ–∫ preset_id –≤—Å–µ —â–µ None ‚Äî —Ü–µ –ø–æ–º–∏–ª–∫–∞
    if preset_id is None:
        err_msg = f"‚ùå –ù–µ–≤—ñ–¥–æ–º–∏–π –Ω–æ–º–µ—Ä –ø—Ä–µ—Å–µ—Ç—É: {user_input}"
        logging.warning(err_msg)
        print(err_msg)
        return

    sql = presets[preset_id]["sql"]
    preset_name = presets[preset_id]["name"]

    info_msg = f"‚ñ∂ –û–±—Ä–∞–Ω–∏–π –ø—Ä–µ—Å–µ—Ç [{preset_id}]: {preset_name}"
    logging.info(info_msg)
    print(info_msg)

    # 4. –ü—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ –±–∞–∑–∏ —Ç–∞ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è –∑–∞–ø–∏—Ç—É
    conn = oc_connect_db()
    if not conn:
        logging.error("‚ùå –ù–µ–º–æ–∂–ª–∏–≤–æ –ø—ñ–¥–∫–ª—é—á–∏—Ç–∏—Å—è –¥–æ –ë–î (conn is None)")
        return

    try:
        with conn.cursor() as cursor:
            logging.info("‚è≥ –í–∏–∫–æ–Ω—É—î—Ç—å—Å—è SQL –∑–∞–ø–∏—Ç...")
            cursor.execute(sql)
            rows = cursor.fetchall()
    except pymysql.MySQLError as e:
        err_sql = f"‚ùå –ü–æ–º–∏–ª–∫–∞ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è SQL: {e}"
        logging.error(err_sql)
        print(err_sql)
        return
    finally:
        # –ó–∞–≤–∂–¥–∏ –∑–∞–∫—Ä–∏–≤–∞—î–º–æ –∑'—î–¥–Ω–∞–Ω–Ω—è
        conn.close()
        logging.info("üîå –ó'—î–¥–Ω–∞–Ω–Ω—è –∑ –ë–î –∑–∞–∫—Ä–∏—Ç–æ.")

    # 5. –ó–∞–ø–∏—Å CSV
    if rows:
        try:
            with open(csv_base_path, "w", encoding="utf-8", newline="") as f:
                # –ë–µ—Ä–µ–º–æ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∑ –∫–ª—é—á—ñ–≤ –ø–µ—Ä—à–æ–≥–æ —Ä—è–¥–∫–∞
                fieldnames = list(rows[0].keys())
                
                writer = csv.DictWriter(
                    f,
                    fieldnames=fieldnames,
                    quoting=csv.QUOTE_MINIMAL,
                    delimiter=",",
                    escapechar="\\"
                )

                writer.writeheader()

                for row in rows:
                    # –î–µ–∫–æ–¥—É–≤–∞–Ω–Ω—è HTML —Å—É—Ç–Ω–æ—Å—Ç–µ–π (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥ &quot; -> ")
                    decoded_row = {
                        k: html.unescape(v) if isinstance(v, str) else v
                        for k, v in row.items()
                    }
                    writer.writerow(decoded_row)

            success_msg = f"‚úî –ï–∫—Å–ø–æ—Ä—Ç —É—Å–ø—ñ—à–Ω–æ –≤–∏–∫–æ–Ω–∞–Ω–æ: {len(rows)} –∑–∞–ø–∏—Å—ñ–≤."
            logging.info(success_msg)
            print(f"{success_msg}\nüìÅ –§–∞–π–ª: {csv_base_path}")

        except IOError as e:
            err_io = f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–ø–∏—Å—É —Ñ–∞–π–ª—É: {e}"
            logging.error(err_io)
            print(err_io)
    else:
        empty_msg = "‚ö† –†–µ–∑—É–ª—å—Ç–∞—Ç SQL –∑–∞–ø–∏—Ç—É –ø—É—Å—Ç–∏–π. –§–∞–π–ª –Ω–µ —Å—Ç–≤–æ—Ä–µ–Ω–æ."
        logging.warning(empty_msg)
        print(empty_msg)

# –ì–û–õ–û–í–ù–ê –§–£–ù–ö–¶–Ü–Ø 2: –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –ø—Ä–∞–π—Å—É –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ –∑–∞ –π–æ–≥–æ ID
def download_supplier_price_list(supplier_id):
    """
    –°–∫–∞—á—É—î –ø—Ä–∞–π—Å-–ª–∏—Å—Ç –≤—ñ–¥ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ –∑–∞ –π–æ–≥–æ ID.
    """
    # 0. –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ª–æ–≥—É–≤–∞–Ω–Ω—è –¥–ª—è –¥–æ–ø–∏—Å—É–≤–∞–Ω–Ω—è
    oc_log_message()

    # 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω—å
    settings = load_oc_settings()
    if not settings:
        logging.error("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è. –°–∫–∞—á—É–≤–∞–Ω–Ω—è –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –ø–µ—Ä–µ—Ä–≤–∞–Ω–æ.")
        return
    
    # 2. –û—Ç—Ä–∏–º–∞–Ω–Ω—è —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –ø—Ä–æ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞
    suppliers = settings.get("suppliers", {})
    supplier_info = suppliers.get(int(supplier_id))
    if not supplier_info:
        logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞: –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ –∑ ID '{supplier_id}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return

    # 3. –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è —à–ª—è—Ö—ñ–≤
    url = supplier_info.get("download_url")
    csv_path = supplier_info.get("csv_path")

    if not url or not csv_path:
        logging.error(f"‚ùå –ù–µ–ø–æ–≤–Ω—ñ –¥–∞–Ω—ñ –ø—Ä–æ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ '{supplier_id}'. –í—ñ–¥—Å—É—Ç–Ω—ñ–π URL –∞–±–æ —à–ª—è—Ö.")
        return
    
    logging.info(f"‚è≥ –ó–∞–ø—É—Å–∫–∞—é –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –≤—ñ–¥ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ (ID: {supplier_id}).")

    # 4. –í–∏–¥–∞–ª–µ–Ω–Ω—è —Å—Ç–∞—Ä–æ–≥–æ —Ñ–∞–π–ª—É
    if os.path.exists(csv_path):
        try:
            os.remove(csv_path)
            # –û–Ω–æ–≤–ª–µ–Ω–∞ –ª–æ–≥—ñ–∫–∞: –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ ID –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ –∑–∞–º—ñ—Å—Ç—å –Ω–∞–∑–≤–∏ —Ñ–∞–π–ª—É
            logging.info(f"‚úÖ –°—Ç–∞—Ä–∏–π –ø—Ä–∞–π—Å-–ª–∏—Å—Ç –≤—ñ–¥ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ (ID: {supplier_id}) —É—Å–ø—ñ—à–Ω–æ –≤–∏–¥–∞–ª–µ–Ω–æ.")
        except OSError as e:
            logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –≤–∏–¥–∞–ª–µ–Ω–Ω—ñ —Å—Ç–∞—Ä–æ–≥–æ —Ñ–∞–π–ª—É: {e}")
            return
    
    # 5. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –Ω–æ–≤–æ–≥–æ —Ñ–∞–π–ª—É
    try:
        with requests.get(url, stream=True) as r:
            r.raise_for_status()
            with open(csv_path, 'wb') as f:
                shutil.copyfileobj(r.raw, f)
        
        logging.info(f"üéâ –ü—Ä–∞–π—Å-–ª–∏—Å—Ç –≤—ñ–¥ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ (ID: {supplier_id}) —É—Å–ø—ñ—à–Ω–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ.")
    except requests.exceptions.RequestException as e:
        logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ñ–∞–π–ª—É –≤—ñ–¥ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ (ID: {supplier_id}): {e}", exc_info=True)
    except Exception as e:
        logging.error(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –Ω–µ–≤—ñ–¥–æ–º–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è: {e}", exc_info=True)

# –ì–û–õ–û–í–ù–ê –§–£–ù–ö–¶–Ü–Ø 3: –û–±—Ä–æ–±–∫–∞ –ø—Ä–∞–π—Å—É –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫—ñ–≤
def process_supplier_1_price_list():
    """
    –û–±—Ä–æ–±–ª—è—î —Ç–∞ –æ—á–∏—â–∞—î –ø—Ä–∞–π—Å-–ª–∏—Å—Ç –≤—ñ–¥ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 1.
    """
    # 0. –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ª–æ–≥—É–≤–∞–Ω–Ω—è –¥–ª—è –¥–æ–ø–∏—Å—É–≤–∞–Ω–Ω—è
    oc_log_message()

    # 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω—å
    settings = load_oc_settings()
    if not settings:
        logging.error("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è. –û–±—Ä–æ–±–∫–∞ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –ø–µ—Ä–µ—Ä–≤–∞–Ω–∞.")
        return

    supplier_id = "1"
    supplier_info = settings.get("suppliers", {}).get(int(supplier_id))
    if not supplier_info:
        logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞: –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ –∑ ID '{supplier_id}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return

    # 2. –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è —à–ª—è—Ö—ñ–≤ —Ç–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤
    csv_path = supplier_info.get("csv_path")
    csv_mod_path = supplier_info.get("csv_mod_path")
    delimiter = supplier_info.get("delimiter")
    # –û—Ç—Ä–∏–º—É—î–º–æ –æ—á—ñ–∫—É–≤–∞–Ω—ñ –∑–∞–≥–æ–ª–æ–≤–∫–∏ —è–∫ —Ä—è–¥–æ–∫
    expected_headers_str = supplier_info.get("header_price")
    # –ó–ê–í–ê–ù–¢–ê–ñ–ï–ù–ù–Ø –ß–û–†–ù–û–ì–û –°–ü–ò–°–ö–£
    # –Ø–∫—â–æ —Å–ø–∏—Å–∫—É –Ω–µ–º–∞—î –≤ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è—Ö, –ø–æ–≤–µ—Ä–Ω–µ—Ç—å—Å—è –ø–æ—Ä–æ–∂–Ω—ñ–π —Å–ø–∏—Å–æ–∫ []
    blacklisted_brands = settings.get("blacklisted_brands", [])
    # –ü–µ—Ä–µ–≤–æ–¥–∏–º–æ –≤—Å—ñ —Å–ª–æ–≤–∞ –≤ –Ω–∏–∂–Ω—ñ–π —Ä–µ–≥—ñ—Å—Ç—Ä –ø—Ä–æ –≤—Å—è–∫ –≤–∏–ø–∞–¥–æ–∫
    blacklisted_brands = [word.lower() for word in blacklisted_brands]

    if not os.path.exists(csv_path):
        logging.error(f"‚ùå –§–∞–π–ª –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –¥–ª—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {supplier_id} –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ")
        return

    logging.info(f"‚öôÔ∏è –ó–∞–ø—É—Å–∫–∞—é –æ–±—Ä–æ–±–∫—É –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –¥–ª—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {supplier_id}. \n –ß–æ—Ä–Ω–∏–π —Å–ø–∏—Å–æ–∫ –±—Ä–µ–Ω–¥—ñ–≤: {blacklisted_brands}")

    processed_rows = []
    skipped_rows = 0
    total_rows = 0
    skipped_by_blacklist = 0
    skipped_by_date_in_name = 0
    skipped_by_empty_barcode = 0
    fieldnames = [] # –¢—É—Ç –∑–±–µ—Ä–µ–∂–µ–º–æ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –∑–∞–ø–∏—Å—É

    try:
        with open(csv_path, "r", newline="", encoding="utf-8") as infile:
            reader = csv.DictReader(infile, delimiter=delimiter)

            actual_headers = reader.fieldnames
            fieldnames = actual_headers # –ó–∞–ø–∞–º'—è—Ç–æ–≤—É—î–º–æ –¥–ª—è –∑–∞–ø–∏—Å—É —Ñ–∞–π–ª—É
            # --- –ü–ï–†–ï–í–Ü–†–ö–ê –ó–ê–ì–û–õ–û–í–ö–Ü–í ---
            if expected_headers_str:
                expected_headers_list = next(csv.reader(io.StringIO(expected_headers_str), delimiter=delimiter))

                if actual_headers != expected_headers_list:
                    logging.error("‚ùå –ö–†–ò–¢–ò–ß–ù–ê –ü–û–ú–ò–õ–ö–ê: –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª—É –∑–º—ñ–Ω–∏–ª–∞—Å—è!")
                    logging.error(f"   –û—á—ñ–∫—É–≤–∞–ª–∏: {expected_headers_list}")
                    logging.error(f"   –û—Ç—Ä–∏–º–∞–ª–∏:  {actual_headers}")
                    logging.error("‚èπÔ∏è –û–±—Ä–æ–±–∫—É –∑—É–ø–∏–Ω–µ–Ω–æ.")
                    return
                else:
                    logging.info("‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∑–∞–≥–æ–ª–æ–≤–∫—ñ–≤ –≤—ñ—Ä–Ω–∞.")
            else:
                logging.warning("‚ö†Ô∏è –ù–µ–º–∞—î 'header_price' –≤ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è—Ö, –ø—Ä–æ–ø—É—Å–∫–∞—é –ø–µ—Ä–µ–≤—ñ—Ä–∫—É.")
           

            row_number = 1
            for row in reader:
                row_number += 1
                total_rows += 1

                # 1. –§—ñ–ª—å—Ç—Ä —Ü—ñ–Ω–∏ (–ª—ñ—Ç–µ—Ä–∏)
                price_val = row.get("–¶–µ–Ω–∞", "")
                if re.search(r'[a-zA-Z–∞-—è–ê-–Ø—ñ–Ü—ó–á—î–Ñ“ë“ê—ë–Å]', price_val):
                    logging.warning(f"üö´ –†—è–¥–æ–∫ {row_number}: –ª—ñ—Ç–µ—Ä–∏ –≤ —Ü—ñ–Ω—ñ '{price_val}'.")
                    skipped_rows += 1
                    continue

                # 2. –£–ù–Ü–í–ï–†–°–ê–õ–¨–ù–ò–ô –§–Ü–õ–¨–¢–† –ü–û –ë–†–ï–ù–î–ê–•/–ù–ê–ó–í–ê–• (–ù–æ–≤–∏–π –±–ª–æ–∫)
                if blacklisted_brands:
                    # –û—Ç—Ä–∏–º—É—î–º–æ –∑–Ω–∞—á–µ–Ω–Ω—è –∑ –∫–æ–ª–æ–Ω–æ–∫ —ñ –ø–µ—Ä–µ–≤–æ–¥–∏–º–æ –≤ –Ω–∏–∂–Ω—ñ–π —Ä–µ–≥—ñ—Å—Ç—Ä
                    brand_val = row.get("–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å", "").lower()
                    desc_val = row.get("–û–ø–∏—Å–∞–Ω–∏–µ", "").lower()
                    name_val = row.get("–ù–∞–∑–≤–∞–Ω–∏–µ_–ø–æ–∑–∏—Ü–∏–∏", "").lower()
                    
                    found_bad_word = False
                    
                    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –∫–æ–∂–Ω–µ –∑–∞–±–æ—Ä–æ–Ω–µ–Ω–µ —Å–ª–æ–≤–æ
                    for bad_word in blacklisted_brands:
                        # –®—É–∫–∞—î–º–æ —Å–ª–æ–≤–æ —ñ –≤ –ë—Ä–µ–Ω–¥—ñ, —ñ –≤ –û–ø–∏—Å—ñ
                        if (bad_word in brand_val) or (bad_word in desc_val) or (bad_word in name_val):
                            logging.warning(f"üö´ –†—è–¥–æ–∫ {row_number}: –í–∏–¥–∞–ª–µ–Ω–æ —á–µ—Ä–µ–∑ —Ñ—ñ–ª—å—Ç—Ä '{bad_word}'. (–ù–∞–∑–≤–∞: {row.get('–ù–∞–∑–≤–∞–Ω–∏–µ_–ø–æ–∑–∏—Ü–∏–∏')}, –ë—Ä–µ–Ω–¥: {row.get('–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å')}, –û–ø–∏—Å: {row.get('–û–ø–∏—Å–∞–Ω–∏–µ')[:20]}...)")
                            skipped_rows += 1
                            skipped_by_blacklist += 1
                            found_bad_word = True
                            break # –Ø–∫—â–æ –∑–Ω–∞–π—à–ª–∏ —Ö–æ—á –æ–¥–Ω–µ —Å–ª–æ–≤–æ, –¥–∞–ª—ñ –Ω–µ –ø–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, –≤–∏–¥–∞–ª—è—î–º–æ
                    
                    if found_bad_word:
                        continue


                # 3. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è —Ü—ñ–Ω–∏
                if price_val:
                    try:
                        row["–¶–µ–Ω–∞"] = str(int(float(price_val)))
                    except (ValueError, TypeError):
                         pass 

                # 4. –î–∞—Ç–∞ –≤ –Ω–∞–∑–≤—ñ
                date_pattern = re.compile(r'\b(0[1-9]|1[0-2])\.\d{4}\b')
                name_for_date_val = row.get("–ù–∞–∑–≤–∞–Ω–∏–µ_–ø–æ–∑–∏—Ü–∏–∏", "")
                if date_pattern.search(name_for_date_val):
                    logging.warning(f"üö´ –†—è–¥–æ–∫ {row_number}: –í–∏–¥–∞–ª–µ–Ω–æ —á–µ—Ä–µ–∑ —Ñ—ñ–ª—å—Ç—Ä '–î–∞—Ç–∞ –≤ –Ω–∞–∑–≤—ñ'. –ù–∞–∑–≤–∞: {row.get('–ù–∞–∑–≤–∞–Ω–∏–µ_–ø–æ–∑–∏—Ü–∏–∏')}")
                    skipped_rows += 1
                    skipped_by_date_in_name += 1
                    continue

                # 5. –®—Ç—Ä–∏—Ö–∫–æ–¥
                barcode_val = row.get("–®—Ç—Ä–∏—Ö_–∫–æ–¥", "")
                if not barcode_val or len(barcode_val.strip()) == 0:
                    logging.warning(f"üö´ –†—è–¥–æ–∫ {row_number}: –í–∏–¥–∞–ª–µ–Ω–æ —á–µ—Ä–µ–∑ —Ñ—ñ–ª—å—Ç—Ä '–ü—É—Å—Ç–∏–π —à—Ç—Ä–∏—Ö–∫–æ–¥'")
                    skipped_rows += 1
                    skipped_by_empty_barcode += 1
                    continue
                
                # 6. –ù–∞—è–≤–Ω—ñ—Å—Ç—å
                if row.get("–ù–∞–ª–∏—á–∏–µ") == ">3":
                    row["–ù–∞–ª–∏—á–∏–µ"] = "4"
                
                processed_rows.append(row)                
    
    except Exception as e:
        logging.error(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –æ–±—Ä–æ–±–∫–∏ —Ñ–∞–π–ª—É: {e}", exc_info=True)
        return

    # --- 4. –ó–∞–ø–∏—Å —É –Ω–æ–≤–∏–π —Ñ–∞–π–ª (–í–ò–ü–†–ê–í–õ–ï–ù–û) ---
    try:
        output_dir = os.path.dirname(csv_mod_path)
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir, exist_ok=True)

        with open(csv_mod_path, "w", newline="", encoding="utf-8") as outfile:
            # –¢–£–¢ –ì–û–õ–û–í–ù–ê –ó–ú–Ü–ù–ê: –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ DictWriter
            writer = csv.DictWriter(outfile, fieldnames=fieldnames, delimiter=delimiter)
            
            # –ü–∏—à–µ–º–æ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ
            writer.writeheader()
            
            # –ü–∏—à–µ–º–æ –¥–∞–Ω—ñ
            writer.writerows(processed_rows)
            
        logging.info(f"üíæ –§–∞–π–ª —É—Å–ø—ñ—à–Ω–æ –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {csv_mod_path}")
        
    except Exception as e:
        logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–ø–∏—Å—É —Ñ–∞–π–ª—É {csv_mod_path}: {e}", exc_info=True)
        return

    # --- 5. –ü–ï–†–ï–í–Ü–†–ö–ê –ó–ê–ü–ò–°–ê–ù–û–ì–û –§–ê–ô–õ–£ –ù–ê –î–£–ë–õ–Ü–ö–ê–¢–ò ---
    logging.info(f"üîé –ü–µ—Ä–µ–≤—ñ—Ä—è—é –∑–±–µ—Ä–µ–∂–µ–Ω–∏–π —Ñ–∞–π–ª –Ω–∞ –¥—É–±–ª—ñ–∫–∞—Ç–∏ —à—Ç—Ä–∏—Ö–∫–æ–¥—ñ–≤: {csv_mod_path}")
    
    try:
        barcode_tracker = {}
        duplicates_found = 0
        
        # –í—ñ–¥–∫—Ä–∏–≤–∞—î–º–æ –©–û–ô–ù–û –∑–±–µ—Ä–µ–∂–µ–Ω–∏–π —Ñ–∞–π–ª –¥–ª—è —á–∏—Ç–∞–Ω–Ω—è
        with open(csv_mod_path, "r", newline="", encoding="utf-8") as checkfile:
            # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ DictReader, —â–æ–± –∑–≤–µ—Ä—Ç–∞—Ç–∏—Å—è –ø–æ –Ω–∞–∑–≤—ñ –∫–æ–ª–æ–Ω–∫–∏
            check_reader = csv.DictReader(checkfile, delimiter=delimiter)
            
            # enumerate start=2, –±–æ —Ä—è–¥–æ–∫ 1 - —Ü–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏
            for line_num, row in enumerate(check_reader, start=2):
                barcode = row.get("–®—Ç—Ä–∏—Ö_–∫–æ–¥", "").strip()
                
                if not barcode:
                    continue
                    
                if barcode not in barcode_tracker:
                    barcode_tracker[barcode] = []
                
                barcode_tracker[barcode].append(line_num)
        
        # –ê–Ω–∞–ª—ñ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        for barcode, rows_list in barcode_tracker.items():
            if len(rows_list) > 1:
                duplicates_found += 1
                rows_str = ", ".join(map(str, rows_list))
                logging.warning(f"‚ö†Ô∏è –£–í–ê–ì–ê: –û–¥–Ω–∞–∫–æ–≤—ñ —à—Ç—Ä–∏—Ö–∫–æ–¥–∏ '{barcode}' —É —Ä—è–¥–∫–∞—Ö (–≥–æ—Ç–æ–≤–æ–≥–æ —Ñ–∞–π–ª—É): {rows_str}")

        if duplicates_found == 0:
            logging.info("‚úÖ –£ –∑–±–µ—Ä–µ–∂–µ–Ω–æ–º—É —Ñ–∞–π–ª—ñ –¥—É–±–ª—ñ–∫–∞—Ç—ñ–≤ —à—Ç—Ä–∏—Ö–∫–æ–¥—ñ–≤ –Ω–µ–º–∞—î.")
        else:
            logging.info(f"‚ö†Ô∏è –ó–Ω–∞–π–¥–µ–Ω–æ {duplicates_found} —à—Ç—Ä–∏—Ö–∫–æ–¥—ñ–≤, —â–æ –ø–æ–≤—Ç–æ—Ä—é—é—Ç—å—Å—è —É –∑–±–µ—Ä–µ–∂–µ–Ω–æ–º—É —Ñ–∞–π–ª—ñ.")

    except Exception as e:
        logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–≤—ñ—Ä—Ü—ñ —Ñ–∞–π–ª—É: {e}", exc_info=True)

    # 5. –õ–æ–≥—É–≤–∞–Ω–Ω—è –ø—ñ–¥—Å—É–º–∫—ñ–≤
    logging.info(f"üéâ –û–±—Ä–æ–±–∫—É –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –¥–ª—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {supplier_id} –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")
    logging.info(f"--- –ü—ñ–¥—Å—É–º–æ–∫ –æ–±—Ä–æ–±–∫–∏: ---")
    logging.info(f"üì¶ –í—Å—å–æ–≥–æ —Ä—è–¥–∫—ñ–≤ —É —Ñ–∞–π–ª—ñ: {total_rows}")
    logging.info(f"üóëÔ∏è –í–∏–¥–∞–ª–µ–Ω–æ —Ä—è–¥–∫—ñ–≤: {skipped_rows}")
    logging.info(f"‚úÖ –û–±—Ä–æ–±–ª–µ–Ω—ñ —Ä—è–¥–∫–∏: {len(processed_rows) - 1}")
    logging.info(f"üìÖ –í–∏–¥–∞–ª–µ–Ω–æ —á–µ—Ä–µ–∑ –¥–∞—Ç—É –≤ –Ω–∞–∑–≤—ñ: {skipped_by_date_in_name}")
    logging.info(f"üè∑Ô∏è –í–∏–¥–∞–ª–µ–Ω–æ —á–µ—Ä–µ–∑ –≤—ñ–¥—Å—É—Ç–Ω—ñ–π —à—Ç—Ä–∏—Ö–∫–æ–¥: {skipped_by_empty_barcode}")

# –î–û–†–û–ë–ò–¢–ò
def process_supplier_2_price_list():
    """
    –û–±—Ä–æ–±–ª—è—î —Ç–∞ –æ—á–∏—â–∞—î –ø—Ä–∞–π—Å-–ª–∏—Å—Ç –≤—ñ–¥ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 2.
    """
    # 0. –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ª–æ–≥—É–≤–∞–Ω–Ω—è –¥–ª—è –¥–æ–ø–∏—Å—É–≤–∞–Ω–Ω—è
    oc_log_message()

    # 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω—å
    settings = load_oc_settings()
    if not settings:
        logging.error("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è. –û–±—Ä–æ–±–∫–∞ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –ø–µ—Ä–µ—Ä–≤–∞–Ω–∞.")
        return

    supplier_id = "2"
    supplier_info = settings.get("suppliers", {}).get(supplier_id)
    if not supplier_info:
        logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞: –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ –∑ ID '{supplier_id}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return

    # 2. –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è —à–ª—è—Ö—ñ–≤ —Ç–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤
    base_dir = os.path.join(os.path.dirname(__file__), "..")
    csv_path = os.path.join(base_dir, supplier_info.get("csv_path"))
    delimiter = supplier_info.get("delimiter", ",")

    if not os.path.exists(csv_path):
        logging.error(f"‚ùå –§–∞–π–ª –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –¥–ª—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {supplier_id} –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∑–∞ —à–ª—è—Ö–æ–º: {csv_path}")
        return

    logging.info(f"‚öôÔ∏è –ó–∞–ø—É—Å–∫–∞—é –æ–±—Ä–æ–±–∫—É –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –¥–ª—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {supplier_id}.")

    # 3. –û–±—Ä–æ–±–∫–∞ –¥–∞–Ω–∏—Ö
    temp_file_path = f"{csv_path}.temp"
    processed_rows = []
    skipped_rows = 0
    total_rows = 0
    modifications_count = 0

    try:
        with open(csv_path, "r", newline="", encoding="utf-8") as infile:
            reader = csv.reader(infile, delimiter=delimiter)
            try:
                headers = next(reader)
                processed_rows.append(headers)
            except StopIteration:
                logging.warning("‚ö†Ô∏è –§–∞–π–ª –ø–æ—Ä–æ–∂–Ω—ñ–π. –í—ñ–¥—Å—É—Ç–Ω—ñ —Ä—è–¥–∫–∏.")
                return

            row_number = 1
            for row in reader:
                row_number += 1
                total_rows += 1

                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∫–æ–ª–æ–Ω–∫–∏ 5 (–≤–∞–ª—é—Ç–∞)
                if len(row) > 4:
                    currency_value = row[4].strip().upper()
                    if currency_value != "UAH":
                        logging.warning(f"üö´ –í–∏–¥–∞–ª–µ–Ω–æ —Ä—è–¥–æ–∫ {row_number} —á–µ—Ä–µ–∑ –Ω–µ–∫–æ—Ä–µ–∫—Ç–Ω—É –≤–∞–ª—é—Ç—É —É –∫–æ–ª–æ–Ω—Ü—ñ 5: '{row[4]}'.")
                        skipped_rows += 1
                        continue
                else:
                    logging.warning(f"üö´ –í–∏–¥–∞–ª–µ–Ω–æ —Ä—è–¥–æ–∫ {row_number} —á–µ—Ä–µ–∑ –≤—ñ–¥—Å—É—Ç–Ω—ñ—Å—Ç—å –∑–Ω–∞—á–µ–Ω–Ω—è —É –∫–æ–ª–æ–Ω—Ü—ñ 5 (–≤–∞–ª—é—Ç–∞).")
                    skipped_rows += 1
                    continue

                # –ü–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è –∫–æ–ª–æ–Ω–∫–∏ 4 (—Ü—ñ–Ω–∞) –∑ float –Ω–∞ int
                if len(row) > 3 and row[3]:
                    try:
                        row[3] = str(int(float(row[3])))
                    except (ValueError, IndexError):
                        logging.warning(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –ø–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ü—ñ–Ω–∏ –≤ —Ä—è–¥–∫—É {row_number}. –ó–Ω–∞—á–µ–Ω–Ω—è: '{row[3]}'")
                
                # –ó–∞–º—ñ–Ω–∞ –∑–Ω–∞—á–µ–Ω–Ω—è –≤ –∫–æ–ª–æ–Ω—Ü—ñ 7 (–∫–∞—Ç–µ–≥–æ—Ä—ñ—è)
                if len(row) > 6 and row[6] == ">3":
                    row[6] = "4"
                    modifications_count += 1
                
                processed_rows.append(row)
    
    except Exception as e:
        logging.error(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –æ–±—Ä–æ–±–∫–∏ —Ñ–∞–π–ª—É: {e}", exc_info=True)
        return

    # 4. –ó–∞–ø–∏—Å –æ–±—Ä–æ–±–ª–µ–Ω–æ–≥–æ —Ñ–∞–π–ª—É
    with open(temp_file_path, "w", newline="", encoding="utf-8") as outfile:
        writer = csv.writer(outfile, delimiter=delimiter)
        writer.writerows(processed_rows)

    os.replace(temp_file_path, csv_path)

    # 5. –õ–æ–≥—É–≤–∞–Ω–Ω—è –ø—ñ–¥—Å—É–º–∫—ñ–≤
    logging.info(f"üéâ –û–±—Ä–æ–±–∫—É –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –¥–ª—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {supplier_id} –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")
    logging.info("--- –ü—ñ–¥—Å—É–º–æ–∫ –æ–±—Ä–æ–±–∫–∏: ---")
    logging.info(f"üì¶ –í—Å—å–æ–≥–æ —Ä—è–¥–∫—ñ–≤ —É —Ñ–∞–π–ª—ñ: {total_rows}")
    logging.info(f"üóëÔ∏è –í–∏–¥–∞–ª–µ–Ω–æ —Ä—è–¥–∫—ñ–≤: {skipped_rows}")
    logging.info(f"üìù –ó–º—ñ–Ω–µ–Ω–æ –∫–∞—Ç–µ–≥–æ—Ä—ñ–π '>3' -> '4': {modifications_count} —Ä–∞–∑—ñ–≤")
    logging.info(f"‚úÖ –û–±—Ä–æ–±–ª–µ–Ω—ñ —Ä—è–¥–∫–∏: {len(processed_rows) - 1}")
    print("‚úÖ –û–±—Ä–æ–±–∫–∞ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –î–µ—Ç–∞–ª—ñ –≤ –ª–æ–≥-—Ñ–∞–π–ª—ñ.")
# –î–û–†–û–ë–ò–¢–ò
def process_supplier_3_price_list():
    """
    –û–±—Ä–æ–±–ª—è—î —Ç–∞ –∫–æ–Ω–≤–µ—Ä—Ç—É—î –ø—Ä–∞–π—Å-–ª–∏—Å—Ç –≤—ñ–¥ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ 3 (—Ñ–æ—Ä–º–∞—Ç .xls),
    –∞ –ø–æ—Ç—ñ–º —Ñ—ñ–ª—å—Ç—Ä—É—î –¥–∞–Ω—ñ.
    """
    # 0. –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ª–æ–≥—É–≤–∞–Ω–Ω—è –¥–ª—è –¥–æ–ø–∏—Å—É–≤–∞–Ω–Ω—è
    oc_log_message()

    # 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω—å
    settings = load_oc_settings()
    if not settings:
        logging.error("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è. –û–±—Ä–æ–±–∫–∞ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –ø–µ—Ä–µ—Ä–≤–∞–Ω–∞.")
        return

    supplier_id = "3"
    supplier_info = settings.get("suppliers", {}).get(supplier_id)
    if not supplier_info:
        logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞: –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ –∑ ID '{supplier_id}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return

    # 2. –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è —à–ª—è—Ö—ñ–≤
    base_dir = os.path.join(os.path.dirname(__file__), "..")
    xls_path = os.path.join(base_dir, supplier_info.get("csv_path"))
    csv_name = os.path.join(base_dir, supplier_info.get("csv_name"))

    logging.info(f"‚öôÔ∏è –ó–∞–ø—É—Å–∫–∞—é –æ–±—Ä–æ–±–∫—É –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –¥–ª—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {supplier_id}.")

    # 3. –í–∏–¥–∞–ª–µ–Ω–Ω—è —Å—Ç–∞—Ä–æ–≥–æ CSV-—Ñ–∞–π–ª—É
    if os.path.exists(csv_name):
        try:
            os.remove(csv_name)
            logging.info(f"‚úÖ –°—Ç–∞—Ä–∏–π –ø—Ä–∞–π—Å-–ª–∏—Å—Ç –¥–ª—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {supplier_id} —É—Å–ø—ñ—à–Ω–æ –≤–∏–¥–∞–ª–µ–Ω–æ.")
        except OSError as e:
            logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –≤–∏–¥–∞–ª–µ–Ω–Ω—ñ —Å—Ç–∞—Ä–æ–≥–æ CSV-—Ñ–∞–π–ª—É: {e}")
            return

    # 4. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è XLS –≤ CSV
    if not os.path.exists(xls_path):
        logging.error(f"‚ùå –§–∞–π–ª .xls –¥–ª—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {supplier_id} –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∑–∞ —à–ª—è—Ö–æ–º: {xls_path}")
        return

    try:
        df = pd.read_excel(xls_path)
        df.to_csv(csv_name, index=False, encoding="utf-8")
        
        logging.info(f"üéâ –§–∞–π–ª .xls –¥–ª—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {supplier_id} —É—Å–ø—ñ—à–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–æ–≤–∞–Ω–æ –≤ CSV.")

    except Exception as e:
        logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—ó —Ñ–∞–π–ª—É: {e}", exc_info=True)
        return

    # 5. –§—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è —Ç–∞ –æ—á–∏—â–µ–Ω–Ω—è CSV-—Ñ–∞–π–ª—É
    logging.info(f"üîç –ó–∞–ø—É—Å–∫–∞—é —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—é –¥–∞–Ω–∏—Ö —É CSV-—Ñ–∞–π–ª—ñ –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {supplier_id}.")

    temp_file_path = f"{csv_name}.temp"
    processed_rows = []
    skipped_rows = 0
    total_rows = 0

    try:
        with open(csv_name, "r", newline="", encoding="utf-8") as infile:
            reader = csv.reader(infile)
            try:
                headers = next(reader)
                processed_rows.append(headers)
            except StopIteration:
                logging.warning("‚ö†Ô∏è –§–∞–π–ª –ø–æ—Ä–æ–∂–Ω—ñ–π. –í—ñ–¥—Å—É—Ç–Ω—ñ —Ä—è–¥–∫–∏.")
                return
            
            row_number = 1
            for row in reader:
                row_number += 1
                total_rows += 1

                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞, —â–æ —Ä—è–¥–æ–∫ –º—ñ—Å—Ç–∏—Ç—å –¥–æ—Å—Ç–∞—Ç–Ω—å–æ –∫–æ–ª–æ–Ω–æ–∫
                if len(row) < 4:
                    logging.warning(f"üö´ –í–∏–¥–∞–ª–µ–Ω–æ —Ä—è–¥–æ–∫ {row_number} —á–µ—Ä–µ–∑ –Ω–µ–¥–æ—Å—Ç–∞—Ç–Ω—é –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫–æ–ª–æ–Ω–æ–∫.")
                    skipped_rows += 1
                    continue

                # –ü–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è –∫–æ–ª–æ–Ω–æ–∫ 3 —Ç–∞ 4 –Ω–∞ —Ü—ñ–ª—ñ —á–∏—Å–ª–∞
                is_valid = True
                for col_index in [2, 3]:
                    value = row[col_index]
                    try:
                        # –ü–µ—Ä–µ—Ç–≤–æ—Ä—é—î–º–æ –∑–Ω–∞—á–µ–Ω–Ω—è –Ω–∞ float, –∞ –ø–æ—Ç—ñ–º –Ω–∞ int, —â–æ–± –ø–æ–∑–±—É—Ç–∏—Å—è .0
                        int_value = int(float(value))
                        if int_value < 0:
                            logging.warning(f"üö´ –í–∏–¥–∞–ª–µ–Ω–æ —Ä—è–¥–æ–∫ {row_number} —á–µ—Ä–µ–∑ –≤—ñ–¥'—î–º–Ω–µ –∑–Ω–∞—á–µ–Ω–Ω—è –≤ –∫–æ–ª–æ–Ω—Ü—ñ {col_index + 1}: '{value}'.")
                            is_valid = False
                            break
                        # –ó–∞–ø–∏—Å—É—î–º–æ –æ–±—Ä–æ–±–ª–µ–Ω–µ —Ü—ñ–ª–µ –∑–Ω–∞—á–µ–Ω–Ω—è –Ω–∞–∑–∞–¥ —É —Ä—è–¥–æ–∫
                        row[col_index] = str(int_value) 
                    except (ValueError, IndexError):
                        logging.warning(f"üö´ –í–∏–¥–∞–ª–µ–Ω–æ —Ä—è–¥–æ–∫ {row_number} —á–µ—Ä–µ–∑ –Ω–µ–∫–æ—Ä–µ–∫—Ç–Ω–µ —á–∏—Å–ª–æ–≤–µ –∑–Ω–∞—á–µ–Ω–Ω—è –≤ –∫–æ–ª–æ–Ω—Ü—ñ {col_index + 1}: '{value}'.")
                        is_valid = False
                        break

                if is_valid:
                    processed_rows.append(row)
                else:
                    skipped_rows += 1
    
    except Exception as e:
        logging.error(f"‚ùå –í–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—ó —Ñ–∞–π–ª—É: {e}", exc_info=True)
        return

    # 6. –ó–∞–ø–∏—Å –≤—ñ–¥—Ñ—ñ–ª—å—Ç—Ä–æ–≤–∞–Ω–∏—Ö –¥–∞–Ω–∏—Ö —É —Ñ–∞–π–ª
    with open(temp_file_path, "w", newline="", encoding="utf-8") as outfile:
        writer = csv.writer(outfile)
        writer.writerows(processed_rows)

    os.replace(temp_file_path, csv_name)

    # 7. –õ–æ–≥—É–≤–∞–Ω–Ω—è –ø—ñ–¥—Å—É–º–∫—ñ–≤
    logging.info(f"üéâ –û–±—Ä–æ–±–∫—É —Ç–∞ —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—é –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –¥–ª—è –ø–æ—Å—Ç–∞—á–∞–ª—å–Ω–∏–∫–∞ {supplier_id} –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")
    logging.info("--- –ü—ñ–¥—Å—É–º–æ–∫ –æ–±—Ä–æ–±–∫–∏: ---")
    logging.info(f"üì¶ –í—Å—å–æ–≥–æ —Ä—è–¥–∫—ñ–≤ —É —Ñ–∞–π–ª—ñ: {total_rows}")
    logging.info(f"üóëÔ∏è –í–∏–¥–∞–ª–µ–Ω–æ —Ä—è–¥–∫—ñ–≤: {skipped_rows}")
    logging.info(f"‚úÖ –û–±—Ä–æ–±–ª–µ–Ω—ñ —Ä—è–¥–∫–∏: {len(processed_rows) - 1}")
    print("‚úÖ –û–±—Ä–æ–±–∫–∞ –ø—Ä–∞–π—Å-–ª–∏—Å—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –î–µ—Ç–∞–ª—ñ –≤ –ª–æ–≥-—Ñ–∞–π–ª—ñ.")